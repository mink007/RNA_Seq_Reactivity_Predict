{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07014148",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import math\n",
    "import copy\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "#import polars as pl\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "\n",
    "import math\n",
    "import copy\n",
    "\n",
    "# Check if a GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "#Training Data\n",
    "df = pd.read_csv('/media/spartans/COMMON:/RNA_Project/train_data.csv')\n",
    "\n",
    "# Create a list of random data samples (for demonstration)\n",
    "max_seq_len = 206 + 2  # +2 is added to cover start and end token of sequence This will change to 457 in private set  # Set the maximum sequence length to 100\n",
    "\n",
    "\n",
    "seed=69\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "seed_everything(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23a3a954",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.d_k = d_model // num_heads\n",
    "        \n",
    "        self.W_q = nn.Linear(d_model, d_model)\n",
    "        self.W_k = nn.Linear(d_model, d_model)\n",
    "        self.W_v = nn.Linear(d_model, d_model)\n",
    "        self.W_o = nn.Linear(d_model, d_model)\n",
    "        \n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
    "        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "        if mask is not None:\n",
    "            attn_scores = attn_scores.masked_fill(mask == 0, -1e9)\n",
    "        attn_probs = torch.softmax(attn_scores, dim=-1)\n",
    "        output = torch.matmul(attn_probs, V)\n",
    "        return output\n",
    "        \n",
    "    def split_heads(self, x):\n",
    "        batch_size, seq_length, d_model = x.size()\n",
    "        return x.view(batch_size, seq_length, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        \n",
    "    def combine_heads(self, x):\n",
    "        batch_size, _, seq_length, d_k = x.size()\n",
    "        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.d_model)\n",
    "        \n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        Q = self.split_heads(self.W_q(Q))\n",
    "        K = self.split_heads(self.W_k(K))\n",
    "        V = self.split_heads(self.W_v(V))\n",
    "        \n",
    "        attn_output = self.scaled_dot_product_attention(Q, K, V, mask)\n",
    "        output = self.W_o(self.combine_heads(attn_output))\n",
    "        #print(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc319971",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionWiseFeedForward1(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PositionWiseFeedForward, self).__init__()\n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc2(self.relu(self.fc1(x)))\n",
    "    \n",
    "class PositionWiseFeedForward(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, hidden, drop_prob=0.1):\n",
    "        super(PositionWiseFeedForward, self).__init__()\n",
    "        self.linear1 = nn.Linear(d_model, hidden)\n",
    "        self.linear2 = nn.Linear(hidden, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=drop_prob)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        #print(f\"x after first linear layer: {x.size()}\")\n",
    "        x = self.relu(x)\n",
    "        #print(f\"x after activation: {x.size()}\")\n",
    "        x = self.dropout(x)\n",
    "        #print(f\"x after dropout: {x.size()}\")\n",
    "        x = self.linear2(x)\n",
    "        #print(f\"x after 2nd linear layer: {x.size()}\")\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bd711d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_seq_length):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        \n",
    "        pe = torch.zeros(max_seq_length, d_model)\n",
    "        position = torch.arange(0, max_seq_length, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n",
    "        \n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        \n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #print(x.size())\n",
    "        #print(self.pe[:, :x.size(1)].size())\n",
    "        #print((x + self.pe[:, :x.size(1)]).size())\n",
    "        return x + self.pe[:, :x.size(1)]\n",
    "    \n",
    "\n",
    "class PositionalEncoding1(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, max_sequence_length):\n",
    "        super().__init__()\n",
    "        self.max_sequence_length = max_sequence_length\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        even_i = torch.arange(0, self.d_model, 2).float()\n",
    "        denominator = torch.pow(10000, even_i/self.d_model)\n",
    "        position = torch.arange(self.max_sequence_length).reshape(self.max_sequence_length, 1)\n",
    "        even_PE = torch.sin(position / denominator)\n",
    "        odd_PE = torch.cos(position / denominator)\n",
    "        stacked = torch.stack([even_PE, odd_PE], dim=2)\n",
    "        PE = torch.flatten(stacked, start_dim=1, end_dim=2)\n",
    "        print(\"PE size\", PE.size())\n",
    "        print(\"x size\", x.size())\n",
    "        print(\"PE x size\", PE[:, :x.size(1)].size())\n",
    "        print(\"stacked dim\", stacked.size())\n",
    "        return x + PE[:, :x.size(1)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3dbaa553",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        attn_output = self.self_attn(x, x, x, mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm2(x + self.dropout(ff_output))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49895d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.cross_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, enc_output, src_mask, tgt_mask):\n",
    "        attn_output = self.self_attn(x, x, x, tgt_mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        attn_output = self.cross_attn(x, enc_output, enc_output, src_mask)\n",
    "        x = self.norm2(x + self.dropout(attn_output))\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm3(x + self.dropout(ff_output))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af828056",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.encoder_embedding = nn.Embedding(src_vocab_size, d_model)\n",
    "        self.decoder_embedding = nn.Embedding(tgt_vocab_size, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(d_model, max_seq_length)\n",
    "\n",
    "        self.encoder_layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "        self.decoder_layers = nn.ModuleList([DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "\n",
    "        self.fc = nn.Linear(d_model, tgt_vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def generate_mask(self, src, tgt):\n",
    "        src_mask = (src != 0).unsqueeze(1).unsqueeze(2)\n",
    "        tgt_mask = (tgt != 0).unsqueeze(1).unsqueeze(3)\n",
    "        seq_length = tgt.size(1)\n",
    "        nopeak_mask = (1 - torch.triu(torch.ones(1, seq_length, seq_length), diagonal=1)).bool().to(device)\n",
    "        tgt_mask = tgt_mask & nopeak_mask\n",
    "        return src_mask, tgt_mask\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        print(\"forward \",src, src.size())\n",
    "        print(\"forward \", tgt, tgt.size())\n",
    "        src_mask, tgt_mask = self.generate_mask(src, tgt)\n",
    "        src_embedded = self.dropout(self.positional_encoding(self.encoder_embedding(src)))\n",
    "        tgt_embedded = self.dropout(self.positional_encoding(self.decoder_embedding(tgt)))\n",
    "\n",
    "        enc_output = src_embedded\n",
    "        for enc_layer in self.encoder_layers:\n",
    "            enc_output = enc_layer(enc_output, src_mask)\n",
    "\n",
    "        dec_output = tgt_embedded\n",
    "        for dec_layer in self.decoder_layers:\n",
    "            dec_output = dec_layer(dec_output, enc_output, src_mask, tgt_mask)\n",
    "\n",
    "        output = self.fc(dec_output)\n",
    "        #include here FC layers with output dimension = input dimension of the sequence (considering padding this will be const number)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02c976af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src data -  tensor([[4997, 2458, 4492, 1115, 4087,  585,  166, 1738, 2802, 2132, 4155, 1752,\n",
      "         3319, 1808, 2164, 3892, 2211, 4077,  124,  496, 4507, 3476,  243, 1731,\n",
      "         4436, 1811,  688, 4567, 2406, 3653, 4214, 4493, 3415, 1190, 2811, 3307,\n",
      "         3747,  719, 2902,  957,  790, 1785, 3376, 2573, 2196,  796, 2908, 3983,\n",
      "         3066, 4278, 1568, 3313,  382, 1562, 2102, 2977, 3678, 4513, 3177, 2748,\n",
      "         4645,   74,  995,  115,  665, 1085, 1935,   81,  197, 2146, 3998,  213,\n",
      "         2949, 3822, 3782,  963,  501, 2008, 4438,  127, 1518,  273, 1507, 3046,\n",
      "         1969, 3640, 1681, 4060, 3535, 3489, 4450,  291, 3663, 3983, 2578,  207,\n",
      "         2695,  679, 2669, 3045],\n",
      "        [4950, 4331,   94, 3183,  901,   95, 1714, 3563, 3864,  116, 4016, 2356,\n",
      "          550, 3772, 3242, 3960, 2030, 1160,  391,  768, 1374,  827, 4873, 3283,\n",
      "         1994, 3517, 4391, 1187, 2219, 4614,  243, 3782, 2883, 3537, 3169, 2340,\n",
      "         2220,  685, 2114, 2267, 2287,  901, 4808, 1191, 3243, 4473, 4601, 4550,\n",
      "         4885,  268, 4980, 1232, 4556,  738, 4332, 3535, 3195,  176, 1875,  947,\n",
      "         2469,  343, 3723, 4926, 3304, 2108, 1921,  207,  489, 1286,  983, 2509,\n",
      "         1673, 1017, 4924, 3259, 3131, 2174,  936, 2833, 4562, 4357, 2624, 1692,\n",
      "         4067, 4415,  886,  615, 1949, 2686, 3072, 3506, 3925,  155,  446,  848,\n",
      "          425, 3711, 1806, 4930]], device='cuda:0') torch.Size([2, 100])\n",
      "trg data -  tensor([[ 310, 3537,  936, 2845, 1247, 3988, 1072, 1915,  120,  921,  405, 1128,\n",
      "         1054, 1818, 1870,   93,  338,  409, 1702, 3382, 1073, 1102,  572, 3321,\n",
      "           14, 2674,  856, 3750, 3724, 4832, 2651,  325, 2766,  484, 3238,  298,\n",
      "          716, 4581, 1245, 2972, 1239, 3883, 1069, 2070,  276, 2682, 3221, 1493,\n",
      "         2264, 4805, 4444, 2676,  499,  871, 2640, 2655, 1071, 3351, 4671, 2991,\n",
      "         3005, 3769, 1749, 1116, 3518, 4397, 4928, 3746, 2485, 1111, 2266, 1120,\n",
      "         4890, 3331, 2926, 4093,  537, 4586,  382, 2109, 4952, 1315, 4032, 3925,\n",
      "         3847, 3960,  599, 1154, 3053, 3837,   25,  312, 1610, 2772, 2647,  159,\n",
      "         2929, 1537, 2389,  616],\n",
      "        [3939, 2051,  226, 2678, 3565, 4498,  247, 1404, 2418, 4168, 3602,  915,\n",
      "         1803, 1057, 3400,  723, 1285, 3816, 4483, 4443, 2081, 1768, 2909, 1808,\n",
      "         1203, 2983, 2809, 4248, 3424, 4945, 4458, 3580, 2049, 1776,  762, 4802,\n",
      "         3029,  142, 4142, 2025,  375,   56, 2322, 3395, 3992, 2983,  102,  908,\n",
      "          597, 3706, 1353, 4458, 2781, 3812, 2914, 4860, 4213, 2657, 2658,   79,\n",
      "         3704,  490, 4494,  694,   33, 4508, 3726, 4352, 1528, 2188,  503, 3758,\n",
      "         2623, 4628,  743, 4881, 3388, 3242, 3149, 3349,  230,  610, 1953, 4306,\n",
      "         1782, 3675, 4155, 3474, 3534, 4280, 1857, 3153,  432,  996, 4075,  997,\n",
      "         2349, 1377, 4171, 2096]], device='cuda:0') torch.Size([2, 100])\n"
     ]
    }
   ],
   "source": [
    "src_vocab_size = 5000\n",
    "tgt_vocab_size = 5000\n",
    "d_model = 512\n",
    "num_heads = 8\n",
    "num_layers = 6\n",
    "d_ff = 2048\n",
    "max_seq_length = 100\n",
    "dropout = 0.1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Generate random sample data\n",
    "src_data = torch.randint(1, src_vocab_size, (2, max_seq_length)).to(device)  # (batch_size, seq_length)\n",
    "tgt_data = torch.randint(1, tgt_vocab_size, (2, max_seq_length)).to(device)  # (batch_size, seq_length)\n",
    "\n",
    "print(\"src data - \", src_data, src_data.size())\n",
    "print(\"trg data - \", tgt_data, tgt_data.size())\n",
    "transformer = Transformer(src_vocab_size, tgt_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40c439ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src  tensor([[4997, 2458, 4492, 1115, 4087,  585,  166, 1738, 2802, 2132, 4155, 1752,\n",
      "         3319, 1808, 2164, 3892, 2211, 4077,  124,  496, 4507, 3476,  243, 1731,\n",
      "         4436, 1811,  688, 4567, 2406, 3653, 4214, 4493, 3415, 1190, 2811, 3307,\n",
      "         3747,  719, 2902,  957,  790, 1785, 3376, 2573, 2196,  796, 2908, 3983,\n",
      "         3066, 4278, 1568, 3313,  382, 1562, 2102, 2977, 3678, 4513, 3177, 2748,\n",
      "         4645,   74,  995,  115,  665, 1085, 1935,   81,  197, 2146, 3998,  213,\n",
      "         2949, 3822, 3782,  963,  501, 2008, 4438,  127, 1518,  273, 1507, 3046,\n",
      "         1969, 3640, 1681, 4060, 3535, 3489, 4450,  291, 3663, 3983, 2578,  207,\n",
      "         2695,  679, 2669, 3045],\n",
      "        [4950, 4331,   94, 3183,  901,   95, 1714, 3563, 3864,  116, 4016, 2356,\n",
      "          550, 3772, 3242, 3960, 2030, 1160,  391,  768, 1374,  827, 4873, 3283,\n",
      "         1994, 3517, 4391, 1187, 2219, 4614,  243, 3782, 2883, 3537, 3169, 2340,\n",
      "         2220,  685, 2114, 2267, 2287,  901, 4808, 1191, 3243, 4473, 4601, 4550,\n",
      "         4885,  268, 4980, 1232, 4556,  738, 4332, 3535, 3195,  176, 1875,  947,\n",
      "         2469,  343, 3723, 4926, 3304, 2108, 1921,  207,  489, 1286,  983, 2509,\n",
      "         1673, 1017, 4924, 3259, 3131, 2174,  936, 2833, 4562, 4357, 2624, 1692,\n",
      "         4067, 4415,  886,  615, 1949, 2686, 3072, 3506, 3925,  155,  446,  848,\n",
      "          425, 3711, 1806, 4930]], device='cuda:0') torch.Size([2, 100])\n",
      "trg  tensor([[ 310, 3537,  936, 2845, 1247, 3988, 1072, 1915,  120,  921,  405, 1128,\n",
      "         1054, 1818, 1870,   93,  338,  409, 1702, 3382, 1073, 1102,  572, 3321,\n",
      "           14, 2674,  856, 3750, 3724, 4832, 2651,  325, 2766,  484, 3238,  298,\n",
      "          716, 4581, 1245, 2972, 1239, 3883, 1069, 2070,  276, 2682, 3221, 1493,\n",
      "         2264, 4805, 4444, 2676,  499,  871, 2640, 2655, 1071, 3351, 4671, 2991,\n",
      "         3005, 3769, 1749, 1116, 3518, 4397, 4928, 3746, 2485, 1111, 2266, 1120,\n",
      "         4890, 3331, 2926, 4093,  537, 4586,  382, 2109, 4952, 1315, 4032, 3925,\n",
      "         3847, 3960,  599, 1154, 3053, 3837,   25,  312, 1610, 2772, 2647,  159,\n",
      "         2929, 1537, 2389,  616],\n",
      "        [3939, 2051,  226, 2678, 3565, 4498,  247, 1404, 2418, 4168, 3602,  915,\n",
      "         1803, 1057, 3400,  723, 1285, 3816, 4483, 4443, 2081, 1768, 2909, 1808,\n",
      "         1203, 2983, 2809, 4248, 3424, 4945, 4458, 3580, 2049, 1776,  762, 4802,\n",
      "         3029,  142, 4142, 2025,  375,   56, 2322, 3395, 3992, 2983,  102,  908,\n",
      "          597, 3706, 1353, 4458, 2781, 3812, 2914, 4860, 4213, 2657, 2658,   79,\n",
      "         3704,  490, 4494,  694,   33, 4508, 3726, 4352, 1528, 2188,  503, 3758,\n",
      "         2623, 4628,  743, 4881, 3388, 3242, 3149, 3349,  230,  610, 1953, 4306,\n",
      "         1782, 3675, 4155, 3474, 3534, 4280, 1857, 3153,  432,  996, 4075,  997,\n",
      "         2349, 1377, 4171, 2096]], device='cuda:0') torch.Size([2, 100])\n",
      "trg  -1   -- tensor([[ 310, 3537,  936, 2845, 1247, 3988, 1072, 1915,  120,  921,  405, 1128,\n",
      "         1054, 1818, 1870,   93,  338,  409, 1702, 3382, 1073, 1102,  572, 3321,\n",
      "           14, 2674,  856, 3750, 3724, 4832, 2651,  325, 2766,  484, 3238,  298,\n",
      "          716, 4581, 1245, 2972, 1239, 3883, 1069, 2070,  276, 2682, 3221, 1493,\n",
      "         2264, 4805, 4444, 2676,  499,  871, 2640, 2655, 1071, 3351, 4671, 2991,\n",
      "         3005, 3769, 1749, 1116, 3518, 4397, 4928, 3746, 2485, 1111, 2266, 1120,\n",
      "         4890, 3331, 2926, 4093,  537, 4586,  382, 2109, 4952, 1315, 4032, 3925,\n",
      "         3847, 3960,  599, 1154, 3053, 3837,   25,  312, 1610, 2772, 2647,  159,\n",
      "         2929, 1537, 2389],\n",
      "        [3939, 2051,  226, 2678, 3565, 4498,  247, 1404, 2418, 4168, 3602,  915,\n",
      "         1803, 1057, 3400,  723, 1285, 3816, 4483, 4443, 2081, 1768, 2909, 1808,\n",
      "         1203, 2983, 2809, 4248, 3424, 4945, 4458, 3580, 2049, 1776,  762, 4802,\n",
      "         3029,  142, 4142, 2025,  375,   56, 2322, 3395, 3992, 2983,  102,  908,\n",
      "          597, 3706, 1353, 4458, 2781, 3812, 2914, 4860, 4213, 2657, 2658,   79,\n",
      "         3704,  490, 4494,  694,   33, 4508, 3726, 4352, 1528, 2188,  503, 3758,\n",
      "         2623, 4628,  743, 4881, 3388, 3242, 3149, 3349,  230,  610, 1953, 4306,\n",
      "         1782, 3675, 4155, 3474, 3534, 4280, 1857, 3153,  432,  996, 4075,  997,\n",
      "         2349, 1377, 4171]], device='cuda:0') torch.Size([2, 99])\n",
      "forward  tensor([[4997, 2458, 4492, 1115, 4087,  585,  166, 1738, 2802, 2132, 4155, 1752,\n",
      "         3319, 1808, 2164, 3892, 2211, 4077,  124,  496, 4507, 3476,  243, 1731,\n",
      "         4436, 1811,  688, 4567, 2406, 3653, 4214, 4493, 3415, 1190, 2811, 3307,\n",
      "         3747,  719, 2902,  957,  790, 1785, 3376, 2573, 2196,  796, 2908, 3983,\n",
      "         3066, 4278, 1568, 3313,  382, 1562, 2102, 2977, 3678, 4513, 3177, 2748,\n",
      "         4645,   74,  995,  115,  665, 1085, 1935,   81,  197, 2146, 3998,  213,\n",
      "         2949, 3822, 3782,  963,  501, 2008, 4438,  127, 1518,  273, 1507, 3046,\n",
      "         1969, 3640, 1681, 4060, 3535, 3489, 4450,  291, 3663, 3983, 2578,  207,\n",
      "         2695,  679, 2669, 3045],\n",
      "        [4950, 4331,   94, 3183,  901,   95, 1714, 3563, 3864,  116, 4016, 2356,\n",
      "          550, 3772, 3242, 3960, 2030, 1160,  391,  768, 1374,  827, 4873, 3283,\n",
      "         1994, 3517, 4391, 1187, 2219, 4614,  243, 3782, 2883, 3537, 3169, 2340,\n",
      "         2220,  685, 2114, 2267, 2287,  901, 4808, 1191, 3243, 4473, 4601, 4550,\n",
      "         4885,  268, 4980, 1232, 4556,  738, 4332, 3535, 3195,  176, 1875,  947,\n",
      "         2469,  343, 3723, 4926, 3304, 2108, 1921,  207,  489, 1286,  983, 2509,\n",
      "         1673, 1017, 4924, 3259, 3131, 2174,  936, 2833, 4562, 4357, 2624, 1692,\n",
      "         4067, 4415,  886,  615, 1949, 2686, 3072, 3506, 3925,  155,  446,  848,\n",
      "          425, 3711, 1806, 4930]], device='cuda:0') torch.Size([2, 100])\n",
      "forward  tensor([[ 310, 3537,  936, 2845, 1247, 3988, 1072, 1915,  120,  921,  405, 1128,\n",
      "         1054, 1818, 1870,   93,  338,  409, 1702, 3382, 1073, 1102,  572, 3321,\n",
      "           14, 2674,  856, 3750, 3724, 4832, 2651,  325, 2766,  484, 3238,  298,\n",
      "          716, 4581, 1245, 2972, 1239, 3883, 1069, 2070,  276, 2682, 3221, 1493,\n",
      "         2264, 4805, 4444, 2676,  499,  871, 2640, 2655, 1071, 3351, 4671, 2991,\n",
      "         3005, 3769, 1749, 1116, 3518, 4397, 4928, 3746, 2485, 1111, 2266, 1120,\n",
      "         4890, 3331, 2926, 4093,  537, 4586,  382, 2109, 4952, 1315, 4032, 3925,\n",
      "         3847, 3960,  599, 1154, 3053, 3837,   25,  312, 1610, 2772, 2647,  159,\n",
      "         2929, 1537, 2389],\n",
      "        [3939, 2051,  226, 2678, 3565, 4498,  247, 1404, 2418, 4168, 3602,  915,\n",
      "         1803, 1057, 3400,  723, 1285, 3816, 4483, 4443, 2081, 1768, 2909, 1808,\n",
      "         1203, 2983, 2809, 4248, 3424, 4945, 4458, 3580, 2049, 1776,  762, 4802,\n",
      "         3029,  142, 4142, 2025,  375,   56, 2322, 3395, 3992, 2983,  102,  908,\n",
      "          597, 3706, 1353, 4458, 2781, 3812, 2914, 4860, 4213, 2657, 2658,   79,\n",
      "         3704,  490, 4494,  694,   33, 4508, 3726, 4352, 1528, 2188,  503, 3758,\n",
      "         2623, 4628,  743, 4881, 3388, 3242, 3149, 3349,  230,  610, 1953, 4306,\n",
      "         1782, 3675, 4155, 3474, 3534, 4280, 1857, 3153,  432,  996, 4075,  997,\n",
      "         2349, 1377, 4171]], device='cuda:0') torch.Size([2, 99])\n",
      "Epoch: 1, Loss: 8.703269004821777\n",
      "forward  tensor([[4997, 2458, 4492, 1115, 4087,  585,  166, 1738, 2802, 2132, 4155, 1752,\n",
      "         3319, 1808, 2164, 3892, 2211, 4077,  124,  496, 4507, 3476,  243, 1731,\n",
      "         4436, 1811,  688, 4567, 2406, 3653, 4214, 4493, 3415, 1190, 2811, 3307,\n",
      "         3747,  719, 2902,  957,  790, 1785, 3376, 2573, 2196,  796, 2908, 3983,\n",
      "         3066, 4278, 1568, 3313,  382, 1562, 2102, 2977, 3678, 4513, 3177, 2748,\n",
      "         4645,   74,  995,  115,  665, 1085, 1935,   81,  197, 2146, 3998,  213,\n",
      "         2949, 3822, 3782,  963,  501, 2008, 4438,  127, 1518,  273, 1507, 3046,\n",
      "         1969, 3640, 1681, 4060, 3535, 3489, 4450,  291, 3663, 3983, 2578,  207,\n",
      "         2695,  679, 2669, 3045],\n",
      "        [4950, 4331,   94, 3183,  901,   95, 1714, 3563, 3864,  116, 4016, 2356,\n",
      "          550, 3772, 3242, 3960, 2030, 1160,  391,  768, 1374,  827, 4873, 3283,\n",
      "         1994, 3517, 4391, 1187, 2219, 4614,  243, 3782, 2883, 3537, 3169, 2340,\n",
      "         2220,  685, 2114, 2267, 2287,  901, 4808, 1191, 3243, 4473, 4601, 4550,\n",
      "         4885,  268, 4980, 1232, 4556,  738, 4332, 3535, 3195,  176, 1875,  947,\n",
      "         2469,  343, 3723, 4926, 3304, 2108, 1921,  207,  489, 1286,  983, 2509,\n",
      "         1673, 1017, 4924, 3259, 3131, 2174,  936, 2833, 4562, 4357, 2624, 1692,\n",
      "         4067, 4415,  886,  615, 1949, 2686, 3072, 3506, 3925,  155,  446,  848,\n",
      "          425, 3711, 1806, 4930]], device='cuda:0') torch.Size([2, 100])\n",
      "forward  tensor([[ 310, 3537,  936, 2845, 1247, 3988, 1072, 1915,  120,  921,  405, 1128,\n",
      "         1054, 1818, 1870,   93,  338,  409, 1702, 3382, 1073, 1102,  572, 3321,\n",
      "           14, 2674,  856, 3750, 3724, 4832, 2651,  325, 2766,  484, 3238,  298,\n",
      "          716, 4581, 1245, 2972, 1239, 3883, 1069, 2070,  276, 2682, 3221, 1493,\n",
      "         2264, 4805, 4444, 2676,  499,  871, 2640, 2655, 1071, 3351, 4671, 2991,\n",
      "         3005, 3769, 1749, 1116, 3518, 4397, 4928, 3746, 2485, 1111, 2266, 1120,\n",
      "         4890, 3331, 2926, 4093,  537, 4586,  382, 2109, 4952, 1315, 4032, 3925,\n",
      "         3847, 3960,  599, 1154, 3053, 3837,   25,  312, 1610, 2772, 2647,  159,\n",
      "         2929, 1537, 2389],\n",
      "        [3939, 2051,  226, 2678, 3565, 4498,  247, 1404, 2418, 4168, 3602,  915,\n",
      "         1803, 1057, 3400,  723, 1285, 3816, 4483, 4443, 2081, 1768, 2909, 1808,\n",
      "         1203, 2983, 2809, 4248, 3424, 4945, 4458, 3580, 2049, 1776,  762, 4802,\n",
      "         3029,  142, 4142, 2025,  375,   56, 2322, 3395, 3992, 2983,  102,  908,\n",
      "          597, 3706, 1353, 4458, 2781, 3812, 2914, 4860, 4213, 2657, 2658,   79,\n",
      "         3704,  490, 4494,  694,   33, 4508, 3726, 4352, 1528, 2188,  503, 3758,\n",
      "         2623, 4628,  743, 4881, 3388, 3242, 3149, 3349,  230,  610, 1953, 4306,\n",
      "         1782, 3675, 4155, 3474, 3534, 4280, 1857, 3153,  432,  996, 4075,  997,\n",
      "         2349, 1377, 4171]], device='cuda:0') torch.Size([2, 99])\n",
      "Epoch: 1, Loss: 8.006426811218262\n",
      "src  tensor([[4997, 2458, 4492, 1115, 4087,  585,  166, 1738, 2802, 2132, 4155, 1752,\n",
      "         3319, 1808, 2164, 3892, 2211, 4077,  124,  496, 4507, 3476,  243, 1731,\n",
      "         4436, 1811,  688, 4567, 2406, 3653, 4214, 4493, 3415, 1190, 2811, 3307,\n",
      "         3747,  719, 2902,  957,  790, 1785, 3376, 2573, 2196,  796, 2908, 3983,\n",
      "         3066, 4278, 1568, 3313,  382, 1562, 2102, 2977, 3678, 4513, 3177, 2748,\n",
      "         4645,   74,  995,  115,  665, 1085, 1935,   81,  197, 2146, 3998,  213,\n",
      "         2949, 3822, 3782,  963,  501, 2008, 4438,  127, 1518,  273, 1507, 3046,\n",
      "         1969, 3640, 1681, 4060, 3535, 3489, 4450,  291, 3663, 3983, 2578,  207,\n",
      "         2695,  679, 2669, 3045],\n",
      "        [4950, 4331,   94, 3183,  901,   95, 1714, 3563, 3864,  116, 4016, 2356,\n",
      "          550, 3772, 3242, 3960, 2030, 1160,  391,  768, 1374,  827, 4873, 3283,\n",
      "         1994, 3517, 4391, 1187, 2219, 4614,  243, 3782, 2883, 3537, 3169, 2340,\n",
      "         2220,  685, 2114, 2267, 2287,  901, 4808, 1191, 3243, 4473, 4601, 4550,\n",
      "         4885,  268, 4980, 1232, 4556,  738, 4332, 3535, 3195,  176, 1875,  947,\n",
      "         2469,  343, 3723, 4926, 3304, 2108, 1921,  207,  489, 1286,  983, 2509,\n",
      "         1673, 1017, 4924, 3259, 3131, 2174,  936, 2833, 4562, 4357, 2624, 1692,\n",
      "         4067, 4415,  886,  615, 1949, 2686, 3072, 3506, 3925,  155,  446,  848,\n",
      "          425, 3711, 1806, 4930]], device='cuda:0') torch.Size([2, 100])\n",
      "trg  tensor([[ 310, 3537,  936, 2845, 1247, 3988, 1072, 1915,  120,  921,  405, 1128,\n",
      "         1054, 1818, 1870,   93,  338,  409, 1702, 3382, 1073, 1102,  572, 3321,\n",
      "           14, 2674,  856, 3750, 3724, 4832, 2651,  325, 2766,  484, 3238,  298,\n",
      "          716, 4581, 1245, 2972, 1239, 3883, 1069, 2070,  276, 2682, 3221, 1493,\n",
      "         2264, 4805, 4444, 2676,  499,  871, 2640, 2655, 1071, 3351, 4671, 2991,\n",
      "         3005, 3769, 1749, 1116, 3518, 4397, 4928, 3746, 2485, 1111, 2266, 1120,\n",
      "         4890, 3331, 2926, 4093,  537, 4586,  382, 2109, 4952, 1315, 4032, 3925,\n",
      "         3847, 3960,  599, 1154, 3053, 3837,   25,  312, 1610, 2772, 2647,  159,\n",
      "         2929, 1537, 2389,  616],\n",
      "        [3939, 2051,  226, 2678, 3565, 4498,  247, 1404, 2418, 4168, 3602,  915,\n",
      "         1803, 1057, 3400,  723, 1285, 3816, 4483, 4443, 2081, 1768, 2909, 1808,\n",
      "         1203, 2983, 2809, 4248, 3424, 4945, 4458, 3580, 2049, 1776,  762, 4802,\n",
      "         3029,  142, 4142, 2025,  375,   56, 2322, 3395, 3992, 2983,  102,  908,\n",
      "          597, 3706, 1353, 4458, 2781, 3812, 2914, 4860, 4213, 2657, 2658,   79,\n",
      "         3704,  490, 4494,  694,   33, 4508, 3726, 4352, 1528, 2188,  503, 3758,\n",
      "         2623, 4628,  743, 4881, 3388, 3242, 3149, 3349,  230,  610, 1953, 4306,\n",
      "         1782, 3675, 4155, 3474, 3534, 4280, 1857, 3153,  432,  996, 4075,  997,\n",
      "         2349, 1377, 4171, 2096]], device='cuda:0') torch.Size([2, 100])\n",
      "trg  -1   -- tensor([[ 310, 3537,  936, 2845, 1247, 3988, 1072, 1915,  120,  921,  405, 1128,\n",
      "         1054, 1818, 1870,   93,  338,  409, 1702, 3382, 1073, 1102,  572, 3321,\n",
      "           14, 2674,  856, 3750, 3724, 4832, 2651,  325, 2766,  484, 3238,  298,\n",
      "          716, 4581, 1245, 2972, 1239, 3883, 1069, 2070,  276, 2682, 3221, 1493,\n",
      "         2264, 4805, 4444, 2676,  499,  871, 2640, 2655, 1071, 3351, 4671, 2991,\n",
      "         3005, 3769, 1749, 1116, 3518, 4397, 4928, 3746, 2485, 1111, 2266, 1120,\n",
      "         4890, 3331, 2926, 4093,  537, 4586,  382, 2109, 4952, 1315, 4032, 3925,\n",
      "         3847, 3960,  599, 1154, 3053, 3837,   25,  312, 1610, 2772, 2647,  159,\n",
      "         2929, 1537, 2389],\n",
      "        [3939, 2051,  226, 2678, 3565, 4498,  247, 1404, 2418, 4168, 3602,  915,\n",
      "         1803, 1057, 3400,  723, 1285, 3816, 4483, 4443, 2081, 1768, 2909, 1808,\n",
      "         1203, 2983, 2809, 4248, 3424, 4945, 4458, 3580, 2049, 1776,  762, 4802,\n",
      "         3029,  142, 4142, 2025,  375,   56, 2322, 3395, 3992, 2983,  102,  908,\n",
      "          597, 3706, 1353, 4458, 2781, 3812, 2914, 4860, 4213, 2657, 2658,   79,\n",
      "         3704,  490, 4494,  694,   33, 4508, 3726, 4352, 1528, 2188,  503, 3758,\n",
      "         2623, 4628,  743, 4881, 3388, 3242, 3149, 3349,  230,  610, 1953, 4306,\n",
      "         1782, 3675, 4155, 3474, 3534, 4280, 1857, 3153,  432,  996, 4075,  997,\n",
      "         2349, 1377, 4171]], device='cuda:0') torch.Size([2, 99])\n",
      "forward  tensor([[4997, 2458, 4492, 1115, 4087,  585,  166, 1738, 2802, 2132, 4155, 1752,\n",
      "         3319, 1808, 2164, 3892, 2211, 4077,  124,  496, 4507, 3476,  243, 1731,\n",
      "         4436, 1811,  688, 4567, 2406, 3653, 4214, 4493, 3415, 1190, 2811, 3307,\n",
      "         3747,  719, 2902,  957,  790, 1785, 3376, 2573, 2196,  796, 2908, 3983,\n",
      "         3066, 4278, 1568, 3313,  382, 1562, 2102, 2977, 3678, 4513, 3177, 2748,\n",
      "         4645,   74,  995,  115,  665, 1085, 1935,   81,  197, 2146, 3998,  213,\n",
      "         2949, 3822, 3782,  963,  501, 2008, 4438,  127, 1518,  273, 1507, 3046,\n",
      "         1969, 3640, 1681, 4060, 3535, 3489, 4450,  291, 3663, 3983, 2578,  207,\n",
      "         2695,  679, 2669, 3045],\n",
      "        [4950, 4331,   94, 3183,  901,   95, 1714, 3563, 3864,  116, 4016, 2356,\n",
      "          550, 3772, 3242, 3960, 2030, 1160,  391,  768, 1374,  827, 4873, 3283,\n",
      "         1994, 3517, 4391, 1187, 2219, 4614,  243, 3782, 2883, 3537, 3169, 2340,\n",
      "         2220,  685, 2114, 2267, 2287,  901, 4808, 1191, 3243, 4473, 4601, 4550,\n",
      "         4885,  268, 4980, 1232, 4556,  738, 4332, 3535, 3195,  176, 1875,  947,\n",
      "         2469,  343, 3723, 4926, 3304, 2108, 1921,  207,  489, 1286,  983, 2509,\n",
      "         1673, 1017, 4924, 3259, 3131, 2174,  936, 2833, 4562, 4357, 2624, 1692,\n",
      "         4067, 4415,  886,  615, 1949, 2686, 3072, 3506, 3925,  155,  446,  848,\n",
      "          425, 3711, 1806, 4930]], device='cuda:0') torch.Size([2, 100])\n",
      "forward  tensor([[ 310, 3537,  936, 2845, 1247, 3988, 1072, 1915,  120,  921,  405, 1128,\n",
      "         1054, 1818, 1870,   93,  338,  409, 1702, 3382, 1073, 1102,  572, 3321,\n",
      "           14, 2674,  856, 3750, 3724, 4832, 2651,  325, 2766,  484, 3238,  298,\n",
      "          716, 4581, 1245, 2972, 1239, 3883, 1069, 2070,  276, 2682, 3221, 1493,\n",
      "         2264, 4805, 4444, 2676,  499,  871, 2640, 2655, 1071, 3351, 4671, 2991,\n",
      "         3005, 3769, 1749, 1116, 3518, 4397, 4928, 3746, 2485, 1111, 2266, 1120,\n",
      "         4890, 3331, 2926, 4093,  537, 4586,  382, 2109, 4952, 1315, 4032, 3925,\n",
      "         3847, 3960,  599, 1154, 3053, 3837,   25,  312, 1610, 2772, 2647,  159,\n",
      "         2929, 1537, 2389],\n",
      "        [3939, 2051,  226, 2678, 3565, 4498,  247, 1404, 2418, 4168, 3602,  915,\n",
      "         1803, 1057, 3400,  723, 1285, 3816, 4483, 4443, 2081, 1768, 2909, 1808,\n",
      "         1203, 2983, 2809, 4248, 3424, 4945, 4458, 3580, 2049, 1776,  762, 4802,\n",
      "         3029,  142, 4142, 2025,  375,   56, 2322, 3395, 3992, 2983,  102,  908,\n",
      "          597, 3706, 1353, 4458, 2781, 3812, 2914, 4860, 4213, 2657, 2658,   79,\n",
      "         3704,  490, 4494,  694,   33, 4508, 3726, 4352, 1528, 2188,  503, 3758,\n",
      "         2623, 4628,  743, 4881, 3388, 3242, 3149, 3349,  230,  610, 1953, 4306,\n",
      "         1782, 3675, 4155, 3474, 3534, 4280, 1857, 3153,  432,  996, 4075,  997,\n",
      "         2349, 1377, 4171]], device='cuda:0') torch.Size([2, 99])\n",
      "Epoch: 2, Loss: 8.067545890808105\n",
      "forward  tensor([[4997, 2458, 4492, 1115, 4087,  585,  166, 1738, 2802, 2132, 4155, 1752,\n",
      "         3319, 1808, 2164, 3892, 2211, 4077,  124,  496, 4507, 3476,  243, 1731,\n",
      "         4436, 1811,  688, 4567, 2406, 3653, 4214, 4493, 3415, 1190, 2811, 3307,\n",
      "         3747,  719, 2902,  957,  790, 1785, 3376, 2573, 2196,  796, 2908, 3983,\n",
      "         3066, 4278, 1568, 3313,  382, 1562, 2102, 2977, 3678, 4513, 3177, 2748,\n",
      "         4645,   74,  995,  115,  665, 1085, 1935,   81,  197, 2146, 3998,  213,\n",
      "         2949, 3822, 3782,  963,  501, 2008, 4438,  127, 1518,  273, 1507, 3046,\n",
      "         1969, 3640, 1681, 4060, 3535, 3489, 4450,  291, 3663, 3983, 2578,  207,\n",
      "         2695,  679, 2669, 3045],\n",
      "        [4950, 4331,   94, 3183,  901,   95, 1714, 3563, 3864,  116, 4016, 2356,\n",
      "          550, 3772, 3242, 3960, 2030, 1160,  391,  768, 1374,  827, 4873, 3283,\n",
      "         1994, 3517, 4391, 1187, 2219, 4614,  243, 3782, 2883, 3537, 3169, 2340,\n",
      "         2220,  685, 2114, 2267, 2287,  901, 4808, 1191, 3243, 4473, 4601, 4550,\n",
      "         4885,  268, 4980, 1232, 4556,  738, 4332, 3535, 3195,  176, 1875,  947,\n",
      "         2469,  343, 3723, 4926, 3304, 2108, 1921,  207,  489, 1286,  983, 2509,\n",
      "         1673, 1017, 4924, 3259, 3131, 2174,  936, 2833, 4562, 4357, 2624, 1692,\n",
      "         4067, 4415,  886,  615, 1949, 2686, 3072, 3506, 3925,  155,  446,  848,\n",
      "          425, 3711, 1806, 4930]], device='cuda:0') torch.Size([2, 100])\n",
      "forward  tensor([[ 310, 3537,  936, 2845, 1247, 3988, 1072, 1915,  120,  921,  405, 1128,\n",
      "         1054, 1818, 1870,   93,  338,  409, 1702, 3382, 1073, 1102,  572, 3321,\n",
      "           14, 2674,  856, 3750, 3724, 4832, 2651,  325, 2766,  484, 3238,  298,\n",
      "          716, 4581, 1245, 2972, 1239, 3883, 1069, 2070,  276, 2682, 3221, 1493,\n",
      "         2264, 4805, 4444, 2676,  499,  871, 2640, 2655, 1071, 3351, 4671, 2991,\n",
      "         3005, 3769, 1749, 1116, 3518, 4397, 4928, 3746, 2485, 1111, 2266, 1120,\n",
      "         4890, 3331, 2926, 4093,  537, 4586,  382, 2109, 4952, 1315, 4032, 3925,\n",
      "         3847, 3960,  599, 1154, 3053, 3837,   25,  312, 1610, 2772, 2647,  159,\n",
      "         2929, 1537, 2389],\n",
      "        [3939, 2051,  226, 2678, 3565, 4498,  247, 1404, 2418, 4168, 3602,  915,\n",
      "         1803, 1057, 3400,  723, 1285, 3816, 4483, 4443, 2081, 1768, 2909, 1808,\n",
      "         1203, 2983, 2809, 4248, 3424, 4945, 4458, 3580, 2049, 1776,  762, 4802,\n",
      "         3029,  142, 4142, 2025,  375,   56, 2322, 3395, 3992, 2983,  102,  908,\n",
      "          597, 3706, 1353, 4458, 2781, 3812, 2914, 4860, 4213, 2657, 2658,   79,\n",
      "         3704,  490, 4494,  694,   33, 4508, 3726, 4352, 1528, 2188,  503, 3758,\n",
      "         2623, 4628,  743, 4881, 3388, 3242, 3149, 3349,  230,  610, 1953, 4306,\n",
      "         1782, 3675, 4155, 3474, 3534, 4280, 1857, 3153,  432,  996, 4075,  997,\n",
      "         2349, 1377, 4171]], device='cuda:0') torch.Size([2, 99])\n",
      "Epoch: 2, Loss: 7.660370349884033\n",
      "src  tensor([[4997, 2458, 4492, 1115, 4087,  585,  166, 1738, 2802, 2132, 4155, 1752,\n",
      "         3319, 1808, 2164, 3892, 2211, 4077,  124,  496, 4507, 3476,  243, 1731,\n",
      "         4436, 1811,  688, 4567, 2406, 3653, 4214, 4493, 3415, 1190, 2811, 3307,\n",
      "         3747,  719, 2902,  957,  790, 1785, 3376, 2573, 2196,  796, 2908, 3983,\n",
      "         3066, 4278, 1568, 3313,  382, 1562, 2102, 2977, 3678, 4513, 3177, 2748,\n",
      "         4645,   74,  995,  115,  665, 1085, 1935,   81,  197, 2146, 3998,  213,\n",
      "         2949, 3822, 3782,  963,  501, 2008, 4438,  127, 1518,  273, 1507, 3046,\n",
      "         1969, 3640, 1681, 4060, 3535, 3489, 4450,  291, 3663, 3983, 2578,  207,\n",
      "         2695,  679, 2669, 3045],\n",
      "        [4950, 4331,   94, 3183,  901,   95, 1714, 3563, 3864,  116, 4016, 2356,\n",
      "          550, 3772, 3242, 3960, 2030, 1160,  391,  768, 1374,  827, 4873, 3283,\n",
      "         1994, 3517, 4391, 1187, 2219, 4614,  243, 3782, 2883, 3537, 3169, 2340,\n",
      "         2220,  685, 2114, 2267, 2287,  901, 4808, 1191, 3243, 4473, 4601, 4550,\n",
      "         4885,  268, 4980, 1232, 4556,  738, 4332, 3535, 3195,  176, 1875,  947,\n",
      "         2469,  343, 3723, 4926, 3304, 2108, 1921,  207,  489, 1286,  983, 2509,\n",
      "         1673, 1017, 4924, 3259, 3131, 2174,  936, 2833, 4562, 4357, 2624, 1692,\n",
      "         4067, 4415,  886,  615, 1949, 2686, 3072, 3506, 3925,  155,  446,  848,\n",
      "          425, 3711, 1806, 4930]], device='cuda:0') torch.Size([2, 100])\n",
      "trg  tensor([[ 310, 3537,  936, 2845, 1247, 3988, 1072, 1915,  120,  921,  405, 1128,\n",
      "         1054, 1818, 1870,   93,  338,  409, 1702, 3382, 1073, 1102,  572, 3321,\n",
      "           14, 2674,  856, 3750, 3724, 4832, 2651,  325, 2766,  484, 3238,  298,\n",
      "          716, 4581, 1245, 2972, 1239, 3883, 1069, 2070,  276, 2682, 3221, 1493,\n",
      "         2264, 4805, 4444, 2676,  499,  871, 2640, 2655, 1071, 3351, 4671, 2991,\n",
      "         3005, 3769, 1749, 1116, 3518, 4397, 4928, 3746, 2485, 1111, 2266, 1120,\n",
      "         4890, 3331, 2926, 4093,  537, 4586,  382, 2109, 4952, 1315, 4032, 3925,\n",
      "         3847, 3960,  599, 1154, 3053, 3837,   25,  312, 1610, 2772, 2647,  159,\n",
      "         2929, 1537, 2389,  616],\n",
      "        [3939, 2051,  226, 2678, 3565, 4498,  247, 1404, 2418, 4168, 3602,  915,\n",
      "         1803, 1057, 3400,  723, 1285, 3816, 4483, 4443, 2081, 1768, 2909, 1808,\n",
      "         1203, 2983, 2809, 4248, 3424, 4945, 4458, 3580, 2049, 1776,  762, 4802,\n",
      "         3029,  142, 4142, 2025,  375,   56, 2322, 3395, 3992, 2983,  102,  908,\n",
      "          597, 3706, 1353, 4458, 2781, 3812, 2914, 4860, 4213, 2657, 2658,   79,\n",
      "         3704,  490, 4494,  694,   33, 4508, 3726, 4352, 1528, 2188,  503, 3758,\n",
      "         2623, 4628,  743, 4881, 3388, 3242, 3149, 3349,  230,  610, 1953, 4306,\n",
      "         1782, 3675, 4155, 3474, 3534, 4280, 1857, 3153,  432,  996, 4075,  997,\n",
      "         2349, 1377, 4171, 2096]], device='cuda:0') torch.Size([2, 100])\n",
      "trg  -1   -- tensor([[ 310, 3537,  936, 2845, 1247, 3988, 1072, 1915,  120,  921,  405, 1128,\n",
      "         1054, 1818, 1870,   93,  338,  409, 1702, 3382, 1073, 1102,  572, 3321,\n",
      "           14, 2674,  856, 3750, 3724, 4832, 2651,  325, 2766,  484, 3238,  298,\n",
      "          716, 4581, 1245, 2972, 1239, 3883, 1069, 2070,  276, 2682, 3221, 1493,\n",
      "         2264, 4805, 4444, 2676,  499,  871, 2640, 2655, 1071, 3351, 4671, 2991,\n",
      "         3005, 3769, 1749, 1116, 3518, 4397, 4928, 3746, 2485, 1111, 2266, 1120,\n",
      "         4890, 3331, 2926, 4093,  537, 4586,  382, 2109, 4952, 1315, 4032, 3925,\n",
      "         3847, 3960,  599, 1154, 3053, 3837,   25,  312, 1610, 2772, 2647,  159,\n",
      "         2929, 1537, 2389],\n",
      "        [3939, 2051,  226, 2678, 3565, 4498,  247, 1404, 2418, 4168, 3602,  915,\n",
      "         1803, 1057, 3400,  723, 1285, 3816, 4483, 4443, 2081, 1768, 2909, 1808,\n",
      "         1203, 2983, 2809, 4248, 3424, 4945, 4458, 3580, 2049, 1776,  762, 4802,\n",
      "         3029,  142, 4142, 2025,  375,   56, 2322, 3395, 3992, 2983,  102,  908,\n",
      "          597, 3706, 1353, 4458, 2781, 3812, 2914, 4860, 4213, 2657, 2658,   79,\n",
      "         3704,  490, 4494,  694,   33, 4508, 3726, 4352, 1528, 2188,  503, 3758,\n",
      "         2623, 4628,  743, 4881, 3388, 3242, 3149, 3349,  230,  610, 1953, 4306,\n",
      "         1782, 3675, 4155, 3474, 3534, 4280, 1857, 3153,  432,  996, 4075,  997,\n",
      "         2349, 1377, 4171]], device='cuda:0') torch.Size([2, 99])\n",
      "forward  tensor([[4997, 2458, 4492, 1115, 4087,  585,  166, 1738, 2802, 2132, 4155, 1752,\n",
      "         3319, 1808, 2164, 3892, 2211, 4077,  124,  496, 4507, 3476,  243, 1731,\n",
      "         4436, 1811,  688, 4567, 2406, 3653, 4214, 4493, 3415, 1190, 2811, 3307,\n",
      "         3747,  719, 2902,  957,  790, 1785, 3376, 2573, 2196,  796, 2908, 3983,\n",
      "         3066, 4278, 1568, 3313,  382, 1562, 2102, 2977, 3678, 4513, 3177, 2748,\n",
      "         4645,   74,  995,  115,  665, 1085, 1935,   81,  197, 2146, 3998,  213,\n",
      "         2949, 3822, 3782,  963,  501, 2008, 4438,  127, 1518,  273, 1507, 3046,\n",
      "         1969, 3640, 1681, 4060, 3535, 3489, 4450,  291, 3663, 3983, 2578,  207,\n",
      "         2695,  679, 2669, 3045],\n",
      "        [4950, 4331,   94, 3183,  901,   95, 1714, 3563, 3864,  116, 4016, 2356,\n",
      "          550, 3772, 3242, 3960, 2030, 1160,  391,  768, 1374,  827, 4873, 3283,\n",
      "         1994, 3517, 4391, 1187, 2219, 4614,  243, 3782, 2883, 3537, 3169, 2340,\n",
      "         2220,  685, 2114, 2267, 2287,  901, 4808, 1191, 3243, 4473, 4601, 4550,\n",
      "         4885,  268, 4980, 1232, 4556,  738, 4332, 3535, 3195,  176, 1875,  947,\n",
      "         2469,  343, 3723, 4926, 3304, 2108, 1921,  207,  489, 1286,  983, 2509,\n",
      "         1673, 1017, 4924, 3259, 3131, 2174,  936, 2833, 4562, 4357, 2624, 1692,\n",
      "         4067, 4415,  886,  615, 1949, 2686, 3072, 3506, 3925,  155,  446,  848,\n",
      "          425, 3711, 1806, 4930]], device='cuda:0') torch.Size([2, 100])\n",
      "forward  tensor([[ 310, 3537,  936, 2845, 1247, 3988, 1072, 1915,  120,  921,  405, 1128,\n",
      "         1054, 1818, 1870,   93,  338,  409, 1702, 3382, 1073, 1102,  572, 3321,\n",
      "           14, 2674,  856, 3750, 3724, 4832, 2651,  325, 2766,  484, 3238,  298,\n",
      "          716, 4581, 1245, 2972, 1239, 3883, 1069, 2070,  276, 2682, 3221, 1493,\n",
      "         2264, 4805, 4444, 2676,  499,  871, 2640, 2655, 1071, 3351, 4671, 2991,\n",
      "         3005, 3769, 1749, 1116, 3518, 4397, 4928, 3746, 2485, 1111, 2266, 1120,\n",
      "         4890, 3331, 2926, 4093,  537, 4586,  382, 2109, 4952, 1315, 4032, 3925,\n",
      "         3847, 3960,  599, 1154, 3053, 3837,   25,  312, 1610, 2772, 2647,  159,\n",
      "         2929, 1537, 2389],\n",
      "        [3939, 2051,  226, 2678, 3565, 4498,  247, 1404, 2418, 4168, 3602,  915,\n",
      "         1803, 1057, 3400,  723, 1285, 3816, 4483, 4443, 2081, 1768, 2909, 1808,\n",
      "         1203, 2983, 2809, 4248, 3424, 4945, 4458, 3580, 2049, 1776,  762, 4802,\n",
      "         3029,  142, 4142, 2025,  375,   56, 2322, 3395, 3992, 2983,  102,  908,\n",
      "          597, 3706, 1353, 4458, 2781, 3812, 2914, 4860, 4213, 2657, 2658,   79,\n",
      "         3704,  490, 4494,  694,   33, 4508, 3726, 4352, 1528, 2188,  503, 3758,\n",
      "         2623, 4628,  743, 4881, 3388, 3242, 3149, 3349,  230,  610, 1953, 4306,\n",
      "         1782, 3675, 4155, 3474, 3534, 4280, 1857, 3153,  432,  996, 4075,  997,\n",
      "         2349, 1377, 4171]], device='cuda:0') torch.Size([2, 99])\n",
      "Epoch: 3, Loss: 7.744290828704834\n",
      "forward  tensor([[4997, 2458, 4492, 1115, 4087,  585,  166, 1738, 2802, 2132, 4155, 1752,\n",
      "         3319, 1808, 2164, 3892, 2211, 4077,  124,  496, 4507, 3476,  243, 1731,\n",
      "         4436, 1811,  688, 4567, 2406, 3653, 4214, 4493, 3415, 1190, 2811, 3307,\n",
      "         3747,  719, 2902,  957,  790, 1785, 3376, 2573, 2196,  796, 2908, 3983,\n",
      "         3066, 4278, 1568, 3313,  382, 1562, 2102, 2977, 3678, 4513, 3177, 2748,\n",
      "         4645,   74,  995,  115,  665, 1085, 1935,   81,  197, 2146, 3998,  213,\n",
      "         2949, 3822, 3782,  963,  501, 2008, 4438,  127, 1518,  273, 1507, 3046,\n",
      "         1969, 3640, 1681, 4060, 3535, 3489, 4450,  291, 3663, 3983, 2578,  207,\n",
      "         2695,  679, 2669, 3045],\n",
      "        [4950, 4331,   94, 3183,  901,   95, 1714, 3563, 3864,  116, 4016, 2356,\n",
      "          550, 3772, 3242, 3960, 2030, 1160,  391,  768, 1374,  827, 4873, 3283,\n",
      "         1994, 3517, 4391, 1187, 2219, 4614,  243, 3782, 2883, 3537, 3169, 2340,\n",
      "         2220,  685, 2114, 2267, 2287,  901, 4808, 1191, 3243, 4473, 4601, 4550,\n",
      "         4885,  268, 4980, 1232, 4556,  738, 4332, 3535, 3195,  176, 1875,  947,\n",
      "         2469,  343, 3723, 4926, 3304, 2108, 1921,  207,  489, 1286,  983, 2509,\n",
      "         1673, 1017, 4924, 3259, 3131, 2174,  936, 2833, 4562, 4357, 2624, 1692,\n",
      "         4067, 4415,  886,  615, 1949, 2686, 3072, 3506, 3925,  155,  446,  848,\n",
      "          425, 3711, 1806, 4930]], device='cuda:0') torch.Size([2, 100])\n",
      "forward  tensor([[ 310, 3537,  936, 2845, 1247, 3988, 1072, 1915,  120,  921,  405, 1128,\n",
      "         1054, 1818, 1870,   93,  338,  409, 1702, 3382, 1073, 1102,  572, 3321,\n",
      "           14, 2674,  856, 3750, 3724, 4832, 2651,  325, 2766,  484, 3238,  298,\n",
      "          716, 4581, 1245, 2972, 1239, 3883, 1069, 2070,  276, 2682, 3221, 1493,\n",
      "         2264, 4805, 4444, 2676,  499,  871, 2640, 2655, 1071, 3351, 4671, 2991,\n",
      "         3005, 3769, 1749, 1116, 3518, 4397, 4928, 3746, 2485, 1111, 2266, 1120,\n",
      "         4890, 3331, 2926, 4093,  537, 4586,  382, 2109, 4952, 1315, 4032, 3925,\n",
      "         3847, 3960,  599, 1154, 3053, 3837,   25,  312, 1610, 2772, 2647,  159,\n",
      "         2929, 1537, 2389],\n",
      "        [3939, 2051,  226, 2678, 3565, 4498,  247, 1404, 2418, 4168, 3602,  915,\n",
      "         1803, 1057, 3400,  723, 1285, 3816, 4483, 4443, 2081, 1768, 2909, 1808,\n",
      "         1203, 2983, 2809, 4248, 3424, 4945, 4458, 3580, 2049, 1776,  762, 4802,\n",
      "         3029,  142, 4142, 2025,  375,   56, 2322, 3395, 3992, 2983,  102,  908,\n",
      "          597, 3706, 1353, 4458, 2781, 3812, 2914, 4860, 4213, 2657, 2658,   79,\n",
      "         3704,  490, 4494,  694,   33, 4508, 3726, 4352, 1528, 2188,  503, 3758,\n",
      "         2623, 4628,  743, 4881, 3388, 3242, 3149, 3349,  230,  610, 1953, 4306,\n",
      "         1782, 3675, 4155, 3474, 3534, 4280, 1857, 3153,  432,  996, 4075,  997,\n",
      "         2349, 1377, 4171]], device='cuda:0') torch.Size([2, 99])\n",
      "Epoch: 3, Loss: 7.4186930656433105\n",
      "src  tensor([[4997, 2458, 4492, 1115, 4087,  585,  166, 1738, 2802, 2132, 4155, 1752,\n",
      "         3319, 1808, 2164, 3892, 2211, 4077,  124,  496, 4507, 3476,  243, 1731,\n",
      "         4436, 1811,  688, 4567, 2406, 3653, 4214, 4493, 3415, 1190, 2811, 3307,\n",
      "         3747,  719, 2902,  957,  790, 1785, 3376, 2573, 2196,  796, 2908, 3983,\n",
      "         3066, 4278, 1568, 3313,  382, 1562, 2102, 2977, 3678, 4513, 3177, 2748,\n",
      "         4645,   74,  995,  115,  665, 1085, 1935,   81,  197, 2146, 3998,  213,\n",
      "         2949, 3822, 3782,  963,  501, 2008, 4438,  127, 1518,  273, 1507, 3046,\n",
      "         1969, 3640, 1681, 4060, 3535, 3489, 4450,  291, 3663, 3983, 2578,  207,\n",
      "         2695,  679, 2669, 3045],\n",
      "        [4950, 4331,   94, 3183,  901,   95, 1714, 3563, 3864,  116, 4016, 2356,\n",
      "          550, 3772, 3242, 3960, 2030, 1160,  391,  768, 1374,  827, 4873, 3283,\n",
      "         1994, 3517, 4391, 1187, 2219, 4614,  243, 3782, 2883, 3537, 3169, 2340,\n",
      "         2220,  685, 2114, 2267, 2287,  901, 4808, 1191, 3243, 4473, 4601, 4550,\n",
      "         4885,  268, 4980, 1232, 4556,  738, 4332, 3535, 3195,  176, 1875,  947,\n",
      "         2469,  343, 3723, 4926, 3304, 2108, 1921,  207,  489, 1286,  983, 2509,\n",
      "         1673, 1017, 4924, 3259, 3131, 2174,  936, 2833, 4562, 4357, 2624, 1692,\n",
      "         4067, 4415,  886,  615, 1949, 2686, 3072, 3506, 3925,  155,  446,  848,\n",
      "          425, 3711, 1806, 4930]], device='cuda:0') torch.Size([2, 100])\n",
      "trg  tensor([[ 310, 3537,  936, 2845, 1247, 3988, 1072, 1915,  120,  921,  405, 1128,\n",
      "         1054, 1818, 1870,   93,  338,  409, 1702, 3382, 1073, 1102,  572, 3321,\n",
      "           14, 2674,  856, 3750, 3724, 4832, 2651,  325, 2766,  484, 3238,  298,\n",
      "          716, 4581, 1245, 2972, 1239, 3883, 1069, 2070,  276, 2682, 3221, 1493,\n",
      "         2264, 4805, 4444, 2676,  499,  871, 2640, 2655, 1071, 3351, 4671, 2991,\n",
      "         3005, 3769, 1749, 1116, 3518, 4397, 4928, 3746, 2485, 1111, 2266, 1120,\n",
      "         4890, 3331, 2926, 4093,  537, 4586,  382, 2109, 4952, 1315, 4032, 3925,\n",
      "         3847, 3960,  599, 1154, 3053, 3837,   25,  312, 1610, 2772, 2647,  159,\n",
      "         2929, 1537, 2389,  616],\n",
      "        [3939, 2051,  226, 2678, 3565, 4498,  247, 1404, 2418, 4168, 3602,  915,\n",
      "         1803, 1057, 3400,  723, 1285, 3816, 4483, 4443, 2081, 1768, 2909, 1808,\n",
      "         1203, 2983, 2809, 4248, 3424, 4945, 4458, 3580, 2049, 1776,  762, 4802,\n",
      "         3029,  142, 4142, 2025,  375,   56, 2322, 3395, 3992, 2983,  102,  908,\n",
      "          597, 3706, 1353, 4458, 2781, 3812, 2914, 4860, 4213, 2657, 2658,   79,\n",
      "         3704,  490, 4494,  694,   33, 4508, 3726, 4352, 1528, 2188,  503, 3758,\n",
      "         2623, 4628,  743, 4881, 3388, 3242, 3149, 3349,  230,  610, 1953, 4306,\n",
      "         1782, 3675, 4155, 3474, 3534, 4280, 1857, 3153,  432,  996, 4075,  997,\n",
      "         2349, 1377, 4171, 2096]], device='cuda:0') torch.Size([2, 100])\n",
      "trg  -1   -- tensor([[ 310, 3537,  936, 2845, 1247, 3988, 1072, 1915,  120,  921,  405, 1128,\n",
      "         1054, 1818, 1870,   93,  338,  409, 1702, 3382, 1073, 1102,  572, 3321,\n",
      "           14, 2674,  856, 3750, 3724, 4832, 2651,  325, 2766,  484, 3238,  298,\n",
      "          716, 4581, 1245, 2972, 1239, 3883, 1069, 2070,  276, 2682, 3221, 1493,\n",
      "         2264, 4805, 4444, 2676,  499,  871, 2640, 2655, 1071, 3351, 4671, 2991,\n",
      "         3005, 3769, 1749, 1116, 3518, 4397, 4928, 3746, 2485, 1111, 2266, 1120,\n",
      "         4890, 3331, 2926, 4093,  537, 4586,  382, 2109, 4952, 1315, 4032, 3925,\n",
      "         3847, 3960,  599, 1154, 3053, 3837,   25,  312, 1610, 2772, 2647,  159,\n",
      "         2929, 1537, 2389],\n",
      "        [3939, 2051,  226, 2678, 3565, 4498,  247, 1404, 2418, 4168, 3602,  915,\n",
      "         1803, 1057, 3400,  723, 1285, 3816, 4483, 4443, 2081, 1768, 2909, 1808,\n",
      "         1203, 2983, 2809, 4248, 3424, 4945, 4458, 3580, 2049, 1776,  762, 4802,\n",
      "         3029,  142, 4142, 2025,  375,   56, 2322, 3395, 3992, 2983,  102,  908,\n",
      "          597, 3706, 1353, 4458, 2781, 3812, 2914, 4860, 4213, 2657, 2658,   79,\n",
      "         3704,  490, 4494,  694,   33, 4508, 3726, 4352, 1528, 2188,  503, 3758,\n",
      "         2623, 4628,  743, 4881, 3388, 3242, 3149, 3349,  230,  610, 1953, 4306,\n",
      "         1782, 3675, 4155, 3474, 3534, 4280, 1857, 3153,  432,  996, 4075,  997,\n",
      "         2349, 1377, 4171]], device='cuda:0') torch.Size([2, 99])\n",
      "forward  tensor([[4997, 2458, 4492, 1115, 4087,  585,  166, 1738, 2802, 2132, 4155, 1752,\n",
      "         3319, 1808, 2164, 3892, 2211, 4077,  124,  496, 4507, 3476,  243, 1731,\n",
      "         4436, 1811,  688, 4567, 2406, 3653, 4214, 4493, 3415, 1190, 2811, 3307,\n",
      "         3747,  719, 2902,  957,  790, 1785, 3376, 2573, 2196,  796, 2908, 3983,\n",
      "         3066, 4278, 1568, 3313,  382, 1562, 2102, 2977, 3678, 4513, 3177, 2748,\n",
      "         4645,   74,  995,  115,  665, 1085, 1935,   81,  197, 2146, 3998,  213,\n",
      "         2949, 3822, 3782,  963,  501, 2008, 4438,  127, 1518,  273, 1507, 3046,\n",
      "         1969, 3640, 1681, 4060, 3535, 3489, 4450,  291, 3663, 3983, 2578,  207,\n",
      "         2695,  679, 2669, 3045],\n",
      "        [4950, 4331,   94, 3183,  901,   95, 1714, 3563, 3864,  116, 4016, 2356,\n",
      "          550, 3772, 3242, 3960, 2030, 1160,  391,  768, 1374,  827, 4873, 3283,\n",
      "         1994, 3517, 4391, 1187, 2219, 4614,  243, 3782, 2883, 3537, 3169, 2340,\n",
      "         2220,  685, 2114, 2267, 2287,  901, 4808, 1191, 3243, 4473, 4601, 4550,\n",
      "         4885,  268, 4980, 1232, 4556,  738, 4332, 3535, 3195,  176, 1875,  947,\n",
      "         2469,  343, 3723, 4926, 3304, 2108, 1921,  207,  489, 1286,  983, 2509,\n",
      "         1673, 1017, 4924, 3259, 3131, 2174,  936, 2833, 4562, 4357, 2624, 1692,\n",
      "         4067, 4415,  886,  615, 1949, 2686, 3072, 3506, 3925,  155,  446,  848,\n",
      "          425, 3711, 1806, 4930]], device='cuda:0') torch.Size([2, 100])\n",
      "forward  tensor([[ 310, 3537,  936, 2845, 1247, 3988, 1072, 1915,  120,  921,  405, 1128,\n",
      "         1054, 1818, 1870,   93,  338,  409, 1702, 3382, 1073, 1102,  572, 3321,\n",
      "           14, 2674,  856, 3750, 3724, 4832, 2651,  325, 2766,  484, 3238,  298,\n",
      "          716, 4581, 1245, 2972, 1239, 3883, 1069, 2070,  276, 2682, 3221, 1493,\n",
      "         2264, 4805, 4444, 2676,  499,  871, 2640, 2655, 1071, 3351, 4671, 2991,\n",
      "         3005, 3769, 1749, 1116, 3518, 4397, 4928, 3746, 2485, 1111, 2266, 1120,\n",
      "         4890, 3331, 2926, 4093,  537, 4586,  382, 2109, 4952, 1315, 4032, 3925,\n",
      "         3847, 3960,  599, 1154, 3053, 3837,   25,  312, 1610, 2772, 2647,  159,\n",
      "         2929, 1537, 2389],\n",
      "        [3939, 2051,  226, 2678, 3565, 4498,  247, 1404, 2418, 4168, 3602,  915,\n",
      "         1803, 1057, 3400,  723, 1285, 3816, 4483, 4443, 2081, 1768, 2909, 1808,\n",
      "         1203, 2983, 2809, 4248, 3424, 4945, 4458, 3580, 2049, 1776,  762, 4802,\n",
      "         3029,  142, 4142, 2025,  375,   56, 2322, 3395, 3992, 2983,  102,  908,\n",
      "          597, 3706, 1353, 4458, 2781, 3812, 2914, 4860, 4213, 2657, 2658,   79,\n",
      "         3704,  490, 4494,  694,   33, 4508, 3726, 4352, 1528, 2188,  503, 3758,\n",
      "         2623, 4628,  743, 4881, 3388, 3242, 3149, 3349,  230,  610, 1953, 4306,\n",
      "         1782, 3675, 4155, 3474, 3534, 4280, 1857, 3153,  432,  996, 4075,  997,\n",
      "         2349, 1377, 4171]], device='cuda:0') torch.Size([2, 99])\n",
      "Epoch: 4, Loss: 7.515976905822754\n",
      "forward  tensor([[4997, 2458, 4492, 1115, 4087,  585,  166, 1738, 2802, 2132, 4155, 1752,\n",
      "         3319, 1808, 2164, 3892, 2211, 4077,  124,  496, 4507, 3476,  243, 1731,\n",
      "         4436, 1811,  688, 4567, 2406, 3653, 4214, 4493, 3415, 1190, 2811, 3307,\n",
      "         3747,  719, 2902,  957,  790, 1785, 3376, 2573, 2196,  796, 2908, 3983,\n",
      "         3066, 4278, 1568, 3313,  382, 1562, 2102, 2977, 3678, 4513, 3177, 2748,\n",
      "         4645,   74,  995,  115,  665, 1085, 1935,   81,  197, 2146, 3998,  213,\n",
      "         2949, 3822, 3782,  963,  501, 2008, 4438,  127, 1518,  273, 1507, 3046,\n",
      "         1969, 3640, 1681, 4060, 3535, 3489, 4450,  291, 3663, 3983, 2578,  207,\n",
      "         2695,  679, 2669, 3045],\n",
      "        [4950, 4331,   94, 3183,  901,   95, 1714, 3563, 3864,  116, 4016, 2356,\n",
      "          550, 3772, 3242, 3960, 2030, 1160,  391,  768, 1374,  827, 4873, 3283,\n",
      "         1994, 3517, 4391, 1187, 2219, 4614,  243, 3782, 2883, 3537, 3169, 2340,\n",
      "         2220,  685, 2114, 2267, 2287,  901, 4808, 1191, 3243, 4473, 4601, 4550,\n",
      "         4885,  268, 4980, 1232, 4556,  738, 4332, 3535, 3195,  176, 1875,  947,\n",
      "         2469,  343, 3723, 4926, 3304, 2108, 1921,  207,  489, 1286,  983, 2509,\n",
      "         1673, 1017, 4924, 3259, 3131, 2174,  936, 2833, 4562, 4357, 2624, 1692,\n",
      "         4067, 4415,  886,  615, 1949, 2686, 3072, 3506, 3925,  155,  446,  848,\n",
      "          425, 3711, 1806, 4930]], device='cuda:0') torch.Size([2, 100])\n",
      "forward  tensor([[ 310, 3537,  936, 2845, 1247, 3988, 1072, 1915,  120,  921,  405, 1128,\n",
      "         1054, 1818, 1870,   93,  338,  409, 1702, 3382, 1073, 1102,  572, 3321,\n",
      "           14, 2674,  856, 3750, 3724, 4832, 2651,  325, 2766,  484, 3238,  298,\n",
      "          716, 4581, 1245, 2972, 1239, 3883, 1069, 2070,  276, 2682, 3221, 1493,\n",
      "         2264, 4805, 4444, 2676,  499,  871, 2640, 2655, 1071, 3351, 4671, 2991,\n",
      "         3005, 3769, 1749, 1116, 3518, 4397, 4928, 3746, 2485, 1111, 2266, 1120,\n",
      "         4890, 3331, 2926, 4093,  537, 4586,  382, 2109, 4952, 1315, 4032, 3925,\n",
      "         3847, 3960,  599, 1154, 3053, 3837,   25,  312, 1610, 2772, 2647,  159,\n",
      "         2929, 1537, 2389],\n",
      "        [3939, 2051,  226, 2678, 3565, 4498,  247, 1404, 2418, 4168, 3602,  915,\n",
      "         1803, 1057, 3400,  723, 1285, 3816, 4483, 4443, 2081, 1768, 2909, 1808,\n",
      "         1203, 2983, 2809, 4248, 3424, 4945, 4458, 3580, 2049, 1776,  762, 4802,\n",
      "         3029,  142, 4142, 2025,  375,   56, 2322, 3395, 3992, 2983,  102,  908,\n",
      "          597, 3706, 1353, 4458, 2781, 3812, 2914, 4860, 4213, 2657, 2658,   79,\n",
      "         3704,  490, 4494,  694,   33, 4508, 3726, 4352, 1528, 2188,  503, 3758,\n",
      "         2623, 4628,  743, 4881, 3388, 3242, 3149, 3349,  230,  610, 1953, 4306,\n",
      "         1782, 3675, 4155, 3474, 3534, 4280, 1857, 3153,  432,  996, 4075,  997,\n",
      "         2349, 1377, 4171]], device='cuda:0') torch.Size([2, 99])\n",
      "Epoch: 4, Loss: 7.187893390655518\n",
      "src  tensor([[4997, 2458, 4492, 1115, 4087,  585,  166, 1738, 2802, 2132, 4155, 1752,\n",
      "         3319, 1808, 2164, 3892, 2211, 4077,  124,  496, 4507, 3476,  243, 1731,\n",
      "         4436, 1811,  688, 4567, 2406, 3653, 4214, 4493, 3415, 1190, 2811, 3307,\n",
      "         3747,  719, 2902,  957,  790, 1785, 3376, 2573, 2196,  796, 2908, 3983,\n",
      "         3066, 4278, 1568, 3313,  382, 1562, 2102, 2977, 3678, 4513, 3177, 2748,\n",
      "         4645,   74,  995,  115,  665, 1085, 1935,   81,  197, 2146, 3998,  213,\n",
      "         2949, 3822, 3782,  963,  501, 2008, 4438,  127, 1518,  273, 1507, 3046,\n",
      "         1969, 3640, 1681, 4060, 3535, 3489, 4450,  291, 3663, 3983, 2578,  207,\n",
      "         2695,  679, 2669, 3045],\n",
      "        [4950, 4331,   94, 3183,  901,   95, 1714, 3563, 3864,  116, 4016, 2356,\n",
      "          550, 3772, 3242, 3960, 2030, 1160,  391,  768, 1374,  827, 4873, 3283,\n",
      "         1994, 3517, 4391, 1187, 2219, 4614,  243, 3782, 2883, 3537, 3169, 2340,\n",
      "         2220,  685, 2114, 2267, 2287,  901, 4808, 1191, 3243, 4473, 4601, 4550,\n",
      "         4885,  268, 4980, 1232, 4556,  738, 4332, 3535, 3195,  176, 1875,  947,\n",
      "         2469,  343, 3723, 4926, 3304, 2108, 1921,  207,  489, 1286,  983, 2509,\n",
      "         1673, 1017, 4924, 3259, 3131, 2174,  936, 2833, 4562, 4357, 2624, 1692,\n",
      "         4067, 4415,  886,  615, 1949, 2686, 3072, 3506, 3925,  155,  446,  848,\n",
      "          425, 3711, 1806, 4930]], device='cuda:0') torch.Size([2, 100])\n",
      "trg  tensor([[ 310, 3537,  936, 2845, 1247, 3988, 1072, 1915,  120,  921,  405, 1128,\n",
      "         1054, 1818, 1870,   93,  338,  409, 1702, 3382, 1073, 1102,  572, 3321,\n",
      "           14, 2674,  856, 3750, 3724, 4832, 2651,  325, 2766,  484, 3238,  298,\n",
      "          716, 4581, 1245, 2972, 1239, 3883, 1069, 2070,  276, 2682, 3221, 1493,\n",
      "         2264, 4805, 4444, 2676,  499,  871, 2640, 2655, 1071, 3351, 4671, 2991,\n",
      "         3005, 3769, 1749, 1116, 3518, 4397, 4928, 3746, 2485, 1111, 2266, 1120,\n",
      "         4890, 3331, 2926, 4093,  537, 4586,  382, 2109, 4952, 1315, 4032, 3925,\n",
      "         3847, 3960,  599, 1154, 3053, 3837,   25,  312, 1610, 2772, 2647,  159,\n",
      "         2929, 1537, 2389,  616],\n",
      "        [3939, 2051,  226, 2678, 3565, 4498,  247, 1404, 2418, 4168, 3602,  915,\n",
      "         1803, 1057, 3400,  723, 1285, 3816, 4483, 4443, 2081, 1768, 2909, 1808,\n",
      "         1203, 2983, 2809, 4248, 3424, 4945, 4458, 3580, 2049, 1776,  762, 4802,\n",
      "         3029,  142, 4142, 2025,  375,   56, 2322, 3395, 3992, 2983,  102,  908,\n",
      "          597, 3706, 1353, 4458, 2781, 3812, 2914, 4860, 4213, 2657, 2658,   79,\n",
      "         3704,  490, 4494,  694,   33, 4508, 3726, 4352, 1528, 2188,  503, 3758,\n",
      "         2623, 4628,  743, 4881, 3388, 3242, 3149, 3349,  230,  610, 1953, 4306,\n",
      "         1782, 3675, 4155, 3474, 3534, 4280, 1857, 3153,  432,  996, 4075,  997,\n",
      "         2349, 1377, 4171, 2096]], device='cuda:0') torch.Size([2, 100])\n",
      "trg  -1   -- tensor([[ 310, 3537,  936, 2845, 1247, 3988, 1072, 1915,  120,  921,  405, 1128,\n",
      "         1054, 1818, 1870,   93,  338,  409, 1702, 3382, 1073, 1102,  572, 3321,\n",
      "           14, 2674,  856, 3750, 3724, 4832, 2651,  325, 2766,  484, 3238,  298,\n",
      "          716, 4581, 1245, 2972, 1239, 3883, 1069, 2070,  276, 2682, 3221, 1493,\n",
      "         2264, 4805, 4444, 2676,  499,  871, 2640, 2655, 1071, 3351, 4671, 2991,\n",
      "         3005, 3769, 1749, 1116, 3518, 4397, 4928, 3746, 2485, 1111, 2266, 1120,\n",
      "         4890, 3331, 2926, 4093,  537, 4586,  382, 2109, 4952, 1315, 4032, 3925,\n",
      "         3847, 3960,  599, 1154, 3053, 3837,   25,  312, 1610, 2772, 2647,  159,\n",
      "         2929, 1537, 2389],\n",
      "        [3939, 2051,  226, 2678, 3565, 4498,  247, 1404, 2418, 4168, 3602,  915,\n",
      "         1803, 1057, 3400,  723, 1285, 3816, 4483, 4443, 2081, 1768, 2909, 1808,\n",
      "         1203, 2983, 2809, 4248, 3424, 4945, 4458, 3580, 2049, 1776,  762, 4802,\n",
      "         3029,  142, 4142, 2025,  375,   56, 2322, 3395, 3992, 2983,  102,  908,\n",
      "          597, 3706, 1353, 4458, 2781, 3812, 2914, 4860, 4213, 2657, 2658,   79,\n",
      "         3704,  490, 4494,  694,   33, 4508, 3726, 4352, 1528, 2188,  503, 3758,\n",
      "         2623, 4628,  743, 4881, 3388, 3242, 3149, 3349,  230,  610, 1953, 4306,\n",
      "         1782, 3675, 4155, 3474, 3534, 4280, 1857, 3153,  432,  996, 4075,  997,\n",
      "         2349, 1377, 4171]], device='cuda:0') torch.Size([2, 99])\n",
      "forward  tensor([[4997, 2458, 4492, 1115, 4087,  585,  166, 1738, 2802, 2132, 4155, 1752,\n",
      "         3319, 1808, 2164, 3892, 2211, 4077,  124,  496, 4507, 3476,  243, 1731,\n",
      "         4436, 1811,  688, 4567, 2406, 3653, 4214, 4493, 3415, 1190, 2811, 3307,\n",
      "         3747,  719, 2902,  957,  790, 1785, 3376, 2573, 2196,  796, 2908, 3983,\n",
      "         3066, 4278, 1568, 3313,  382, 1562, 2102, 2977, 3678, 4513, 3177, 2748,\n",
      "         4645,   74,  995,  115,  665, 1085, 1935,   81,  197, 2146, 3998,  213,\n",
      "         2949, 3822, 3782,  963,  501, 2008, 4438,  127, 1518,  273, 1507, 3046,\n",
      "         1969, 3640, 1681, 4060, 3535, 3489, 4450,  291, 3663, 3983, 2578,  207,\n",
      "         2695,  679, 2669, 3045],\n",
      "        [4950, 4331,   94, 3183,  901,   95, 1714, 3563, 3864,  116, 4016, 2356,\n",
      "          550, 3772, 3242, 3960, 2030, 1160,  391,  768, 1374,  827, 4873, 3283,\n",
      "         1994, 3517, 4391, 1187, 2219, 4614,  243, 3782, 2883, 3537, 3169, 2340,\n",
      "         2220,  685, 2114, 2267, 2287,  901, 4808, 1191, 3243, 4473, 4601, 4550,\n",
      "         4885,  268, 4980, 1232, 4556,  738, 4332, 3535, 3195,  176, 1875,  947,\n",
      "         2469,  343, 3723, 4926, 3304, 2108, 1921,  207,  489, 1286,  983, 2509,\n",
      "         1673, 1017, 4924, 3259, 3131, 2174,  936, 2833, 4562, 4357, 2624, 1692,\n",
      "         4067, 4415,  886,  615, 1949, 2686, 3072, 3506, 3925,  155,  446,  848,\n",
      "          425, 3711, 1806, 4930]], device='cuda:0') torch.Size([2, 100])\n",
      "forward  tensor([[ 310, 3537,  936, 2845, 1247, 3988, 1072, 1915,  120,  921,  405, 1128,\n",
      "         1054, 1818, 1870,   93,  338,  409, 1702, 3382, 1073, 1102,  572, 3321,\n",
      "           14, 2674,  856, 3750, 3724, 4832, 2651,  325, 2766,  484, 3238,  298,\n",
      "          716, 4581, 1245, 2972, 1239, 3883, 1069, 2070,  276, 2682, 3221, 1493,\n",
      "         2264, 4805, 4444, 2676,  499,  871, 2640, 2655, 1071, 3351, 4671, 2991,\n",
      "         3005, 3769, 1749, 1116, 3518, 4397, 4928, 3746, 2485, 1111, 2266, 1120,\n",
      "         4890, 3331, 2926, 4093,  537, 4586,  382, 2109, 4952, 1315, 4032, 3925,\n",
      "         3847, 3960,  599, 1154, 3053, 3837,   25,  312, 1610, 2772, 2647,  159,\n",
      "         2929, 1537, 2389],\n",
      "        [3939, 2051,  226, 2678, 3565, 4498,  247, 1404, 2418, 4168, 3602,  915,\n",
      "         1803, 1057, 3400,  723, 1285, 3816, 4483, 4443, 2081, 1768, 2909, 1808,\n",
      "         1203, 2983, 2809, 4248, 3424, 4945, 4458, 3580, 2049, 1776,  762, 4802,\n",
      "         3029,  142, 4142, 2025,  375,   56, 2322, 3395, 3992, 2983,  102,  908,\n",
      "          597, 3706, 1353, 4458, 2781, 3812, 2914, 4860, 4213, 2657, 2658,   79,\n",
      "         3704,  490, 4494,  694,   33, 4508, 3726, 4352, 1528, 2188,  503, 3758,\n",
      "         2623, 4628,  743, 4881, 3388, 3242, 3149, 3349,  230,  610, 1953, 4306,\n",
      "         1782, 3675, 4155, 3474, 3534, 4280, 1857, 3153,  432,  996, 4075,  997,\n",
      "         2349, 1377, 4171]], device='cuda:0') torch.Size([2, 99])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Loss: 7.289721488952637\n",
      "forward  tensor([[4997, 2458, 4492, 1115, 4087,  585,  166, 1738, 2802, 2132, 4155, 1752,\n",
      "         3319, 1808, 2164, 3892, 2211, 4077,  124,  496, 4507, 3476,  243, 1731,\n",
      "         4436, 1811,  688, 4567, 2406, 3653, 4214, 4493, 3415, 1190, 2811, 3307,\n",
      "         3747,  719, 2902,  957,  790, 1785, 3376, 2573, 2196,  796, 2908, 3983,\n",
      "         3066, 4278, 1568, 3313,  382, 1562, 2102, 2977, 3678, 4513, 3177, 2748,\n",
      "         4645,   74,  995,  115,  665, 1085, 1935,   81,  197, 2146, 3998,  213,\n",
      "         2949, 3822, 3782,  963,  501, 2008, 4438,  127, 1518,  273, 1507, 3046,\n",
      "         1969, 3640, 1681, 4060, 3535, 3489, 4450,  291, 3663, 3983, 2578,  207,\n",
      "         2695,  679, 2669, 3045],\n",
      "        [4950, 4331,   94, 3183,  901,   95, 1714, 3563, 3864,  116, 4016, 2356,\n",
      "          550, 3772, 3242, 3960, 2030, 1160,  391,  768, 1374,  827, 4873, 3283,\n",
      "         1994, 3517, 4391, 1187, 2219, 4614,  243, 3782, 2883, 3537, 3169, 2340,\n",
      "         2220,  685, 2114, 2267, 2287,  901, 4808, 1191, 3243, 4473, 4601, 4550,\n",
      "         4885,  268, 4980, 1232, 4556,  738, 4332, 3535, 3195,  176, 1875,  947,\n",
      "         2469,  343, 3723, 4926, 3304, 2108, 1921,  207,  489, 1286,  983, 2509,\n",
      "         1673, 1017, 4924, 3259, 3131, 2174,  936, 2833, 4562, 4357, 2624, 1692,\n",
      "         4067, 4415,  886,  615, 1949, 2686, 3072, 3506, 3925,  155,  446,  848,\n",
      "          425, 3711, 1806, 4930]], device='cuda:0') torch.Size([2, 100])\n",
      "forward  tensor([[ 310, 3537,  936, 2845, 1247, 3988, 1072, 1915,  120,  921,  405, 1128,\n",
      "         1054, 1818, 1870,   93,  338,  409, 1702, 3382, 1073, 1102,  572, 3321,\n",
      "           14, 2674,  856, 3750, 3724, 4832, 2651,  325, 2766,  484, 3238,  298,\n",
      "          716, 4581, 1245, 2972, 1239, 3883, 1069, 2070,  276, 2682, 3221, 1493,\n",
      "         2264, 4805, 4444, 2676,  499,  871, 2640, 2655, 1071, 3351, 4671, 2991,\n",
      "         3005, 3769, 1749, 1116, 3518, 4397, 4928, 3746, 2485, 1111, 2266, 1120,\n",
      "         4890, 3331, 2926, 4093,  537, 4586,  382, 2109, 4952, 1315, 4032, 3925,\n",
      "         3847, 3960,  599, 1154, 3053, 3837,   25,  312, 1610, 2772, 2647,  159,\n",
      "         2929, 1537, 2389],\n",
      "        [3939, 2051,  226, 2678, 3565, 4498,  247, 1404, 2418, 4168, 3602,  915,\n",
      "         1803, 1057, 3400,  723, 1285, 3816, 4483, 4443, 2081, 1768, 2909, 1808,\n",
      "         1203, 2983, 2809, 4248, 3424, 4945, 4458, 3580, 2049, 1776,  762, 4802,\n",
      "         3029,  142, 4142, 2025,  375,   56, 2322, 3395, 3992, 2983,  102,  908,\n",
      "          597, 3706, 1353, 4458, 2781, 3812, 2914, 4860, 4213, 2657, 2658,   79,\n",
      "         3704,  490, 4494,  694,   33, 4508, 3726, 4352, 1528, 2188,  503, 3758,\n",
      "         2623, 4628,  743, 4881, 3388, 3242, 3149, 3349,  230,  610, 1953, 4306,\n",
      "         1782, 3675, 4155, 3474, 3534, 4280, 1857, 3153,  432,  996, 4075,  997,\n",
      "         2349, 1377, 4171]], device='cuda:0') torch.Size([2, 99])\n",
      "Epoch: 5, Loss: 6.915325164794922\n",
      "src  tensor([[4997, 2458, 4492, 1115, 4087,  585,  166, 1738, 2802, 2132, 4155, 1752,\n",
      "         3319, 1808, 2164, 3892, 2211, 4077,  124,  496, 4507, 3476,  243, 1731,\n",
      "         4436, 1811,  688, 4567, 2406, 3653, 4214, 4493, 3415, 1190, 2811, 3307,\n",
      "         3747,  719, 2902,  957,  790, 1785, 3376, 2573, 2196,  796, 2908, 3983,\n",
      "         3066, 4278, 1568, 3313,  382, 1562, 2102, 2977, 3678, 4513, 3177, 2748,\n",
      "         4645,   74,  995,  115,  665, 1085, 1935,   81,  197, 2146, 3998,  213,\n",
      "         2949, 3822, 3782,  963,  501, 2008, 4438,  127, 1518,  273, 1507, 3046,\n",
      "         1969, 3640, 1681, 4060, 3535, 3489, 4450,  291, 3663, 3983, 2578,  207,\n",
      "         2695,  679, 2669, 3045],\n",
      "        [4950, 4331,   94, 3183,  901,   95, 1714, 3563, 3864,  116, 4016, 2356,\n",
      "          550, 3772, 3242, 3960, 2030, 1160,  391,  768, 1374,  827, 4873, 3283,\n",
      "         1994, 3517, 4391, 1187, 2219, 4614,  243, 3782, 2883, 3537, 3169, 2340,\n",
      "         2220,  685, 2114, 2267, 2287,  901, 4808, 1191, 3243, 4473, 4601, 4550,\n",
      "         4885,  268, 4980, 1232, 4556,  738, 4332, 3535, 3195,  176, 1875,  947,\n",
      "         2469,  343, 3723, 4926, 3304, 2108, 1921,  207,  489, 1286,  983, 2509,\n",
      "         1673, 1017, 4924, 3259, 3131, 2174,  936, 2833, 4562, 4357, 2624, 1692,\n",
      "         4067, 4415,  886,  615, 1949, 2686, 3072, 3506, 3925,  155,  446,  848,\n",
      "          425, 3711, 1806, 4930]], device='cuda:0') torch.Size([2, 100])\n",
      "trg  tensor([[ 310, 3537,  936, 2845, 1247, 3988, 1072, 1915,  120,  921,  405, 1128,\n",
      "         1054, 1818, 1870,   93,  338,  409, 1702, 3382, 1073, 1102,  572, 3321,\n",
      "           14, 2674,  856, 3750, 3724, 4832, 2651,  325, 2766,  484, 3238,  298,\n",
      "          716, 4581, 1245, 2972, 1239, 3883, 1069, 2070,  276, 2682, 3221, 1493,\n",
      "         2264, 4805, 4444, 2676,  499,  871, 2640, 2655, 1071, 3351, 4671, 2991,\n",
      "         3005, 3769, 1749, 1116, 3518, 4397, 4928, 3746, 2485, 1111, 2266, 1120,\n",
      "         4890, 3331, 2926, 4093,  537, 4586,  382, 2109, 4952, 1315, 4032, 3925,\n",
      "         3847, 3960,  599, 1154, 3053, 3837,   25,  312, 1610, 2772, 2647,  159,\n",
      "         2929, 1537, 2389,  616],\n",
      "        [3939, 2051,  226, 2678, 3565, 4498,  247, 1404, 2418, 4168, 3602,  915,\n",
      "         1803, 1057, 3400,  723, 1285, 3816, 4483, 4443, 2081, 1768, 2909, 1808,\n",
      "         1203, 2983, 2809, 4248, 3424, 4945, 4458, 3580, 2049, 1776,  762, 4802,\n",
      "         3029,  142, 4142, 2025,  375,   56, 2322, 3395, 3992, 2983,  102,  908,\n",
      "          597, 3706, 1353, 4458, 2781, 3812, 2914, 4860, 4213, 2657, 2658,   79,\n",
      "         3704,  490, 4494,  694,   33, 4508, 3726, 4352, 1528, 2188,  503, 3758,\n",
      "         2623, 4628,  743, 4881, 3388, 3242, 3149, 3349,  230,  610, 1953, 4306,\n",
      "         1782, 3675, 4155, 3474, 3534, 4280, 1857, 3153,  432,  996, 4075,  997,\n",
      "         2349, 1377, 4171, 2096]], device='cuda:0') torch.Size([2, 100])\n",
      "trg  -1   -- tensor([[ 310, 3537,  936, 2845, 1247, 3988, 1072, 1915,  120,  921,  405, 1128,\n",
      "         1054, 1818, 1870,   93,  338,  409, 1702, 3382, 1073, 1102,  572, 3321,\n",
      "           14, 2674,  856, 3750, 3724, 4832, 2651,  325, 2766,  484, 3238,  298,\n",
      "          716, 4581, 1245, 2972, 1239, 3883, 1069, 2070,  276, 2682, 3221, 1493,\n",
      "         2264, 4805, 4444, 2676,  499,  871, 2640, 2655, 1071, 3351, 4671, 2991,\n",
      "         3005, 3769, 1749, 1116, 3518, 4397, 4928, 3746, 2485, 1111, 2266, 1120,\n",
      "         4890, 3331, 2926, 4093,  537, 4586,  382, 2109, 4952, 1315, 4032, 3925,\n",
      "         3847, 3960,  599, 1154, 3053, 3837,   25,  312, 1610, 2772, 2647,  159,\n",
      "         2929, 1537, 2389],\n",
      "        [3939, 2051,  226, 2678, 3565, 4498,  247, 1404, 2418, 4168, 3602,  915,\n",
      "         1803, 1057, 3400,  723, 1285, 3816, 4483, 4443, 2081, 1768, 2909, 1808,\n",
      "         1203, 2983, 2809, 4248, 3424, 4945, 4458, 3580, 2049, 1776,  762, 4802,\n",
      "         3029,  142, 4142, 2025,  375,   56, 2322, 3395, 3992, 2983,  102,  908,\n",
      "          597, 3706, 1353, 4458, 2781, 3812, 2914, 4860, 4213, 2657, 2658,   79,\n",
      "         3704,  490, 4494,  694,   33, 4508, 3726, 4352, 1528, 2188,  503, 3758,\n",
      "         2623, 4628,  743, 4881, 3388, 3242, 3149, 3349,  230,  610, 1953, 4306,\n",
      "         1782, 3675, 4155, 3474, 3534, 4280, 1857, 3153,  432,  996, 4075,  997,\n",
      "         2349, 1377, 4171]], device='cuda:0') torch.Size([2, 99])\n",
      "forward  tensor([[4997, 2458, 4492, 1115, 4087,  585,  166, 1738, 2802, 2132, 4155, 1752,\n",
      "         3319, 1808, 2164, 3892, 2211, 4077,  124,  496, 4507, 3476,  243, 1731,\n",
      "         4436, 1811,  688, 4567, 2406, 3653, 4214, 4493, 3415, 1190, 2811, 3307,\n",
      "         3747,  719, 2902,  957,  790, 1785, 3376, 2573, 2196,  796, 2908, 3983,\n",
      "         3066, 4278, 1568, 3313,  382, 1562, 2102, 2977, 3678, 4513, 3177, 2748,\n",
      "         4645,   74,  995,  115,  665, 1085, 1935,   81,  197, 2146, 3998,  213,\n",
      "         2949, 3822, 3782,  963,  501, 2008, 4438,  127, 1518,  273, 1507, 3046,\n",
      "         1969, 3640, 1681, 4060, 3535, 3489, 4450,  291, 3663, 3983, 2578,  207,\n",
      "         2695,  679, 2669, 3045],\n",
      "        [4950, 4331,   94, 3183,  901,   95, 1714, 3563, 3864,  116, 4016, 2356,\n",
      "          550, 3772, 3242, 3960, 2030, 1160,  391,  768, 1374,  827, 4873, 3283,\n",
      "         1994, 3517, 4391, 1187, 2219, 4614,  243, 3782, 2883, 3537, 3169, 2340,\n",
      "         2220,  685, 2114, 2267, 2287,  901, 4808, 1191, 3243, 4473, 4601, 4550,\n",
      "         4885,  268, 4980, 1232, 4556,  738, 4332, 3535, 3195,  176, 1875,  947,\n",
      "         2469,  343, 3723, 4926, 3304, 2108, 1921,  207,  489, 1286,  983, 2509,\n",
      "         1673, 1017, 4924, 3259, 3131, 2174,  936, 2833, 4562, 4357, 2624, 1692,\n",
      "         4067, 4415,  886,  615, 1949, 2686, 3072, 3506, 3925,  155,  446,  848,\n",
      "          425, 3711, 1806, 4930]], device='cuda:0') torch.Size([2, 100])\n",
      "forward  tensor([[ 310, 3537,  936, 2845, 1247, 3988, 1072, 1915,  120,  921,  405, 1128,\n",
      "         1054, 1818, 1870,   93,  338,  409, 1702, 3382, 1073, 1102,  572, 3321,\n",
      "           14, 2674,  856, 3750, 3724, 4832, 2651,  325, 2766,  484, 3238,  298,\n",
      "          716, 4581, 1245, 2972, 1239, 3883, 1069, 2070,  276, 2682, 3221, 1493,\n",
      "         2264, 4805, 4444, 2676,  499,  871, 2640, 2655, 1071, 3351, 4671, 2991,\n",
      "         3005, 3769, 1749, 1116, 3518, 4397, 4928, 3746, 2485, 1111, 2266, 1120,\n",
      "         4890, 3331, 2926, 4093,  537, 4586,  382, 2109, 4952, 1315, 4032, 3925,\n",
      "         3847, 3960,  599, 1154, 3053, 3837,   25,  312, 1610, 2772, 2647,  159,\n",
      "         2929, 1537, 2389],\n",
      "        [3939, 2051,  226, 2678, 3565, 4498,  247, 1404, 2418, 4168, 3602,  915,\n",
      "         1803, 1057, 3400,  723, 1285, 3816, 4483, 4443, 2081, 1768, 2909, 1808,\n",
      "         1203, 2983, 2809, 4248, 3424, 4945, 4458, 3580, 2049, 1776,  762, 4802,\n",
      "         3029,  142, 4142, 2025,  375,   56, 2322, 3395, 3992, 2983,  102,  908,\n",
      "          597, 3706, 1353, 4458, 2781, 3812, 2914, 4860, 4213, 2657, 2658,   79,\n",
      "         3704,  490, 4494,  694,   33, 4508, 3726, 4352, 1528, 2188,  503, 3758,\n",
      "         2623, 4628,  743, 4881, 3388, 3242, 3149, 3349,  230,  610, 1953, 4306,\n",
      "         1782, 3675, 4155, 3474, 3534, 4280, 1857, 3153,  432,  996, 4075,  997,\n",
      "         2349, 1377, 4171]], device='cuda:0') torch.Size([2, 99])\n",
      "Epoch: 6, Loss: 7.07689094543457\n",
      "forward  tensor([[4997, 2458, 4492, 1115, 4087,  585,  166, 1738, 2802, 2132, 4155, 1752,\n",
      "         3319, 1808, 2164, 3892, 2211, 4077,  124,  496, 4507, 3476,  243, 1731,\n",
      "         4436, 1811,  688, 4567, 2406, 3653, 4214, 4493, 3415, 1190, 2811, 3307,\n",
      "         3747,  719, 2902,  957,  790, 1785, 3376, 2573, 2196,  796, 2908, 3983,\n",
      "         3066, 4278, 1568, 3313,  382, 1562, 2102, 2977, 3678, 4513, 3177, 2748,\n",
      "         4645,   74,  995,  115,  665, 1085, 1935,   81,  197, 2146, 3998,  213,\n",
      "         2949, 3822, 3782,  963,  501, 2008, 4438,  127, 1518,  273, 1507, 3046,\n",
      "         1969, 3640, 1681, 4060, 3535, 3489, 4450,  291, 3663, 3983, 2578,  207,\n",
      "         2695,  679, 2669, 3045],\n",
      "        [4950, 4331,   94, 3183,  901,   95, 1714, 3563, 3864,  116, 4016, 2356,\n",
      "          550, 3772, 3242, 3960, 2030, 1160,  391,  768, 1374,  827, 4873, 3283,\n",
      "         1994, 3517, 4391, 1187, 2219, 4614,  243, 3782, 2883, 3537, 3169, 2340,\n",
      "         2220,  685, 2114, 2267, 2287,  901, 4808, 1191, 3243, 4473, 4601, 4550,\n",
      "         4885,  268, 4980, 1232, 4556,  738, 4332, 3535, 3195,  176, 1875,  947,\n",
      "         2469,  343, 3723, 4926, 3304, 2108, 1921,  207,  489, 1286,  983, 2509,\n",
      "         1673, 1017, 4924, 3259, 3131, 2174,  936, 2833, 4562, 4357, 2624, 1692,\n",
      "         4067, 4415,  886,  615, 1949, 2686, 3072, 3506, 3925,  155,  446,  848,\n",
      "          425, 3711, 1806, 4930]], device='cuda:0') torch.Size([2, 100])\n",
      "forward  tensor([[ 310, 3537,  936, 2845, 1247, 3988, 1072, 1915,  120,  921,  405, 1128,\n",
      "         1054, 1818, 1870,   93,  338,  409, 1702, 3382, 1073, 1102,  572, 3321,\n",
      "           14, 2674,  856, 3750, 3724, 4832, 2651,  325, 2766,  484, 3238,  298,\n",
      "          716, 4581, 1245, 2972, 1239, 3883, 1069, 2070,  276, 2682, 3221, 1493,\n",
      "         2264, 4805, 4444, 2676,  499,  871, 2640, 2655, 1071, 3351, 4671, 2991,\n",
      "         3005, 3769, 1749, 1116, 3518, 4397, 4928, 3746, 2485, 1111, 2266, 1120,\n",
      "         4890, 3331, 2926, 4093,  537, 4586,  382, 2109, 4952, 1315, 4032, 3925,\n",
      "         3847, 3960,  599, 1154, 3053, 3837,   25,  312, 1610, 2772, 2647,  159,\n",
      "         2929, 1537, 2389],\n",
      "        [3939, 2051,  226, 2678, 3565, 4498,  247, 1404, 2418, 4168, 3602,  915,\n",
      "         1803, 1057, 3400,  723, 1285, 3816, 4483, 4443, 2081, 1768, 2909, 1808,\n",
      "         1203, 2983, 2809, 4248, 3424, 4945, 4458, 3580, 2049, 1776,  762, 4802,\n",
      "         3029,  142, 4142, 2025,  375,   56, 2322, 3395, 3992, 2983,  102,  908,\n",
      "          597, 3706, 1353, 4458, 2781, 3812, 2914, 4860, 4213, 2657, 2658,   79,\n",
      "         3704,  490, 4494,  694,   33, 4508, 3726, 4352, 1528, 2188,  503, 3758,\n",
      "         2623, 4628,  743, 4881, 3388, 3242, 3149, 3349,  230,  610, 1953, 4306,\n",
      "         1782, 3675, 4155, 3474, 3534, 4280, 1857, 3153,  432,  996, 4075,  997,\n",
      "         2349, 1377, 4171]], device='cuda:0') torch.Size([2, 99])\n",
      "Epoch: 6, Loss: 6.5816473960876465\n",
      "src  tensor([[4997, 2458, 4492, 1115, 4087,  585,  166, 1738, 2802, 2132, 4155, 1752,\n",
      "         3319, 1808, 2164, 3892, 2211, 4077,  124,  496, 4507, 3476,  243, 1731,\n",
      "         4436, 1811,  688, 4567, 2406, 3653, 4214, 4493, 3415, 1190, 2811, 3307,\n",
      "         3747,  719, 2902,  957,  790, 1785, 3376, 2573, 2196,  796, 2908, 3983,\n",
      "         3066, 4278, 1568, 3313,  382, 1562, 2102, 2977, 3678, 4513, 3177, 2748,\n",
      "         4645,   74,  995,  115,  665, 1085, 1935,   81,  197, 2146, 3998,  213,\n",
      "         2949, 3822, 3782,  963,  501, 2008, 4438,  127, 1518,  273, 1507, 3046,\n",
      "         1969, 3640, 1681, 4060, 3535, 3489, 4450,  291, 3663, 3983, 2578,  207,\n",
      "         2695,  679, 2669, 3045],\n",
      "        [4950, 4331,   94, 3183,  901,   95, 1714, 3563, 3864,  116, 4016, 2356,\n",
      "          550, 3772, 3242, 3960, 2030, 1160,  391,  768, 1374,  827, 4873, 3283,\n",
      "         1994, 3517, 4391, 1187, 2219, 4614,  243, 3782, 2883, 3537, 3169, 2340,\n",
      "         2220,  685, 2114, 2267, 2287,  901, 4808, 1191, 3243, 4473, 4601, 4550,\n",
      "         4885,  268, 4980, 1232, 4556,  738, 4332, 3535, 3195,  176, 1875,  947,\n",
      "         2469,  343, 3723, 4926, 3304, 2108, 1921,  207,  489, 1286,  983, 2509,\n",
      "         1673, 1017, 4924, 3259, 3131, 2174,  936, 2833, 4562, 4357, 2624, 1692,\n",
      "         4067, 4415,  886,  615, 1949, 2686, 3072, 3506, 3925,  155,  446,  848,\n",
      "          425, 3711, 1806, 4930]], device='cuda:0') torch.Size([2, 100])\n",
      "trg  tensor([[ 310, 3537,  936, 2845, 1247, 3988, 1072, 1915,  120,  921,  405, 1128,\n",
      "         1054, 1818, 1870,   93,  338,  409, 1702, 3382, 1073, 1102,  572, 3321,\n",
      "           14, 2674,  856, 3750, 3724, 4832, 2651,  325, 2766,  484, 3238,  298,\n",
      "          716, 4581, 1245, 2972, 1239, 3883, 1069, 2070,  276, 2682, 3221, 1493,\n",
      "         2264, 4805, 4444, 2676,  499,  871, 2640, 2655, 1071, 3351, 4671, 2991,\n",
      "         3005, 3769, 1749, 1116, 3518, 4397, 4928, 3746, 2485, 1111, 2266, 1120,\n",
      "         4890, 3331, 2926, 4093,  537, 4586,  382, 2109, 4952, 1315, 4032, 3925,\n",
      "         3847, 3960,  599, 1154, 3053, 3837,   25,  312, 1610, 2772, 2647,  159,\n",
      "         2929, 1537, 2389,  616],\n",
      "        [3939, 2051,  226, 2678, 3565, 4498,  247, 1404, 2418, 4168, 3602,  915,\n",
      "         1803, 1057, 3400,  723, 1285, 3816, 4483, 4443, 2081, 1768, 2909, 1808,\n",
      "         1203, 2983, 2809, 4248, 3424, 4945, 4458, 3580, 2049, 1776,  762, 4802,\n",
      "         3029,  142, 4142, 2025,  375,   56, 2322, 3395, 3992, 2983,  102,  908,\n",
      "          597, 3706, 1353, 4458, 2781, 3812, 2914, 4860, 4213, 2657, 2658,   79,\n",
      "         3704,  490, 4494,  694,   33, 4508, 3726, 4352, 1528, 2188,  503, 3758,\n",
      "         2623, 4628,  743, 4881, 3388, 3242, 3149, 3349,  230,  610, 1953, 4306,\n",
      "         1782, 3675, 4155, 3474, 3534, 4280, 1857, 3153,  432,  996, 4075,  997,\n",
      "         2349, 1377, 4171, 2096]], device='cuda:0') torch.Size([2, 100])\n",
      "trg  -1   -- tensor([[ 310, 3537,  936, 2845, 1247, 3988, 1072, 1915,  120,  921,  405, 1128,\n",
      "         1054, 1818, 1870,   93,  338,  409, 1702, 3382, 1073, 1102,  572, 3321,\n",
      "           14, 2674,  856, 3750, 3724, 4832, 2651,  325, 2766,  484, 3238,  298,\n",
      "          716, 4581, 1245, 2972, 1239, 3883, 1069, 2070,  276, 2682, 3221, 1493,\n",
      "         2264, 4805, 4444, 2676,  499,  871, 2640, 2655, 1071, 3351, 4671, 2991,\n",
      "         3005, 3769, 1749, 1116, 3518, 4397, 4928, 3746, 2485, 1111, 2266, 1120,\n",
      "         4890, 3331, 2926, 4093,  537, 4586,  382, 2109, 4952, 1315, 4032, 3925,\n",
      "         3847, 3960,  599, 1154, 3053, 3837,   25,  312, 1610, 2772, 2647,  159,\n",
      "         2929, 1537, 2389],\n",
      "        [3939, 2051,  226, 2678, 3565, 4498,  247, 1404, 2418, 4168, 3602,  915,\n",
      "         1803, 1057, 3400,  723, 1285, 3816, 4483, 4443, 2081, 1768, 2909, 1808,\n",
      "         1203, 2983, 2809, 4248, 3424, 4945, 4458, 3580, 2049, 1776,  762, 4802,\n",
      "         3029,  142, 4142, 2025,  375,   56, 2322, 3395, 3992, 2983,  102,  908,\n",
      "          597, 3706, 1353, 4458, 2781, 3812, 2914, 4860, 4213, 2657, 2658,   79,\n",
      "         3704,  490, 4494,  694,   33, 4508, 3726, 4352, 1528, 2188,  503, 3758,\n",
      "         2623, 4628,  743, 4881, 3388, 3242, 3149, 3349,  230,  610, 1953, 4306,\n",
      "         1782, 3675, 4155, 3474, 3534, 4280, 1857, 3153,  432,  996, 4075,  997,\n",
      "         2349, 1377, 4171]], device='cuda:0') torch.Size([2, 99])\n",
      "forward  tensor([[4997, 2458, 4492, 1115, 4087,  585,  166, 1738, 2802, 2132, 4155, 1752,\n",
      "         3319, 1808, 2164, 3892, 2211, 4077,  124,  496, 4507, 3476,  243, 1731,\n",
      "         4436, 1811,  688, 4567, 2406, 3653, 4214, 4493, 3415, 1190, 2811, 3307,\n",
      "         3747,  719, 2902,  957,  790, 1785, 3376, 2573, 2196,  796, 2908, 3983,\n",
      "         3066, 4278, 1568, 3313,  382, 1562, 2102, 2977, 3678, 4513, 3177, 2748,\n",
      "         4645,   74,  995,  115,  665, 1085, 1935,   81,  197, 2146, 3998,  213,\n",
      "         2949, 3822, 3782,  963,  501, 2008, 4438,  127, 1518,  273, 1507, 3046,\n",
      "         1969, 3640, 1681, 4060, 3535, 3489, 4450,  291, 3663, 3983, 2578,  207,\n",
      "         2695,  679, 2669, 3045],\n",
      "        [4950, 4331,   94, 3183,  901,   95, 1714, 3563, 3864,  116, 4016, 2356,\n",
      "          550, 3772, 3242, 3960, 2030, 1160,  391,  768, 1374,  827, 4873, 3283,\n",
      "         1994, 3517, 4391, 1187, 2219, 4614,  243, 3782, 2883, 3537, 3169, 2340,\n",
      "         2220,  685, 2114, 2267, 2287,  901, 4808, 1191, 3243, 4473, 4601, 4550,\n",
      "         4885,  268, 4980, 1232, 4556,  738, 4332, 3535, 3195,  176, 1875,  947,\n",
      "         2469,  343, 3723, 4926, 3304, 2108, 1921,  207,  489, 1286,  983, 2509,\n",
      "         1673, 1017, 4924, 3259, 3131, 2174,  936, 2833, 4562, 4357, 2624, 1692,\n",
      "         4067, 4415,  886,  615, 1949, 2686, 3072, 3506, 3925,  155,  446,  848,\n",
      "          425, 3711, 1806, 4930]], device='cuda:0') torch.Size([2, 100])\n",
      "forward  tensor([[ 310, 3537,  936, 2845, 1247, 3988, 1072, 1915,  120,  921,  405, 1128,\n",
      "         1054, 1818, 1870,   93,  338,  409, 1702, 3382, 1073, 1102,  572, 3321,\n",
      "           14, 2674,  856, 3750, 3724, 4832, 2651,  325, 2766,  484, 3238,  298,\n",
      "          716, 4581, 1245, 2972, 1239, 3883, 1069, 2070,  276, 2682, 3221, 1493,\n",
      "         2264, 4805, 4444, 2676,  499,  871, 2640, 2655, 1071, 3351, 4671, 2991,\n",
      "         3005, 3769, 1749, 1116, 3518, 4397, 4928, 3746, 2485, 1111, 2266, 1120,\n",
      "         4890, 3331, 2926, 4093,  537, 4586,  382, 2109, 4952, 1315, 4032, 3925,\n",
      "         3847, 3960,  599, 1154, 3053, 3837,   25,  312, 1610, 2772, 2647,  159,\n",
      "         2929, 1537, 2389],\n",
      "        [3939, 2051,  226, 2678, 3565, 4498,  247, 1404, 2418, 4168, 3602,  915,\n",
      "         1803, 1057, 3400,  723, 1285, 3816, 4483, 4443, 2081, 1768, 2909, 1808,\n",
      "         1203, 2983, 2809, 4248, 3424, 4945, 4458, 3580, 2049, 1776,  762, 4802,\n",
      "         3029,  142, 4142, 2025,  375,   56, 2322, 3395, 3992, 2983,  102,  908,\n",
      "          597, 3706, 1353, 4458, 2781, 3812, 2914, 4860, 4213, 2657, 2658,   79,\n",
      "         3704,  490, 4494,  694,   33, 4508, 3726, 4352, 1528, 2188,  503, 3758,\n",
      "         2623, 4628,  743, 4881, 3388, 3242, 3149, 3349,  230,  610, 1953, 4306,\n",
      "         1782, 3675, 4155, 3474, 3534, 4280, 1857, 3153,  432,  996, 4075,  997,\n",
      "         2349, 1377, 4171]], device='cuda:0') torch.Size([2, 99])\n",
      "Epoch: 7, Loss: 6.776505947113037\n",
      "forward  tensor([[4997, 2458, 4492, 1115, 4087,  585,  166, 1738, 2802, 2132, 4155, 1752,\n",
      "         3319, 1808, 2164, 3892, 2211, 4077,  124,  496, 4507, 3476,  243, 1731,\n",
      "         4436, 1811,  688, 4567, 2406, 3653, 4214, 4493, 3415, 1190, 2811, 3307,\n",
      "         3747,  719, 2902,  957,  790, 1785, 3376, 2573, 2196,  796, 2908, 3983,\n",
      "         3066, 4278, 1568, 3313,  382, 1562, 2102, 2977, 3678, 4513, 3177, 2748,\n",
      "         4645,   74,  995,  115,  665, 1085, 1935,   81,  197, 2146, 3998,  213,\n",
      "         2949, 3822, 3782,  963,  501, 2008, 4438,  127, 1518,  273, 1507, 3046,\n",
      "         1969, 3640, 1681, 4060, 3535, 3489, 4450,  291, 3663, 3983, 2578,  207,\n",
      "         2695,  679, 2669, 3045],\n",
      "        [4950, 4331,   94, 3183,  901,   95, 1714, 3563, 3864,  116, 4016, 2356,\n",
      "          550, 3772, 3242, 3960, 2030, 1160,  391,  768, 1374,  827, 4873, 3283,\n",
      "         1994, 3517, 4391, 1187, 2219, 4614,  243, 3782, 2883, 3537, 3169, 2340,\n",
      "         2220,  685, 2114, 2267, 2287,  901, 4808, 1191, 3243, 4473, 4601, 4550,\n",
      "         4885,  268, 4980, 1232, 4556,  738, 4332, 3535, 3195,  176, 1875,  947,\n",
      "         2469,  343, 3723, 4926, 3304, 2108, 1921,  207,  489, 1286,  983, 2509,\n",
      "         1673, 1017, 4924, 3259, 3131, 2174,  936, 2833, 4562, 4357, 2624, 1692,\n",
      "         4067, 4415,  886,  615, 1949, 2686, 3072, 3506, 3925,  155,  446,  848,\n",
      "          425, 3711, 1806, 4930]], device='cuda:0') torch.Size([2, 100])\n",
      "forward  tensor([[ 310, 3537,  936, 2845, 1247, 3988, 1072, 1915,  120,  921,  405, 1128,\n",
      "         1054, 1818, 1870,   93,  338,  409, 1702, 3382, 1073, 1102,  572, 3321,\n",
      "           14, 2674,  856, 3750, 3724, 4832, 2651,  325, 2766,  484, 3238,  298,\n",
      "          716, 4581, 1245, 2972, 1239, 3883, 1069, 2070,  276, 2682, 3221, 1493,\n",
      "         2264, 4805, 4444, 2676,  499,  871, 2640, 2655, 1071, 3351, 4671, 2991,\n",
      "         3005, 3769, 1749, 1116, 3518, 4397, 4928, 3746, 2485, 1111, 2266, 1120,\n",
      "         4890, 3331, 2926, 4093,  537, 4586,  382, 2109, 4952, 1315, 4032, 3925,\n",
      "         3847, 3960,  599, 1154, 3053, 3837,   25,  312, 1610, 2772, 2647,  159,\n",
      "         2929, 1537, 2389],\n",
      "        [3939, 2051,  226, 2678, 3565, 4498,  247, 1404, 2418, 4168, 3602,  915,\n",
      "         1803, 1057, 3400,  723, 1285, 3816, 4483, 4443, 2081, 1768, 2909, 1808,\n",
      "         1203, 2983, 2809, 4248, 3424, 4945, 4458, 3580, 2049, 1776,  762, 4802,\n",
      "         3029,  142, 4142, 2025,  375,   56, 2322, 3395, 3992, 2983,  102,  908,\n",
      "          597, 3706, 1353, 4458, 2781, 3812, 2914, 4860, 4213, 2657, 2658,   79,\n",
      "         3704,  490, 4494,  694,   33, 4508, 3726, 4352, 1528, 2188,  503, 3758,\n",
      "         2623, 4628,  743, 4881, 3388, 3242, 3149, 3349,  230,  610, 1953, 4306,\n",
      "         1782, 3675, 4155, 3474, 3534, 4280, 1857, 3153,  432,  996, 4075,  997,\n",
      "         2349, 1377, 4171]], device='cuda:0') torch.Size([2, 99])\n",
      "Epoch: 7, Loss: 6.217574119567871\n",
      "src  tensor([[4997, 2458, 4492, 1115, 4087,  585,  166, 1738, 2802, 2132, 4155, 1752,\n",
      "         3319, 1808, 2164, 3892, 2211, 4077,  124,  496, 4507, 3476,  243, 1731,\n",
      "         4436, 1811,  688, 4567, 2406, 3653, 4214, 4493, 3415, 1190, 2811, 3307,\n",
      "         3747,  719, 2902,  957,  790, 1785, 3376, 2573, 2196,  796, 2908, 3983,\n",
      "         3066, 4278, 1568, 3313,  382, 1562, 2102, 2977, 3678, 4513, 3177, 2748,\n",
      "         4645,   74,  995,  115,  665, 1085, 1935,   81,  197, 2146, 3998,  213,\n",
      "         2949, 3822, 3782,  963,  501, 2008, 4438,  127, 1518,  273, 1507, 3046,\n",
      "         1969, 3640, 1681, 4060, 3535, 3489, 4450,  291, 3663, 3983, 2578,  207,\n",
      "         2695,  679, 2669, 3045],\n",
      "        [4950, 4331,   94, 3183,  901,   95, 1714, 3563, 3864,  116, 4016, 2356,\n",
      "          550, 3772, 3242, 3960, 2030, 1160,  391,  768, 1374,  827, 4873, 3283,\n",
      "         1994, 3517, 4391, 1187, 2219, 4614,  243, 3782, 2883, 3537, 3169, 2340,\n",
      "         2220,  685, 2114, 2267, 2287,  901, 4808, 1191, 3243, 4473, 4601, 4550,\n",
      "         4885,  268, 4980, 1232, 4556,  738, 4332, 3535, 3195,  176, 1875,  947,\n",
      "         2469,  343, 3723, 4926, 3304, 2108, 1921,  207,  489, 1286,  983, 2509,\n",
      "         1673, 1017, 4924, 3259, 3131, 2174,  936, 2833, 4562, 4357, 2624, 1692,\n",
      "         4067, 4415,  886,  615, 1949, 2686, 3072, 3506, 3925,  155,  446,  848,\n",
      "          425, 3711, 1806, 4930]], device='cuda:0') torch.Size([2, 100])\n",
      "trg  tensor([[ 310, 3537,  936, 2845, 1247, 3988, 1072, 1915,  120,  921,  405, 1128,\n",
      "         1054, 1818, 1870,   93,  338,  409, 1702, 3382, 1073, 1102,  572, 3321,\n",
      "           14, 2674,  856, 3750, 3724, 4832, 2651,  325, 2766,  484, 3238,  298,\n",
      "          716, 4581, 1245, 2972, 1239, 3883, 1069, 2070,  276, 2682, 3221, 1493,\n",
      "         2264, 4805, 4444, 2676,  499,  871, 2640, 2655, 1071, 3351, 4671, 2991,\n",
      "         3005, 3769, 1749, 1116, 3518, 4397, 4928, 3746, 2485, 1111, 2266, 1120,\n",
      "         4890, 3331, 2926, 4093,  537, 4586,  382, 2109, 4952, 1315, 4032, 3925,\n",
      "         3847, 3960,  599, 1154, 3053, 3837,   25,  312, 1610, 2772, 2647,  159,\n",
      "         2929, 1537, 2389,  616],\n",
      "        [3939, 2051,  226, 2678, 3565, 4498,  247, 1404, 2418, 4168, 3602,  915,\n",
      "         1803, 1057, 3400,  723, 1285, 3816, 4483, 4443, 2081, 1768, 2909, 1808,\n",
      "         1203, 2983, 2809, 4248, 3424, 4945, 4458, 3580, 2049, 1776,  762, 4802,\n",
      "         3029,  142, 4142, 2025,  375,   56, 2322, 3395, 3992, 2983,  102,  908,\n",
      "          597, 3706, 1353, 4458, 2781, 3812, 2914, 4860, 4213, 2657, 2658,   79,\n",
      "         3704,  490, 4494,  694,   33, 4508, 3726, 4352, 1528, 2188,  503, 3758,\n",
      "         2623, 4628,  743, 4881, 3388, 3242, 3149, 3349,  230,  610, 1953, 4306,\n",
      "         1782, 3675, 4155, 3474, 3534, 4280, 1857, 3153,  432,  996, 4075,  997,\n",
      "         2349, 1377, 4171, 2096]], device='cuda:0') torch.Size([2, 100])\n",
      "trg  -1   -- tensor([[ 310, 3537,  936, 2845, 1247, 3988, 1072, 1915,  120,  921,  405, 1128,\n",
      "         1054, 1818, 1870,   93,  338,  409, 1702, 3382, 1073, 1102,  572, 3321,\n",
      "           14, 2674,  856, 3750, 3724, 4832, 2651,  325, 2766,  484, 3238,  298,\n",
      "          716, 4581, 1245, 2972, 1239, 3883, 1069, 2070,  276, 2682, 3221, 1493,\n",
      "         2264, 4805, 4444, 2676,  499,  871, 2640, 2655, 1071, 3351, 4671, 2991,\n",
      "         3005, 3769, 1749, 1116, 3518, 4397, 4928, 3746, 2485, 1111, 2266, 1120,\n",
      "         4890, 3331, 2926, 4093,  537, 4586,  382, 2109, 4952, 1315, 4032, 3925,\n",
      "         3847, 3960,  599, 1154, 3053, 3837,   25,  312, 1610, 2772, 2647,  159,\n",
      "         2929, 1537, 2389],\n",
      "        [3939, 2051,  226, 2678, 3565, 4498,  247, 1404, 2418, 4168, 3602,  915,\n",
      "         1803, 1057, 3400,  723, 1285, 3816, 4483, 4443, 2081, 1768, 2909, 1808,\n",
      "         1203, 2983, 2809, 4248, 3424, 4945, 4458, 3580, 2049, 1776,  762, 4802,\n",
      "         3029,  142, 4142, 2025,  375,   56, 2322, 3395, 3992, 2983,  102,  908,\n",
      "          597, 3706, 1353, 4458, 2781, 3812, 2914, 4860, 4213, 2657, 2658,   79,\n",
      "         3704,  490, 4494,  694,   33, 4508, 3726, 4352, 1528, 2188,  503, 3758,\n",
      "         2623, 4628,  743, 4881, 3388, 3242, 3149, 3349,  230,  610, 1953, 4306,\n",
      "         1782, 3675, 4155, 3474, 3534, 4280, 1857, 3153,  432,  996, 4075,  997,\n",
      "         2349, 1377, 4171]], device='cuda:0') torch.Size([2, 99])\n",
      "forward  tensor([[4997, 2458, 4492, 1115, 4087,  585,  166, 1738, 2802, 2132, 4155, 1752,\n",
      "         3319, 1808, 2164, 3892, 2211, 4077,  124,  496, 4507, 3476,  243, 1731,\n",
      "         4436, 1811,  688, 4567, 2406, 3653, 4214, 4493, 3415, 1190, 2811, 3307,\n",
      "         3747,  719, 2902,  957,  790, 1785, 3376, 2573, 2196,  796, 2908, 3983,\n",
      "         3066, 4278, 1568, 3313,  382, 1562, 2102, 2977, 3678, 4513, 3177, 2748,\n",
      "         4645,   74,  995,  115,  665, 1085, 1935,   81,  197, 2146, 3998,  213,\n",
      "         2949, 3822, 3782,  963,  501, 2008, 4438,  127, 1518,  273, 1507, 3046,\n",
      "         1969, 3640, 1681, 4060, 3535, 3489, 4450,  291, 3663, 3983, 2578,  207,\n",
      "         2695,  679, 2669, 3045],\n",
      "        [4950, 4331,   94, 3183,  901,   95, 1714, 3563, 3864,  116, 4016, 2356,\n",
      "          550, 3772, 3242, 3960, 2030, 1160,  391,  768, 1374,  827, 4873, 3283,\n",
      "         1994, 3517, 4391, 1187, 2219, 4614,  243, 3782, 2883, 3537, 3169, 2340,\n",
      "         2220,  685, 2114, 2267, 2287,  901, 4808, 1191, 3243, 4473, 4601, 4550,\n",
      "         4885,  268, 4980, 1232, 4556,  738, 4332, 3535, 3195,  176, 1875,  947,\n",
      "         2469,  343, 3723, 4926, 3304, 2108, 1921,  207,  489, 1286,  983, 2509,\n",
      "         1673, 1017, 4924, 3259, 3131, 2174,  936, 2833, 4562, 4357, 2624, 1692,\n",
      "         4067, 4415,  886,  615, 1949, 2686, 3072, 3506, 3925,  155,  446,  848,\n",
      "          425, 3711, 1806, 4930]], device='cuda:0') torch.Size([2, 100])\n",
      "forward  tensor([[ 310, 3537,  936, 2845, 1247, 3988, 1072, 1915,  120,  921,  405, 1128,\n",
      "         1054, 1818, 1870,   93,  338,  409, 1702, 3382, 1073, 1102,  572, 3321,\n",
      "           14, 2674,  856, 3750, 3724, 4832, 2651,  325, 2766,  484, 3238,  298,\n",
      "          716, 4581, 1245, 2972, 1239, 3883, 1069, 2070,  276, 2682, 3221, 1493,\n",
      "         2264, 4805, 4444, 2676,  499,  871, 2640, 2655, 1071, 3351, 4671, 2991,\n",
      "         3005, 3769, 1749, 1116, 3518, 4397, 4928, 3746, 2485, 1111, 2266, 1120,\n",
      "         4890, 3331, 2926, 4093,  537, 4586,  382, 2109, 4952, 1315, 4032, 3925,\n",
      "         3847, 3960,  599, 1154, 3053, 3837,   25,  312, 1610, 2772, 2647,  159,\n",
      "         2929, 1537, 2389],\n",
      "        [3939, 2051,  226, 2678, 3565, 4498,  247, 1404, 2418, 4168, 3602,  915,\n",
      "         1803, 1057, 3400,  723, 1285, 3816, 4483, 4443, 2081, 1768, 2909, 1808,\n",
      "         1203, 2983, 2809, 4248, 3424, 4945, 4458, 3580, 2049, 1776,  762, 4802,\n",
      "         3029,  142, 4142, 2025,  375,   56, 2322, 3395, 3992, 2983,  102,  908,\n",
      "          597, 3706, 1353, 4458, 2781, 3812, 2914, 4860, 4213, 2657, 2658,   79,\n",
      "         3704,  490, 4494,  694,   33, 4508, 3726, 4352, 1528, 2188,  503, 3758,\n",
      "         2623, 4628,  743, 4881, 3388, 3242, 3149, 3349,  230,  610, 1953, 4306,\n",
      "         1782, 3675, 4155, 3474, 3534, 4280, 1857, 3153,  432,  996, 4075,  997,\n",
      "         2349, 1377, 4171]], device='cuda:0') torch.Size([2, 99])\n",
      "Epoch: 8, Loss: 6.469450950622559\n",
      "forward  tensor([[4997, 2458, 4492, 1115, 4087,  585,  166, 1738, 2802, 2132, 4155, 1752,\n",
      "         3319, 1808, 2164, 3892, 2211, 4077,  124,  496, 4507, 3476,  243, 1731,\n",
      "         4436, 1811,  688, 4567, 2406, 3653, 4214, 4493, 3415, 1190, 2811, 3307,\n",
      "         3747,  719, 2902,  957,  790, 1785, 3376, 2573, 2196,  796, 2908, 3983,\n",
      "         3066, 4278, 1568, 3313,  382, 1562, 2102, 2977, 3678, 4513, 3177, 2748,\n",
      "         4645,   74,  995,  115,  665, 1085, 1935,   81,  197, 2146, 3998,  213,\n",
      "         2949, 3822, 3782,  963,  501, 2008, 4438,  127, 1518,  273, 1507, 3046,\n",
      "         1969, 3640, 1681, 4060, 3535, 3489, 4450,  291, 3663, 3983, 2578,  207,\n",
      "         2695,  679, 2669, 3045],\n",
      "        [4950, 4331,   94, 3183,  901,   95, 1714, 3563, 3864,  116, 4016, 2356,\n",
      "          550, 3772, 3242, 3960, 2030, 1160,  391,  768, 1374,  827, 4873, 3283,\n",
      "         1994, 3517, 4391, 1187, 2219, 4614,  243, 3782, 2883, 3537, 3169, 2340,\n",
      "         2220,  685, 2114, 2267, 2287,  901, 4808, 1191, 3243, 4473, 4601, 4550,\n",
      "         4885,  268, 4980, 1232, 4556,  738, 4332, 3535, 3195,  176, 1875,  947,\n",
      "         2469,  343, 3723, 4926, 3304, 2108, 1921,  207,  489, 1286,  983, 2509,\n",
      "         1673, 1017, 4924, 3259, 3131, 2174,  936, 2833, 4562, 4357, 2624, 1692,\n",
      "         4067, 4415,  886,  615, 1949, 2686, 3072, 3506, 3925,  155,  446,  848,\n",
      "          425, 3711, 1806, 4930]], device='cuda:0') torch.Size([2, 100])\n",
      "forward  tensor([[ 310, 3537,  936, 2845, 1247, 3988, 1072, 1915,  120,  921,  405, 1128,\n",
      "         1054, 1818, 1870,   93,  338,  409, 1702, 3382, 1073, 1102,  572, 3321,\n",
      "           14, 2674,  856, 3750, 3724, 4832, 2651,  325, 2766,  484, 3238,  298,\n",
      "          716, 4581, 1245, 2972, 1239, 3883, 1069, 2070,  276, 2682, 3221, 1493,\n",
      "         2264, 4805, 4444, 2676,  499,  871, 2640, 2655, 1071, 3351, 4671, 2991,\n",
      "         3005, 3769, 1749, 1116, 3518, 4397, 4928, 3746, 2485, 1111, 2266, 1120,\n",
      "         4890, 3331, 2926, 4093,  537, 4586,  382, 2109, 4952, 1315, 4032, 3925,\n",
      "         3847, 3960,  599, 1154, 3053, 3837,   25,  312, 1610, 2772, 2647,  159,\n",
      "         2929, 1537, 2389],\n",
      "        [3939, 2051,  226, 2678, 3565, 4498,  247, 1404, 2418, 4168, 3602,  915,\n",
      "         1803, 1057, 3400,  723, 1285, 3816, 4483, 4443, 2081, 1768, 2909, 1808,\n",
      "         1203, 2983, 2809, 4248, 3424, 4945, 4458, 3580, 2049, 1776,  762, 4802,\n",
      "         3029,  142, 4142, 2025,  375,   56, 2322, 3395, 3992, 2983,  102,  908,\n",
      "          597, 3706, 1353, 4458, 2781, 3812, 2914, 4860, 4213, 2657, 2658,   79,\n",
      "         3704,  490, 4494,  694,   33, 4508, 3726, 4352, 1528, 2188,  503, 3758,\n",
      "         2623, 4628,  743, 4881, 3388, 3242, 3149, 3349,  230,  610, 1953, 4306,\n",
      "         1782, 3675, 4155, 3474, 3534, 4280, 1857, 3153,  432,  996, 4075,  997,\n",
      "         2349, 1377, 4171]], device='cuda:0') torch.Size([2, 99])\n",
      "Epoch: 8, Loss: 5.897321701049805\n",
      "src  tensor([[4997, 2458, 4492, 1115, 4087,  585,  166, 1738, 2802, 2132, 4155, 1752,\n",
      "         3319, 1808, 2164, 3892, 2211, 4077,  124,  496, 4507, 3476,  243, 1731,\n",
      "         4436, 1811,  688, 4567, 2406, 3653, 4214, 4493, 3415, 1190, 2811, 3307,\n",
      "         3747,  719, 2902,  957,  790, 1785, 3376, 2573, 2196,  796, 2908, 3983,\n",
      "         3066, 4278, 1568, 3313,  382, 1562, 2102, 2977, 3678, 4513, 3177, 2748,\n",
      "         4645,   74,  995,  115,  665, 1085, 1935,   81,  197, 2146, 3998,  213,\n",
      "         2949, 3822, 3782,  963,  501, 2008, 4438,  127, 1518,  273, 1507, 3046,\n",
      "         1969, 3640, 1681, 4060, 3535, 3489, 4450,  291, 3663, 3983, 2578,  207,\n",
      "         2695,  679, 2669, 3045],\n",
      "        [4950, 4331,   94, 3183,  901,   95, 1714, 3563, 3864,  116, 4016, 2356,\n",
      "          550, 3772, 3242, 3960, 2030, 1160,  391,  768, 1374,  827, 4873, 3283,\n",
      "         1994, 3517, 4391, 1187, 2219, 4614,  243, 3782, 2883, 3537, 3169, 2340,\n",
      "         2220,  685, 2114, 2267, 2287,  901, 4808, 1191, 3243, 4473, 4601, 4550,\n",
      "         4885,  268, 4980, 1232, 4556,  738, 4332, 3535, 3195,  176, 1875,  947,\n",
      "         2469,  343, 3723, 4926, 3304, 2108, 1921,  207,  489, 1286,  983, 2509,\n",
      "         1673, 1017, 4924, 3259, 3131, 2174,  936, 2833, 4562, 4357, 2624, 1692,\n",
      "         4067, 4415,  886,  615, 1949, 2686, 3072, 3506, 3925,  155,  446,  848,\n",
      "          425, 3711, 1806, 4930]], device='cuda:0') torch.Size([2, 100])\n",
      "trg  tensor([[ 310, 3537,  936, 2845, 1247, 3988, 1072, 1915,  120,  921,  405, 1128,\n",
      "         1054, 1818, 1870,   93,  338,  409, 1702, 3382, 1073, 1102,  572, 3321,\n",
      "           14, 2674,  856, 3750, 3724, 4832, 2651,  325, 2766,  484, 3238,  298,\n",
      "          716, 4581, 1245, 2972, 1239, 3883, 1069, 2070,  276, 2682, 3221, 1493,\n",
      "         2264, 4805, 4444, 2676,  499,  871, 2640, 2655, 1071, 3351, 4671, 2991,\n",
      "         3005, 3769, 1749, 1116, 3518, 4397, 4928, 3746, 2485, 1111, 2266, 1120,\n",
      "         4890, 3331, 2926, 4093,  537, 4586,  382, 2109, 4952, 1315, 4032, 3925,\n",
      "         3847, 3960,  599, 1154, 3053, 3837,   25,  312, 1610, 2772, 2647,  159,\n",
      "         2929, 1537, 2389,  616],\n",
      "        [3939, 2051,  226, 2678, 3565, 4498,  247, 1404, 2418, 4168, 3602,  915,\n",
      "         1803, 1057, 3400,  723, 1285, 3816, 4483, 4443, 2081, 1768, 2909, 1808,\n",
      "         1203, 2983, 2809, 4248, 3424, 4945, 4458, 3580, 2049, 1776,  762, 4802,\n",
      "         3029,  142, 4142, 2025,  375,   56, 2322, 3395, 3992, 2983,  102,  908,\n",
      "          597, 3706, 1353, 4458, 2781, 3812, 2914, 4860, 4213, 2657, 2658,   79,\n",
      "         3704,  490, 4494,  694,   33, 4508, 3726, 4352, 1528, 2188,  503, 3758,\n",
      "         2623, 4628,  743, 4881, 3388, 3242, 3149, 3349,  230,  610, 1953, 4306,\n",
      "         1782, 3675, 4155, 3474, 3534, 4280, 1857, 3153,  432,  996, 4075,  997,\n",
      "         2349, 1377, 4171, 2096]], device='cuda:0') torch.Size([2, 100])\n",
      "trg  -1   -- tensor([[ 310, 3537,  936, 2845, 1247, 3988, 1072, 1915,  120,  921,  405, 1128,\n",
      "         1054, 1818, 1870,   93,  338,  409, 1702, 3382, 1073, 1102,  572, 3321,\n",
      "           14, 2674,  856, 3750, 3724, 4832, 2651,  325, 2766,  484, 3238,  298,\n",
      "          716, 4581, 1245, 2972, 1239, 3883, 1069, 2070,  276, 2682, 3221, 1493,\n",
      "         2264, 4805, 4444, 2676,  499,  871, 2640, 2655, 1071, 3351, 4671, 2991,\n",
      "         3005, 3769, 1749, 1116, 3518, 4397, 4928, 3746, 2485, 1111, 2266, 1120,\n",
      "         4890, 3331, 2926, 4093,  537, 4586,  382, 2109, 4952, 1315, 4032, 3925,\n",
      "         3847, 3960,  599, 1154, 3053, 3837,   25,  312, 1610, 2772, 2647,  159,\n",
      "         2929, 1537, 2389],\n",
      "        [3939, 2051,  226, 2678, 3565, 4498,  247, 1404, 2418, 4168, 3602,  915,\n",
      "         1803, 1057, 3400,  723, 1285, 3816, 4483, 4443, 2081, 1768, 2909, 1808,\n",
      "         1203, 2983, 2809, 4248, 3424, 4945, 4458, 3580, 2049, 1776,  762, 4802,\n",
      "         3029,  142, 4142, 2025,  375,   56, 2322, 3395, 3992, 2983,  102,  908,\n",
      "          597, 3706, 1353, 4458, 2781, 3812, 2914, 4860, 4213, 2657, 2658,   79,\n",
      "         3704,  490, 4494,  694,   33, 4508, 3726, 4352, 1528, 2188,  503, 3758,\n",
      "         2623, 4628,  743, 4881, 3388, 3242, 3149, 3349,  230,  610, 1953, 4306,\n",
      "         1782, 3675, 4155, 3474, 3534, 4280, 1857, 3153,  432,  996, 4075,  997,\n",
      "         2349, 1377, 4171]], device='cuda:0') torch.Size([2, 99])\n",
      "forward  tensor([[4997, 2458, 4492, 1115, 4087,  585,  166, 1738, 2802, 2132, 4155, 1752,\n",
      "         3319, 1808, 2164, 3892, 2211, 4077,  124,  496, 4507, 3476,  243, 1731,\n",
      "         4436, 1811,  688, 4567, 2406, 3653, 4214, 4493, 3415, 1190, 2811, 3307,\n",
      "         3747,  719, 2902,  957,  790, 1785, 3376, 2573, 2196,  796, 2908, 3983,\n",
      "         3066, 4278, 1568, 3313,  382, 1562, 2102, 2977, 3678, 4513, 3177, 2748,\n",
      "         4645,   74,  995,  115,  665, 1085, 1935,   81,  197, 2146, 3998,  213,\n",
      "         2949, 3822, 3782,  963,  501, 2008, 4438,  127, 1518,  273, 1507, 3046,\n",
      "         1969, 3640, 1681, 4060, 3535, 3489, 4450,  291, 3663, 3983, 2578,  207,\n",
      "         2695,  679, 2669, 3045],\n",
      "        [4950, 4331,   94, 3183,  901,   95, 1714, 3563, 3864,  116, 4016, 2356,\n",
      "          550, 3772, 3242, 3960, 2030, 1160,  391,  768, 1374,  827, 4873, 3283,\n",
      "         1994, 3517, 4391, 1187, 2219, 4614,  243, 3782, 2883, 3537, 3169, 2340,\n",
      "         2220,  685, 2114, 2267, 2287,  901, 4808, 1191, 3243, 4473, 4601, 4550,\n",
      "         4885,  268, 4980, 1232, 4556,  738, 4332, 3535, 3195,  176, 1875,  947,\n",
      "         2469,  343, 3723, 4926, 3304, 2108, 1921,  207,  489, 1286,  983, 2509,\n",
      "         1673, 1017, 4924, 3259, 3131, 2174,  936, 2833, 4562, 4357, 2624, 1692,\n",
      "         4067, 4415,  886,  615, 1949, 2686, 3072, 3506, 3925,  155,  446,  848,\n",
      "          425, 3711, 1806, 4930]], device='cuda:0') torch.Size([2, 100])\n",
      "forward  tensor([[ 310, 3537,  936, 2845, 1247, 3988, 1072, 1915,  120,  921,  405, 1128,\n",
      "         1054, 1818, 1870,   93,  338,  409, 1702, 3382, 1073, 1102,  572, 3321,\n",
      "           14, 2674,  856, 3750, 3724, 4832, 2651,  325, 2766,  484, 3238,  298,\n",
      "          716, 4581, 1245, 2972, 1239, 3883, 1069, 2070,  276, 2682, 3221, 1493,\n",
      "         2264, 4805, 4444, 2676,  499,  871, 2640, 2655, 1071, 3351, 4671, 2991,\n",
      "         3005, 3769, 1749, 1116, 3518, 4397, 4928, 3746, 2485, 1111, 2266, 1120,\n",
      "         4890, 3331, 2926, 4093,  537, 4586,  382, 2109, 4952, 1315, 4032, 3925,\n",
      "         3847, 3960,  599, 1154, 3053, 3837,   25,  312, 1610, 2772, 2647,  159,\n",
      "         2929, 1537, 2389],\n",
      "        [3939, 2051,  226, 2678, 3565, 4498,  247, 1404, 2418, 4168, 3602,  915,\n",
      "         1803, 1057, 3400,  723, 1285, 3816, 4483, 4443, 2081, 1768, 2909, 1808,\n",
      "         1203, 2983, 2809, 4248, 3424, 4945, 4458, 3580, 2049, 1776,  762, 4802,\n",
      "         3029,  142, 4142, 2025,  375,   56, 2322, 3395, 3992, 2983,  102,  908,\n",
      "          597, 3706, 1353, 4458, 2781, 3812, 2914, 4860, 4213, 2657, 2658,   79,\n",
      "         3704,  490, 4494,  694,   33, 4508, 3726, 4352, 1528, 2188,  503, 3758,\n",
      "         2623, 4628,  743, 4881, 3388, 3242, 3149, 3349,  230,  610, 1953, 4306,\n",
      "         1782, 3675, 4155, 3474, 3534, 4280, 1857, 3153,  432,  996, 4075,  997,\n",
      "         2349, 1377, 4171]], device='cuda:0') torch.Size([2, 99])\n",
      "Epoch: 9, Loss: 6.185723781585693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward  tensor([[4997, 2458, 4492, 1115, 4087,  585,  166, 1738, 2802, 2132, 4155, 1752,\n",
      "         3319, 1808, 2164, 3892, 2211, 4077,  124,  496, 4507, 3476,  243, 1731,\n",
      "         4436, 1811,  688, 4567, 2406, 3653, 4214, 4493, 3415, 1190, 2811, 3307,\n",
      "         3747,  719, 2902,  957,  790, 1785, 3376, 2573, 2196,  796, 2908, 3983,\n",
      "         3066, 4278, 1568, 3313,  382, 1562, 2102, 2977, 3678, 4513, 3177, 2748,\n",
      "         4645,   74,  995,  115,  665, 1085, 1935,   81,  197, 2146, 3998,  213,\n",
      "         2949, 3822, 3782,  963,  501, 2008, 4438,  127, 1518,  273, 1507, 3046,\n",
      "         1969, 3640, 1681, 4060, 3535, 3489, 4450,  291, 3663, 3983, 2578,  207,\n",
      "         2695,  679, 2669, 3045],\n",
      "        [4950, 4331,   94, 3183,  901,   95, 1714, 3563, 3864,  116, 4016, 2356,\n",
      "          550, 3772, 3242, 3960, 2030, 1160,  391,  768, 1374,  827, 4873, 3283,\n",
      "         1994, 3517, 4391, 1187, 2219, 4614,  243, 3782, 2883, 3537, 3169, 2340,\n",
      "         2220,  685, 2114, 2267, 2287,  901, 4808, 1191, 3243, 4473, 4601, 4550,\n",
      "         4885,  268, 4980, 1232, 4556,  738, 4332, 3535, 3195,  176, 1875,  947,\n",
      "         2469,  343, 3723, 4926, 3304, 2108, 1921,  207,  489, 1286,  983, 2509,\n",
      "         1673, 1017, 4924, 3259, 3131, 2174,  936, 2833, 4562, 4357, 2624, 1692,\n",
      "         4067, 4415,  886,  615, 1949, 2686, 3072, 3506, 3925,  155,  446,  848,\n",
      "          425, 3711, 1806, 4930]], device='cuda:0') torch.Size([2, 100])\n",
      "forward  tensor([[ 310, 3537,  936, 2845, 1247, 3988, 1072, 1915,  120,  921,  405, 1128,\n",
      "         1054, 1818, 1870,   93,  338,  409, 1702, 3382, 1073, 1102,  572, 3321,\n",
      "           14, 2674,  856, 3750, 3724, 4832, 2651,  325, 2766,  484, 3238,  298,\n",
      "          716, 4581, 1245, 2972, 1239, 3883, 1069, 2070,  276, 2682, 3221, 1493,\n",
      "         2264, 4805, 4444, 2676,  499,  871, 2640, 2655, 1071, 3351, 4671, 2991,\n",
      "         3005, 3769, 1749, 1116, 3518, 4397, 4928, 3746, 2485, 1111, 2266, 1120,\n",
      "         4890, 3331, 2926, 4093,  537, 4586,  382, 2109, 4952, 1315, 4032, 3925,\n",
      "         3847, 3960,  599, 1154, 3053, 3837,   25,  312, 1610, 2772, 2647,  159,\n",
      "         2929, 1537, 2389],\n",
      "        [3939, 2051,  226, 2678, 3565, 4498,  247, 1404, 2418, 4168, 3602,  915,\n",
      "         1803, 1057, 3400,  723, 1285, 3816, 4483, 4443, 2081, 1768, 2909, 1808,\n",
      "         1203, 2983, 2809, 4248, 3424, 4945, 4458, 3580, 2049, 1776,  762, 4802,\n",
      "         3029,  142, 4142, 2025,  375,   56, 2322, 3395, 3992, 2983,  102,  908,\n",
      "          597, 3706, 1353, 4458, 2781, 3812, 2914, 4860, 4213, 2657, 2658,   79,\n",
      "         3704,  490, 4494,  694,   33, 4508, 3726, 4352, 1528, 2188,  503, 3758,\n",
      "         2623, 4628,  743, 4881, 3388, 3242, 3149, 3349,  230,  610, 1953, 4306,\n",
      "         1782, 3675, 4155, 3474, 3534, 4280, 1857, 3153,  432,  996, 4075,  997,\n",
      "         2349, 1377, 4171]], device='cuda:0') torch.Size([2, 99])\n",
      "Epoch: 9, Loss: 5.623772621154785\n",
      "src  tensor([[4997, 2458, 4492, 1115, 4087,  585,  166, 1738, 2802, 2132, 4155, 1752,\n",
      "         3319, 1808, 2164, 3892, 2211, 4077,  124,  496, 4507, 3476,  243, 1731,\n",
      "         4436, 1811,  688, 4567, 2406, 3653, 4214, 4493, 3415, 1190, 2811, 3307,\n",
      "         3747,  719, 2902,  957,  790, 1785, 3376, 2573, 2196,  796, 2908, 3983,\n",
      "         3066, 4278, 1568, 3313,  382, 1562, 2102, 2977, 3678, 4513, 3177, 2748,\n",
      "         4645,   74,  995,  115,  665, 1085, 1935,   81,  197, 2146, 3998,  213,\n",
      "         2949, 3822, 3782,  963,  501, 2008, 4438,  127, 1518,  273, 1507, 3046,\n",
      "         1969, 3640, 1681, 4060, 3535, 3489, 4450,  291, 3663, 3983, 2578,  207,\n",
      "         2695,  679, 2669, 3045],\n",
      "        [4950, 4331,   94, 3183,  901,   95, 1714, 3563, 3864,  116, 4016, 2356,\n",
      "          550, 3772, 3242, 3960, 2030, 1160,  391,  768, 1374,  827, 4873, 3283,\n",
      "         1994, 3517, 4391, 1187, 2219, 4614,  243, 3782, 2883, 3537, 3169, 2340,\n",
      "         2220,  685, 2114, 2267, 2287,  901, 4808, 1191, 3243, 4473, 4601, 4550,\n",
      "         4885,  268, 4980, 1232, 4556,  738, 4332, 3535, 3195,  176, 1875,  947,\n",
      "         2469,  343, 3723, 4926, 3304, 2108, 1921,  207,  489, 1286,  983, 2509,\n",
      "         1673, 1017, 4924, 3259, 3131, 2174,  936, 2833, 4562, 4357, 2624, 1692,\n",
      "         4067, 4415,  886,  615, 1949, 2686, 3072, 3506, 3925,  155,  446,  848,\n",
      "          425, 3711, 1806, 4930]], device='cuda:0') torch.Size([2, 100])\n",
      "trg  tensor([[ 310, 3537,  936, 2845, 1247, 3988, 1072, 1915,  120,  921,  405, 1128,\n",
      "         1054, 1818, 1870,   93,  338,  409, 1702, 3382, 1073, 1102,  572, 3321,\n",
      "           14, 2674,  856, 3750, 3724, 4832, 2651,  325, 2766,  484, 3238,  298,\n",
      "          716, 4581, 1245, 2972, 1239, 3883, 1069, 2070,  276, 2682, 3221, 1493,\n",
      "         2264, 4805, 4444, 2676,  499,  871, 2640, 2655, 1071, 3351, 4671, 2991,\n",
      "         3005, 3769, 1749, 1116, 3518, 4397, 4928, 3746, 2485, 1111, 2266, 1120,\n",
      "         4890, 3331, 2926, 4093,  537, 4586,  382, 2109, 4952, 1315, 4032, 3925,\n",
      "         3847, 3960,  599, 1154, 3053, 3837,   25,  312, 1610, 2772, 2647,  159,\n",
      "         2929, 1537, 2389,  616],\n",
      "        [3939, 2051,  226, 2678, 3565, 4498,  247, 1404, 2418, 4168, 3602,  915,\n",
      "         1803, 1057, 3400,  723, 1285, 3816, 4483, 4443, 2081, 1768, 2909, 1808,\n",
      "         1203, 2983, 2809, 4248, 3424, 4945, 4458, 3580, 2049, 1776,  762, 4802,\n",
      "         3029,  142, 4142, 2025,  375,   56, 2322, 3395, 3992, 2983,  102,  908,\n",
      "          597, 3706, 1353, 4458, 2781, 3812, 2914, 4860, 4213, 2657, 2658,   79,\n",
      "         3704,  490, 4494,  694,   33, 4508, 3726, 4352, 1528, 2188,  503, 3758,\n",
      "         2623, 4628,  743, 4881, 3388, 3242, 3149, 3349,  230,  610, 1953, 4306,\n",
      "         1782, 3675, 4155, 3474, 3534, 4280, 1857, 3153,  432,  996, 4075,  997,\n",
      "         2349, 1377, 4171, 2096]], device='cuda:0') torch.Size([2, 100])\n",
      "trg  -1   -- tensor([[ 310, 3537,  936, 2845, 1247, 3988, 1072, 1915,  120,  921,  405, 1128,\n",
      "         1054, 1818, 1870,   93,  338,  409, 1702, 3382, 1073, 1102,  572, 3321,\n",
      "           14, 2674,  856, 3750, 3724, 4832, 2651,  325, 2766,  484, 3238,  298,\n",
      "          716, 4581, 1245, 2972, 1239, 3883, 1069, 2070,  276, 2682, 3221, 1493,\n",
      "         2264, 4805, 4444, 2676,  499,  871, 2640, 2655, 1071, 3351, 4671, 2991,\n",
      "         3005, 3769, 1749, 1116, 3518, 4397, 4928, 3746, 2485, 1111, 2266, 1120,\n",
      "         4890, 3331, 2926, 4093,  537, 4586,  382, 2109, 4952, 1315, 4032, 3925,\n",
      "         3847, 3960,  599, 1154, 3053, 3837,   25,  312, 1610, 2772, 2647,  159,\n",
      "         2929, 1537, 2389],\n",
      "        [3939, 2051,  226, 2678, 3565, 4498,  247, 1404, 2418, 4168, 3602,  915,\n",
      "         1803, 1057, 3400,  723, 1285, 3816, 4483, 4443, 2081, 1768, 2909, 1808,\n",
      "         1203, 2983, 2809, 4248, 3424, 4945, 4458, 3580, 2049, 1776,  762, 4802,\n",
      "         3029,  142, 4142, 2025,  375,   56, 2322, 3395, 3992, 2983,  102,  908,\n",
      "          597, 3706, 1353, 4458, 2781, 3812, 2914, 4860, 4213, 2657, 2658,   79,\n",
      "         3704,  490, 4494,  694,   33, 4508, 3726, 4352, 1528, 2188,  503, 3758,\n",
      "         2623, 4628,  743, 4881, 3388, 3242, 3149, 3349,  230,  610, 1953, 4306,\n",
      "         1782, 3675, 4155, 3474, 3534, 4280, 1857, 3153,  432,  996, 4075,  997,\n",
      "         2349, 1377, 4171]], device='cuda:0') torch.Size([2, 99])\n",
      "forward  tensor([[4997, 2458, 4492, 1115, 4087,  585,  166, 1738, 2802, 2132, 4155, 1752,\n",
      "         3319, 1808, 2164, 3892, 2211, 4077,  124,  496, 4507, 3476,  243, 1731,\n",
      "         4436, 1811,  688, 4567, 2406, 3653, 4214, 4493, 3415, 1190, 2811, 3307,\n",
      "         3747,  719, 2902,  957,  790, 1785, 3376, 2573, 2196,  796, 2908, 3983,\n",
      "         3066, 4278, 1568, 3313,  382, 1562, 2102, 2977, 3678, 4513, 3177, 2748,\n",
      "         4645,   74,  995,  115,  665, 1085, 1935,   81,  197, 2146, 3998,  213,\n",
      "         2949, 3822, 3782,  963,  501, 2008, 4438,  127, 1518,  273, 1507, 3046,\n",
      "         1969, 3640, 1681, 4060, 3535, 3489, 4450,  291, 3663, 3983, 2578,  207,\n",
      "         2695,  679, 2669, 3045],\n",
      "        [4950, 4331,   94, 3183,  901,   95, 1714, 3563, 3864,  116, 4016, 2356,\n",
      "          550, 3772, 3242, 3960, 2030, 1160,  391,  768, 1374,  827, 4873, 3283,\n",
      "         1994, 3517, 4391, 1187, 2219, 4614,  243, 3782, 2883, 3537, 3169, 2340,\n",
      "         2220,  685, 2114, 2267, 2287,  901, 4808, 1191, 3243, 4473, 4601, 4550,\n",
      "         4885,  268, 4980, 1232, 4556,  738, 4332, 3535, 3195,  176, 1875,  947,\n",
      "         2469,  343, 3723, 4926, 3304, 2108, 1921,  207,  489, 1286,  983, 2509,\n",
      "         1673, 1017, 4924, 3259, 3131, 2174,  936, 2833, 4562, 4357, 2624, 1692,\n",
      "         4067, 4415,  886,  615, 1949, 2686, 3072, 3506, 3925,  155,  446,  848,\n",
      "          425, 3711, 1806, 4930]], device='cuda:0') torch.Size([2, 100])\n",
      "forward  tensor([[ 310, 3537,  936, 2845, 1247, 3988, 1072, 1915,  120,  921,  405, 1128,\n",
      "         1054, 1818, 1870,   93,  338,  409, 1702, 3382, 1073, 1102,  572, 3321,\n",
      "           14, 2674,  856, 3750, 3724, 4832, 2651,  325, 2766,  484, 3238,  298,\n",
      "          716, 4581, 1245, 2972, 1239, 3883, 1069, 2070,  276, 2682, 3221, 1493,\n",
      "         2264, 4805, 4444, 2676,  499,  871, 2640, 2655, 1071, 3351, 4671, 2991,\n",
      "         3005, 3769, 1749, 1116, 3518, 4397, 4928, 3746, 2485, 1111, 2266, 1120,\n",
      "         4890, 3331, 2926, 4093,  537, 4586,  382, 2109, 4952, 1315, 4032, 3925,\n",
      "         3847, 3960,  599, 1154, 3053, 3837,   25,  312, 1610, 2772, 2647,  159,\n",
      "         2929, 1537, 2389],\n",
      "        [3939, 2051,  226, 2678, 3565, 4498,  247, 1404, 2418, 4168, 3602,  915,\n",
      "         1803, 1057, 3400,  723, 1285, 3816, 4483, 4443, 2081, 1768, 2909, 1808,\n",
      "         1203, 2983, 2809, 4248, 3424, 4945, 4458, 3580, 2049, 1776,  762, 4802,\n",
      "         3029,  142, 4142, 2025,  375,   56, 2322, 3395, 3992, 2983,  102,  908,\n",
      "          597, 3706, 1353, 4458, 2781, 3812, 2914, 4860, 4213, 2657, 2658,   79,\n",
      "         3704,  490, 4494,  694,   33, 4508, 3726, 4352, 1528, 2188,  503, 3758,\n",
      "         2623, 4628,  743, 4881, 3388, 3242, 3149, 3349,  230,  610, 1953, 4306,\n",
      "         1782, 3675, 4155, 3474, 3534, 4280, 1857, 3153,  432,  996, 4075,  997,\n",
      "         2349, 1377, 4171]], device='cuda:0') torch.Size([2, 99])\n",
      "Epoch: 10, Loss: 5.928998947143555\n",
      "forward  tensor([[4997, 2458, 4492, 1115, 4087,  585,  166, 1738, 2802, 2132, 4155, 1752,\n",
      "         3319, 1808, 2164, 3892, 2211, 4077,  124,  496, 4507, 3476,  243, 1731,\n",
      "         4436, 1811,  688, 4567, 2406, 3653, 4214, 4493, 3415, 1190, 2811, 3307,\n",
      "         3747,  719, 2902,  957,  790, 1785, 3376, 2573, 2196,  796, 2908, 3983,\n",
      "         3066, 4278, 1568, 3313,  382, 1562, 2102, 2977, 3678, 4513, 3177, 2748,\n",
      "         4645,   74,  995,  115,  665, 1085, 1935,   81,  197, 2146, 3998,  213,\n",
      "         2949, 3822, 3782,  963,  501, 2008, 4438,  127, 1518,  273, 1507, 3046,\n",
      "         1969, 3640, 1681, 4060, 3535, 3489, 4450,  291, 3663, 3983, 2578,  207,\n",
      "         2695,  679, 2669, 3045],\n",
      "        [4950, 4331,   94, 3183,  901,   95, 1714, 3563, 3864,  116, 4016, 2356,\n",
      "          550, 3772, 3242, 3960, 2030, 1160,  391,  768, 1374,  827, 4873, 3283,\n",
      "         1994, 3517, 4391, 1187, 2219, 4614,  243, 3782, 2883, 3537, 3169, 2340,\n",
      "         2220,  685, 2114, 2267, 2287,  901, 4808, 1191, 3243, 4473, 4601, 4550,\n",
      "         4885,  268, 4980, 1232, 4556,  738, 4332, 3535, 3195,  176, 1875,  947,\n",
      "         2469,  343, 3723, 4926, 3304, 2108, 1921,  207,  489, 1286,  983, 2509,\n",
      "         1673, 1017, 4924, 3259, 3131, 2174,  936, 2833, 4562, 4357, 2624, 1692,\n",
      "         4067, 4415,  886,  615, 1949, 2686, 3072, 3506, 3925,  155,  446,  848,\n",
      "          425, 3711, 1806, 4930]], device='cuda:0') torch.Size([2, 100])\n",
      "forward  tensor([[ 310, 3537,  936, 2845, 1247, 3988, 1072, 1915,  120,  921,  405, 1128,\n",
      "         1054, 1818, 1870,   93,  338,  409, 1702, 3382, 1073, 1102,  572, 3321,\n",
      "           14, 2674,  856, 3750, 3724, 4832, 2651,  325, 2766,  484, 3238,  298,\n",
      "          716, 4581, 1245, 2972, 1239, 3883, 1069, 2070,  276, 2682, 3221, 1493,\n",
      "         2264, 4805, 4444, 2676,  499,  871, 2640, 2655, 1071, 3351, 4671, 2991,\n",
      "         3005, 3769, 1749, 1116, 3518, 4397, 4928, 3746, 2485, 1111, 2266, 1120,\n",
      "         4890, 3331, 2926, 4093,  537, 4586,  382, 2109, 4952, 1315, 4032, 3925,\n",
      "         3847, 3960,  599, 1154, 3053, 3837,   25,  312, 1610, 2772, 2647,  159,\n",
      "         2929, 1537, 2389],\n",
      "        [3939, 2051,  226, 2678, 3565, 4498,  247, 1404, 2418, 4168, 3602,  915,\n",
      "         1803, 1057, 3400,  723, 1285, 3816, 4483, 4443, 2081, 1768, 2909, 1808,\n",
      "         1203, 2983, 2809, 4248, 3424, 4945, 4458, 3580, 2049, 1776,  762, 4802,\n",
      "         3029,  142, 4142, 2025,  375,   56, 2322, 3395, 3992, 2983,  102,  908,\n",
      "          597, 3706, 1353, 4458, 2781, 3812, 2914, 4860, 4213, 2657, 2658,   79,\n",
      "         3704,  490, 4494,  694,   33, 4508, 3726, 4352, 1528, 2188,  503, 3758,\n",
      "         2623, 4628,  743, 4881, 3388, 3242, 3149, 3349,  230,  610, 1953, 4306,\n",
      "         1782, 3675, 4155, 3474, 3534, 4280, 1857, 3153,  432,  996, 4075,  997,\n",
      "         2349, 1377, 4171]], device='cuda:0') torch.Size([2, 99])\n",
      "Epoch: 10, Loss: 5.342638969421387\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n",
    "\n",
    "transformer.train()\n",
    "\n",
    "# Training and validation loop\n",
    "num_epochs = 10\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "\n",
    "for epoch in range(10):\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    transformer.train()\n",
    "    optimizer.zero_grad()\n",
    "    src_data = src_data.to(device=device)\n",
    "    #x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "    #y = y.to(device=device, dtype=torch.long)\n",
    "    tgt_data = tgt_data.to(device=device)\n",
    "    print(\"src \", src_data, src_data.size())\n",
    "    print(\"trg \", tgt_data, tgt_data.size())\n",
    "    print(\"trg  -1   --\", tgt_data[:, :-1], tgt_data[:, :-1].size())\n",
    "    #output = transformer(src_data, tgt_data)\n",
    "    output = transformer(src_data, tgt_data[:, :-1])\n",
    "    loss = criterion(output.contiguous().view(-1, tgt_vocab_size), tgt_data[:, 1:].contiguous().view(-1))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch: {epoch+1}, Loss: {loss.item()}\")\n",
    "    train_loss += loss.item()\n",
    "    train_losses.append(train_loss / len(src_data))\n",
    "\n",
    "    #validation part\n",
    "    #Restructure code with validation set data\n",
    "    transformer.eval()\n",
    "    with torch.no_grad():\n",
    "        #This should be validation set data.\n",
    "        src_data = src_data.to(device=device)\n",
    "        tgt_data = tgt_data.to(device=device)\n",
    "        output = transformer(src_data, tgt_data[:, :-1])\n",
    "        loss = criterion(output.contiguous().view(-1, tgt_vocab_size), tgt_data[:, 1:].contiguous().view(-1))\n",
    "        print(f\"Epoch: {epoch+1}, Loss: {loss.item()}\")\n",
    "        val_loss += loss.item()\n",
    "        val_losses.append(val_loss / len(src_data))\n",
    "        \n",
    "    \n",
    "'''\n",
    "with torch.no_grad():\n",
    "        for inputs, labels in val_dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)  # Move data to GPU\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "        val_losses.append(val_loss / len(val_dataloader))\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_losses[-1]}, Val Loss: {val_losses[-1]}\")\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "# Plot both training and validation losses\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba020b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff175736",
   "metadata": {},
   "outputs": [],
   "source": [
    "#src_data\n",
    "#src_data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f683e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#src_data.size()\n",
    "#src_data = torch.randint(1, src_vocab_size, (64, max_seq_length)).to(device)  # (batch_size, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9541148",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3e2595f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#where reactivity is NaN,\n",
    "# have Nan replaced with average of all numbers in the sequence.\n",
    "\n",
    "#Map sequence letters to numbers.\n",
    "\n",
    "#Looking at Reads and Signal To Noise ..they appear to be somewhat coorelated.\n",
    "\n",
    "#Create Dataset function\n",
    "\n",
    "\n",
    "#In contrastive loss model... you can train based on#\n",
    "#in a sequence which part is 2D fold and which part is 3D fold\n",
    "#See notebook https://www.kaggle.com/code/something4kag/ribonanza-3d-coords-prep\n",
    "#if it can be helpful\n",
    "# Also analyze and which position in the sequence the fold can occur and which fold ended up happening based on the data\n",
    "\n",
    "#another method to formulate contrastive learning model is by deferentiating sequences with low SNR and hence reactivity value will not be with high confidence.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7289ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#In RNA, the most common base pairings you'll find are between the following nucleotide bases:\n",
    "\n",
    "#Adenine (A) and Uracil (U): A forms base pairs with U. This is a fundamental pairing and is commonly seen in RNA molecules, particularly in single-stranded regions. It is important for the stability of stem-loop structures and is a key component of RNA secondary structure.\n",
    "\n",
    "#Guanine (G) and Cytosine (C): G forms base pairs with C, just as it does in DNA. This pairing is less common in RNA secondary structure but is still important for certain RNA molecules. It may be more prevalent in the context of ribozymes and catalytic RNA.\n",
    "\n",
    "#While A-U and G-C are the primary base pairings in RNA, it's essential to understand that RNA can also exhibit non-canonical or non-standard base pairings, especially in more complex RNA structures. These non-canonical pairings can involve different combinations of A, U, G, and C and are often seen in tertiary structures or specialized RNA molecules with specific functions.\n",
    "\n",
    "#The prevalence of A-U and G-C base pairings in an RNA molecule can vary depending on its sequence and function. For instance, regions that need to form stable secondary structures often rely on A-U pairings, while regions involved in catalytic activities may include G-C pairs. RNA structures are diverse and can exhibit a wide range of base pairing interactions to achieve their biological functions.\n",
    "\n",
    "\n",
    "\n",
    "#So a contrastive loss can be formed here where\n",
    "#AU pair GC pair are strong positive - stable\n",
    "#AG, UC are less stable\n",
    "#UG, UA, CG pair are unstable so negative .\n",
    "#\n",
    "#In RNA, the stable base pairs among the four nucleotide bases (A, G, U, and C) follow the standard Watson-Crick base-pairing rules. Here are the stable base pairs among these bases:\n",
    "\n",
    "#GC pairs are more stable than AU pair\n",
    "\n",
    "\n",
    "#So you can tokenzie these pairs in the transformer model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "183db9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Formulate Convolution NN or Dense Net which takes SNR, Reactivity error and feeds into the final layer of Transformer network\n",
    "# As an example\n",
    "#Lowest Reactivity Error and High SNR are  strong positives\n",
    "# Lowest SNR are strong negative.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#sequence length range from 115 to 206 in train dataset.\n",
    "#in final it will range from 207 to 457"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2618f036",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In positional encoding\n",
    "#pos means the position of the word in the sequence.\n",
    "#i means the index for that particular word vector (index of the dimension)\n",
    "#dmodel is the dimension for e.g 512 from the example\n",
    "\n",
    "\n",
    "#For 2 experiment types i.e. DMS and 2A3 you can have start and end  token in a sequence for which data is available.\n",
    "#.e. start_DMS, end_DMS, start_2A3, end_2A3.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "951d6737",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "074cf1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.iloc[:,150:213]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2853d990",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f78da00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assigning reactivity Columns to react_columns dataframe and replacing NaN with 0.000 \n",
    "\n",
    "#del(mean_reactivity)\n",
    "#del(react_columns_New)\n",
    "#del(react_columns)\n",
    "react_columns = df.iloc[:,7:213].fillna(0.000000)\n",
    "\n",
    "#Find mean of reactivity per row\n",
    "#df['mean'] = df.mean(axis=1)\n",
    "react_columns_mean = react_columns.mean(axis=1)\n",
    "#Free up memory\n",
    "del(react_columns)\n",
    "\n",
    "#Now replace NaN in react_columns with mean_reactivity\n",
    "#react_columns_New = df.iloc[:,7:213].fillna(mean_reactivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef2810b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  93%|     | 1523886/1643680 [03:36<00:17, 6764.10it/s]"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "react_columns = df.iloc[:,7:213] #You may have to capture those indices as per sequence length i.e. when it extends to 457\n",
    "\n",
    "# Replace NaN values in each row with values from replace_values array\n",
    "for index, row in tqdm(react_columns.iterrows(), total=len(react_columns), desc=\"Processing rows\"):\n",
    "    react_columns.loc[index] = row.fillna(react_columns_mean[index])\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9b9e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#react_columns_New = df.iloc[:,7:213].fillna(react_columns['mean_reactivity'])\n",
    "#react_columns_New\n",
    "#react_columns.columns\n",
    "\n",
    "\n",
    "#for column_name in tqdm(react_columns.columns, total=len(react_columns.columns), desc=\"Processing\"):\n",
    "#    df[column_name] = react_columns[column_name]\n",
    "    \n",
    "#react_columns['sequence'] = df['experiment_type'] + 'start' + df['sequence']\n",
    "#react_columns['sequence'] = react_columns['sequence'] + 'end' + df['experiment_type']\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ef82b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_map = {'A':1,\n",
    "           'C':2,\n",
    "           'G':3,\n",
    "           'U':4, \n",
    "           'M':5,  #Start token of DMS exp seq\n",
    "           'N':6,  #End token of DMS exp seq\n",
    "           'T':7,  #Start token of 2A3 exp seq\n",
    "           'X':8,  #End token of 2A3 exp seq\n",
    "           'Z':0   #Padding token\n",
    "          }\n",
    "#for s in df.at[0,'sequence']:\n",
    "#    print(seq_map[s])\n",
    "#df\n",
    "\n",
    "#test_cell = [seq_map[s] for s in df.at[0, 'sequence']]\n",
    "#print(test_cell)\n",
    "\n",
    "#len(df.at[0, 'sequence'])\n",
    "# Create a list of random data samples (for demonstration)\n",
    "#max_seq_len = 206 #This will change to 457 in private set  # Set the maximum sequence length to 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f388c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over rows and replace a specific value in all columns\n",
    "\n",
    "#seq = [self.seq_map[s] for s in seq]\n",
    "#for index, row in df.iterrows():\n",
    "# Create a list of random data samples (for demonstration)\n",
    "#max_seq_len = 206 #This will change to 457 in private set  # Set the maximum sequence length to 100\n",
    "\n",
    "df_sq = copy.deepcopy(df['sequence']) #saving a backup of sequences.\n",
    "#react_columns['maped_sequence'] = [' ']*len(react_columns)\n",
    "#for index, row in tqdm(df.iterrows(), total=len(df.rows), desc=\"Processing rows\"):\n",
    "for index, row in tqdm(react_columns.iterrows(), total=len(react_columns), desc=\"Processing rows\"):\n",
    "    if df.at[index, 'experiment_type'] == \"2A3_MaP\":\n",
    "        concat_seq = 'T' + df.at[index, 'sequence'] + 'X'\n",
    "    if df.at[index, 'experiment_type'] == \"DMS_MaP\":\n",
    "        concat_seq = 'M' + df.at[index, 'sequence'] + 'N'\n",
    "    padding = \"Z\"*(max_seq_len - len(df.at[index, 'sequence']))\n",
    "    concatenated_seq = concat_seq + padding\n",
    "    df.at[index, 'sequence'] = [seq_map[s] for s in concatenated_seq]\n",
    "    #react_columns.at[index, 'maped_sequence'] = [seq_map[s] for s in concatenated_seq]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28b38e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(df.at[0, 'sequence'])\n",
    "#df\n",
    "#react_columns['maped_sequence'] = [' ']*len(react_columns)\n",
    "\n",
    "\n",
    "react_columns['reactivity_0207'] = copy.deepcopy(react_columns['reactivity_0206'])\n",
    "react_columns['reactivity_0208'] = copy.deepcopy(react_columns['reactivity_0206'])\n",
    "react_columns['mapped_sequence'] = copy.deepcopy(df['sequence'])\n",
    "react_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd0dd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#react_columns.select_dtypes(exclude=\"NaN\")\n",
    "#df[~df['COLUMN1'].str.contains('TOTAL')]\n",
    "#react_columns.iloc[~react_columns[:,1].str.contains('NaN')]\n",
    "\n",
    "#react_columns.iloc[:,1]\n",
    "\n",
    "#data1 = [[1, 1, 2], [6, 4, 2], [4, 2, 1], [4, 2, 3]]\n",
    "\n",
    "#daf = pd.DataFrame(data1)\n",
    "#print(data1)\n",
    "#print(daf.mean())\n",
    "#react_columns['sequence'][150:170][160]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc100e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom dataset class for your data\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, max_seq_len):\n",
    "        self.data = data\n",
    "        self.max_seq_len = max_seq_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #src_sequence, trg_sequence = [0,1] #self.data[idx]\n",
    "        #src_sequence = self.data['reactivity_0001']\n",
    "        #trg_sequence = self.data['mapped_sequence']\n",
    "        #list_src_trg_seq = self.data.loc[idx].apply(lambda row: row.tolist(), axis=1)\n",
    "        #merged_values = ','.join(map(str, df.loc[row_index_to_merge][:-1]))\n",
    "        #list_src_trg_seq = ','.join(map(str, self.data.loc[row_index_to_merge][:-1]))\n",
    "        #src_sequence = list_src_trg_seq[0:-1]\n",
    "        #srg_sequence = list_src_trg_seq[-1]\n",
    "        \n",
    "        #trg_sequence = ','.join(map(str, self.data.loc[idx][:-1]))\n",
    "        #src_sequence = [','.join(map(str, self.data.loc[idx][-1]))]\n",
    "        \n",
    "        trg_sequence = torch.tensor(self.data.iloc[idx, :].tolist()[:-1])\n",
    "        src_sequence = torch.tensor(self.data.iloc[idx, :].tolist()[-1])\n",
    "        \n",
    "        \n",
    "        #trg_sequence = self.data.iloc[idx, :].totensor()[:-1]\n",
    "        #src_sequence = self.data.iloc[idx, :].totensor()[-1]\n",
    "        \n",
    "        # Pad sequences with zeros to match the length of the longest sequence in each batch\n",
    "        #max_len = max(len(src_sequence), len(trg_sequence), self.max_seq_len)\n",
    "        #src_sequence += [0] * (max_len - len(src_sequence))\n",
    "        #trg_sequence += [0] * (max_len - len(trg_sequence))\n",
    "        #print(\"Index \", idx, \" SRC--\", src_sequence, \" TRG--\", trg_sequence)\n",
    "        #print(\"SRC LEN \", len(src_sequence), \" TRG LEN \", len(trg_sequence))\n",
    "        return src_sequence, trg_sequence\n",
    "\n",
    "\n",
    "\n",
    "#data = []\n",
    "#for _ in range(5):\n",
    "#    src_sequence = [random.randint(1, 100) for _ in range(random.randint(5, max_seq_len))]\n",
    "#    trg_sequence = [random.randint(1, 100) for _ in range(random.randint(5, max_seq_len))]\n",
    "#    data.append((src_sequence, trg_sequence))\n",
    "\n",
    "#print(\"src\", len(src_sequence))\n",
    "#print(\"trg\", len(trg_sequence))\n",
    "\n",
    "#list_src_trg_seq = react_columns.apply(lambda row: row.tolist(), axis=1)\n",
    "\n",
    "    \n",
    "# Create a DataLoader for batching and shuffling\n",
    "batch_size = 64\n",
    "batch_size = 3\n",
    "custom_dataset = CustomDataset(react_columns, max_seq_len)\n",
    "#custom_dataset = CustomDataset(data, max_seq_len)\n",
    "\n",
    "#print(custom_dataset)\n",
    "dataloader = DataLoader(custom_dataset, batch_size=batch_size)\n",
    "\n",
    "  \n",
    "# Example usage in the training loop (as previously shown)\n",
    "#for batch in dataloader:\n",
    "#    print(\"Inside DataLoader Func\")\n",
    "#    src, trg = batch\n",
    "#    print(\"SRC -\", src, src.size())\n",
    "#    print(\"TRG -\", trg, trg.size())\n",
    "    # ...\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51c483f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.encoder_embedding = nn.Embedding(src_vocab_size, d_model)\n",
    "        self.decoder_embedding = nn.Embedding(tgt_vocab_size, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(d_model, max_seq_length)\n",
    "\n",
    "        self.encoder_layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "        self.decoder_layers = nn.ModuleList([DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "\n",
    "        self.fc = nn.Linear(d_model, tgt_vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def generate_mask(self, src, tgt):\n",
    "        #print(\"src \", src)\n",
    "        #print(\"tgt \", tgt)\n",
    "        src_mask = (src != 0).unsqueeze(1).unsqueeze(2)\n",
    "        tgt_mask = (tgt != 0).unsqueeze(1).unsqueeze(3)\n",
    "        seq_length = tgt.size(1)\n",
    "        nopeak_mask = (1 - torch.triu(torch.ones(1, seq_length, seq_length), diagonal=1)).bool().to(device)\n",
    "        tgt_mask = tgt_mask & nopeak_mask\n",
    "        return src_mask, tgt_mask\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        src_mask, tgt_mask = self.generate_mask(src, tgt)\n",
    "        src_embedded = self.dropout(self.positional_encoding(self.encoder_embedding(src)))\n",
    "        tgt_embedded = self.dropout(self.positional_encoding(self.decoder_embedding(tgt)))\n",
    "\n",
    "        enc_output = src_embedded\n",
    "        for enc_layer in self.encoder_layers:\n",
    "            enc_output = enc_layer(enc_output, src_mask)\n",
    "\n",
    "        dec_output = tgt_embedded\n",
    "        for dec_layer in self.decoder_layers:\n",
    "            dec_output = dec_layer(dec_output, enc_output, src_mask, tgt_mask)\n",
    "\n",
    "        output = self.fc(dec_output)\n",
    "        #include here FC layers with output dimension = input dimension of the sequence (considering padding this will be const number)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa9b82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab_size = 5000\n",
    "#tgt_vocab_size = 5000\n",
    "tgt_vocab_size = 206\n",
    "d_model = 512\n",
    "num_heads = 8\n",
    "num_layers = 6\n",
    "d_ff = 2048\n",
    "max_seq_length = max_seq_len\n",
    "dropout = 0.1\n",
    "\n",
    "# Generate random sample data\n",
    "#src_data = torch.randint(1, src_vocab_size, (64, max_seq_length)).to(device)  # (batch_size, seq_length)\n",
    "#tgt_data = torch.randint(1, tgt_vocab_size, (64, max_seq_length)).to(device)  # (batch_size, seq_length)\n",
    "\n",
    "transformer = Transformer(src_vocab_size, tgt_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353174f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n",
    "\n",
    "transformer.train()\n",
    "for epoch in range(3):\n",
    "    for src_data, tgt_data in dataloader:\n",
    "        #    print(\"Inside DataLoader Func\")\n",
    "        #src_data, trg_data = src_data.to(device), trg_data.to(device)\n",
    "        #print(\"SRC -\", src, src.size())\n",
    "        #print(\"TRG -\", trg, trg.size())\n",
    "        #src_data = torch.tensor(src_data)\n",
    "        #trg_data = torch.tensor(trg_data)\n",
    "        src_data, tgt_data = src_data.to(device), tgt_data.to(device)\n",
    "        train_loss = 0\n",
    "        val_loss = 0\n",
    "        transformer.train()\n",
    "        optimizer.zero_grad()\n",
    "        #src_data = src_data.to(device)\n",
    "        #x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "        #y = y.to(device=device, dtype=torch.long)\n",
    "        #tgt_data = tgt_data.to(device)\n",
    "        #print(\"TRG DATA \", tgt_data.size())\n",
    "        output = transformer(src_data, tgt_data[:, :-1])\n",
    "        #output = transformer(src_data, tgt_data)\n",
    "        loss = criterion(output.contiguous().view(-1, tgt_vocab_size), tgt_data[:, 1:].contiguous().view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"Epoch: {epoch+1}, Loss: {loss.item()}\")\n",
    "        train_loss += loss.item()\n",
    "        train_losses.append(train_loss / len(src_data))\n",
    "\n",
    "        #validation part\n",
    "        #Restructure code with validation set data\n",
    "        transformer.eval()\n",
    "        with torch.no_grad():\n",
    "            #This should be validation set data.\n",
    "            src_data = src_data.to(device=device)\n",
    "            tgt_data = tgt_data.to(device=device)\n",
    "            output = transformer(src_data, tgt_data[:, :-1])\n",
    "            loss = criterion(output.contiguous().view(-1, tgt_vocab_size), tgt_data[:, 1:].contiguous().view(-1))\n",
    "            print(f\"Epoch: {epoch+1}, Loss: {loss.item()}\")\n",
    "            val_loss += loss.item()\n",
    "            val_losses.append(val_loss / len(src_data))\n",
    "        \n",
    "# Plot both training and validation losses\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9984430",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd47dcfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
