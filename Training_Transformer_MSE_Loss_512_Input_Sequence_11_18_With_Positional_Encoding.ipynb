{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10dd24c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from transformer import Transformer \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import math\n",
    "import copy\n",
    "import os\n",
    "import gc\n",
    "import random\n",
    "import numpy as np\n",
    "#import polars as pl\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset, random_split\n",
    "import fastai\n",
    "from fastai.vision.all import *\n",
    "\n",
    "import math\n",
    "import copy\n",
    "\n",
    "# Check if a GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#device = \"cpu\"\n",
    "\n",
    "\n",
    "max_seq_len = 510 + 2  # +2 is added to cover start and end token of sequence This will change to 457 in private set  # Set the maximum sequence length to 100\n",
    "data_preprocessing_done = 0\n",
    "save_pkl = 0\n",
    "load_pkl = 0\n",
    "small_dataset = 0\n",
    "\n",
    "#Training Data\n",
    "if small_dataset == 1:\n",
    "    \n",
    "    #Uncomment this section when uploading the jupyter notebook\n",
    "    '''\n",
    "    df_read = pd.read_csv('/media/spartans/COMMON:/RNA_Project/train_data.csv')\n",
    "    \n",
    "    criteria_2A3 = (df_read['experiment_type'] == '2A3_MaP') & (df_read['SN_filter'] == 1)\n",
    "    criteria_DMS = (df_read['experiment_type'] == 'DMS_MaP') & (df_read['SN_filter'] == 1)\n",
    "\n",
    "    df_2A3_Filter1 = df_read[criteria_2A3]\n",
    "    df_2A3_Filter1 = df_2A3_Filter1.head(4)\n",
    "\n",
    "    df_DMS_Filter1 = df_read[criteria_DMS]\n",
    "    df_DMS_Filter1 = df_DMS_Filter1.head(4)\n",
    "\n",
    "   \n",
    "    df = pd.concat([df_2A3_Filter1, df_DMS_Filter1], ignore_index=True)\n",
    "    \n",
    "    df.to_csv('2A3_DMS_With_Filter1_Train_Data.csv', index=False)\n",
    "    #df_2A3_Filter1.to_csv('2A3_DMS_With_Filter1_Train_Data.csv', index=False)\n",
    "    '''\n",
    "    df = pd.read_csv('2A3_DMS_With_Filter1_Train_Data.csv')\n",
    "    #df = pd.read_csv('DMS_Data.csv')\n",
    "    #df = pd.read_csv('2A3_Data.csv')\n",
    "else:\n",
    "    df = pd.read_csv('/media/spartans/COMMON:/RNA_Project/train_data.csv')\n",
    "    \n",
    "\n",
    "#test_df = pd.read_csv('/media/spartans/COMMON:/RNA_Project/test_sequences.csv')\n",
    "TEST_PATH = \"/media/spartans/COMMON:/RNA_Project/test_sequences.csv\"\n",
    "SUBMISSION_PATH = \"/media/spartans/COMMON:/RNA_Project/submission_0.csv\"\n",
    "SAMPLE_SUBMISSION_PATH = \"/media/spartans/COMMON:/RNA_Project/sample_submission.csv\"\n",
    "MODEL_NAME = \"Trained_Model.model_512_11_18_2023\"\n",
    "\n",
    "seed=69\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = str(1)\n",
    "\n",
    "os.environ['TORCH_USE_CUDA_DSA'] = str(1)\n",
    "\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "seed_everything(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2deb452f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>sequence</th>\n",
       "      <th>experiment_type</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>reads</th>\n",
       "      <th>signal_to_noise</th>\n",
       "      <th>SN_filter</th>\n",
       "      <th>reactivity_0001</th>\n",
       "      <th>reactivity_0002</th>\n",
       "      <th>reactivity_0003</th>\n",
       "      <th>...</th>\n",
       "      <th>reactivity_error_0197</th>\n",
       "      <th>reactivity_error_0198</th>\n",
       "      <th>reactivity_error_0199</th>\n",
       "      <th>reactivity_error_0200</th>\n",
       "      <th>reactivity_error_0201</th>\n",
       "      <th>reactivity_error_0202</th>\n",
       "      <th>reactivity_error_0203</th>\n",
       "      <th>reactivity_error_0204</th>\n",
       "      <th>reactivity_error_0205</th>\n",
       "      <th>reactivity_error_0206</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51e61fbde94d</td>\n",
       "      <td>GGGAACGACUCGAGUAGAGUCGAAAAACAUUGAUAUGGAUUUACUCCGAGGAGACGAACUACCACGAACAGGGGAAACUCUACCCGUGGCGUCUCCGUUUGACGAGUAAGUCCUAAGUCAACAUGCACAGCGCUGGGUUCGCCCAGCGCAAAAGAAACAACAACAACAAC</td>\n",
       "      <td>2A3_MaP</td>\n",
       "      <td>15k_2A3</td>\n",
       "      <td>5326</td>\n",
       "      <td>1.933</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25ce8d5109cd</td>\n",
       "      <td>GGGAACGACUCGAGUAGAGUCGAAAAACCUUGAUAUGGAUUUACUCCGAGGAGACGAACUACCACGAACAGGGGAAACUCUACCCGUGGCGUCUCCGUUUGACGAGUAAGUCCUAAGUCAACAUGCAUGGGUCCUCCUUCGGGAGGACCAAAAGAAACAACAACAACAAC</td>\n",
       "      <td>2A3_MaP</td>\n",
       "      <td>15k_2A3</td>\n",
       "      <td>4647</td>\n",
       "      <td>2.347</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>07dcfb6d1965</td>\n",
       "      <td>GGGAACGACUCGAGUAGAGUCGAAAAACUUUGAUAUGGAUUUACUCCGAGGAGACGAACUACCACGAACAGGGGAAACUCUACCCGUGGCGUCUCCGUUUGACGAGUAAGUCCUAAGUCAACAUGCCAGGUAUUGACUUCGGUCAAUACAAAAGAAACAACAACAACAAC</td>\n",
       "      <td>2A3_MaP</td>\n",
       "      <td>15k_2A3</td>\n",
       "      <td>102843</td>\n",
       "      <td>11.824</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e561cc042a4c</td>\n",
       "      <td>GGGAACGACUCGAGUAGAGUCGAAAAACGAUGAUAUGGAUUUACUCCGAGGAGACGAACUACCACGAACAGGGGAAACUCUACCCGUGGCGUCUCCGUUUGACGAGUAAGUCCUAAGUCAACAUGCAUGCAUGCGGCUUCGGCCGCAUGAAAAGAAACAACAACAACAAC</td>\n",
       "      <td>2A3_MaP</td>\n",
       "      <td>15k_2A3</td>\n",
       "      <td>7665</td>\n",
       "      <td>3.519</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25ce8d5109cd</td>\n",
       "      <td>GGGAACGACUCGAGUAGAGUCGAAAAACCUUGAUAUGGAUUUACUCCGAGGAGACGAACUACCACGAACAGGGGAAACUCUACCCGUGGCGUCUCCGUUUGACGAGUAAGUCCUAAGUCAACAUGCAUGGGUCCUCCUUCGGGAGGACCAAAAGAAACAACAACAACAAC</td>\n",
       "      <td>DMS_MaP</td>\n",
       "      <td>15k_DMS</td>\n",
       "      <td>1964</td>\n",
       "      <td>1.848</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>07dcfb6d1965</td>\n",
       "      <td>GGGAACGACUCGAGUAGAGUCGAAAAACUUUGAUAUGGAUUUACUCCGAGGAGACGAACUACCACGAACAGGGGAAACUCUACCCGUGGCGUCUCCGUUUGACGAGUAAGUCCUAAGUCAACAUGCCAGGUAUUGACUUCGGUCAAUACAAAAGAAACAACAACAACAAC</td>\n",
       "      <td>DMS_MaP</td>\n",
       "      <td>15k_DMS</td>\n",
       "      <td>45863</td>\n",
       "      <td>9.291</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>e561cc042a4c</td>\n",
       "      <td>GGGAACGACUCGAGUAGAGUCGAAAAACGAUGAUAUGGAUUUACUCCGAGGAGACGAACUACCACGAACAGGGGAAACUCUACCCGUGGCGUCUCCGUUUGACGAGUAAGUCCUAAGUCAACAUGCAUGCAUGCGGCUUCGGCCGCAUGAAAAGAAACAACAACAACAAC</td>\n",
       "      <td>DMS_MaP</td>\n",
       "      <td>15k_DMS</td>\n",
       "      <td>6219</td>\n",
       "      <td>3.210</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>aa948762535f</td>\n",
       "      <td>GGGAACGACUCGAGUAGAGUCGAAAAACGCUGAUAUGGAUUUACUCCGAGGAGACGAACUACCACGAACAGGGGAAACUCUACCCGUGGCGUCUCCGUUUGACGAGUAAGUCCUAAGUCAACAUGCCAGGGUGUCACUUCGGUGACACCAAAAGAAACAACAACAACAAC</td>\n",
       "      <td>DMS_MaP</td>\n",
       "      <td>15k_DMS</td>\n",
       "      <td>7024</td>\n",
       "      <td>3.109</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 419 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    sequence_id  \\\n",
       "0  51e61fbde94d   \n",
       "1  25ce8d5109cd   \n",
       "2  07dcfb6d1965   \n",
       "3  e561cc042a4c   \n",
       "4  25ce8d5109cd   \n",
       "5  07dcfb6d1965   \n",
       "6  e561cc042a4c   \n",
       "7  aa948762535f   \n",
       "\n",
       "                                                                                                                                                                     sequence  \\\n",
       "0  GGGAACGACUCGAGUAGAGUCGAAAAACAUUGAUAUGGAUUUACUCCGAGGAGACGAACUACCACGAACAGGGGAAACUCUACCCGUGGCGUCUCCGUUUGACGAGUAAGUCCUAAGUCAACAUGCACAGCGCUGGGUUCGCCCAGCGCAAAAGAAACAACAACAACAAC   \n",
       "1  GGGAACGACUCGAGUAGAGUCGAAAAACCUUGAUAUGGAUUUACUCCGAGGAGACGAACUACCACGAACAGGGGAAACUCUACCCGUGGCGUCUCCGUUUGACGAGUAAGUCCUAAGUCAACAUGCAUGGGUCCUCCUUCGGGAGGACCAAAAGAAACAACAACAACAAC   \n",
       "2  GGGAACGACUCGAGUAGAGUCGAAAAACUUUGAUAUGGAUUUACUCCGAGGAGACGAACUACCACGAACAGGGGAAACUCUACCCGUGGCGUCUCCGUUUGACGAGUAAGUCCUAAGUCAACAUGCCAGGUAUUGACUUCGGUCAAUACAAAAGAAACAACAACAACAAC   \n",
       "3  GGGAACGACUCGAGUAGAGUCGAAAAACGAUGAUAUGGAUUUACUCCGAGGAGACGAACUACCACGAACAGGGGAAACUCUACCCGUGGCGUCUCCGUUUGACGAGUAAGUCCUAAGUCAACAUGCAUGCAUGCGGCUUCGGCCGCAUGAAAAGAAACAACAACAACAAC   \n",
       "4  GGGAACGACUCGAGUAGAGUCGAAAAACCUUGAUAUGGAUUUACUCCGAGGAGACGAACUACCACGAACAGGGGAAACUCUACCCGUGGCGUCUCCGUUUGACGAGUAAGUCCUAAGUCAACAUGCAUGGGUCCUCCUUCGGGAGGACCAAAAGAAACAACAACAACAAC   \n",
       "5  GGGAACGACUCGAGUAGAGUCGAAAAACUUUGAUAUGGAUUUACUCCGAGGAGACGAACUACCACGAACAGGGGAAACUCUACCCGUGGCGUCUCCGUUUGACGAGUAAGUCCUAAGUCAACAUGCCAGGUAUUGACUUCGGUCAAUACAAAAGAAACAACAACAACAAC   \n",
       "6  GGGAACGACUCGAGUAGAGUCGAAAAACGAUGAUAUGGAUUUACUCCGAGGAGACGAACUACCACGAACAGGGGAAACUCUACCCGUGGCGUCUCCGUUUGACGAGUAAGUCCUAAGUCAACAUGCAUGCAUGCGGCUUCGGCCGCAUGAAAAGAAACAACAACAACAAC   \n",
       "7  GGGAACGACUCGAGUAGAGUCGAAAAACGCUGAUAUGGAUUUACUCCGAGGAGACGAACUACCACGAACAGGGGAAACUCUACCCGUGGCGUCUCCGUUUGACGAGUAAGUCCUAAGUCAACAUGCCAGGGUGUCACUUCGGUGACACCAAAAGAAACAACAACAACAAC   \n",
       "\n",
       "  experiment_type dataset_name   reads  signal_to_noise  SN_filter  \\\n",
       "0         2A3_MaP      15k_2A3    5326            1.933          1   \n",
       "1         2A3_MaP      15k_2A3    4647            2.347          1   \n",
       "2         2A3_MaP      15k_2A3  102843           11.824          1   \n",
       "3         2A3_MaP      15k_2A3    7665            3.519          1   \n",
       "4         DMS_MaP      15k_DMS    1964            1.848          1   \n",
       "5         DMS_MaP      15k_DMS   45863            9.291          1   \n",
       "6         DMS_MaP      15k_DMS    6219            3.210          1   \n",
       "7         DMS_MaP      15k_DMS    7024            3.109          1   \n",
       "\n",
       "   reactivity_0001  reactivity_0002  reactivity_0003  ...  \\\n",
       "0              NaN              NaN              NaN  ...   \n",
       "1              NaN              NaN              NaN  ...   \n",
       "2              NaN              NaN              NaN  ...   \n",
       "3              NaN              NaN              NaN  ...   \n",
       "4              NaN              NaN              NaN  ...   \n",
       "5              NaN              NaN              NaN  ...   \n",
       "6              NaN              NaN              NaN  ...   \n",
       "7              NaN              NaN              NaN  ...   \n",
       "\n",
       "   reactivity_error_0197  reactivity_error_0198  reactivity_error_0199  \\\n",
       "0                    NaN                    NaN                    NaN   \n",
       "1                    NaN                    NaN                    NaN   \n",
       "2                    NaN                    NaN                    NaN   \n",
       "3                    NaN                    NaN                    NaN   \n",
       "4                    NaN                    NaN                    NaN   \n",
       "5                    NaN                    NaN                    NaN   \n",
       "6                    NaN                    NaN                    NaN   \n",
       "7                    NaN                    NaN                    NaN   \n",
       "\n",
       "   reactivity_error_0200  reactivity_error_0201  reactivity_error_0202  \\\n",
       "0                    NaN                    NaN                    NaN   \n",
       "1                    NaN                    NaN                    NaN   \n",
       "2                    NaN                    NaN                    NaN   \n",
       "3                    NaN                    NaN                    NaN   \n",
       "4                    NaN                    NaN                    NaN   \n",
       "5                    NaN                    NaN                    NaN   \n",
       "6                    NaN                    NaN                    NaN   \n",
       "7                    NaN                    NaN                    NaN   \n",
       "\n",
       "   reactivity_error_0203  reactivity_error_0204  reactivity_error_0205  \\\n",
       "0                    NaN                    NaN                    NaN   \n",
       "1                    NaN                    NaN                    NaN   \n",
       "2                    NaN                    NaN                    NaN   \n",
       "3                    NaN                    NaN                    NaN   \n",
       "4                    NaN                    NaN                    NaN   \n",
       "5                    NaN                    NaN                    NaN   \n",
       "6                    NaN                    NaN                    NaN   \n",
       "7                    NaN                    NaN                    NaN   \n",
       "\n",
       "   reactivity_error_0206  \n",
       "0                    NaN  \n",
       "1                    NaN  \n",
       "2                    NaN  \n",
       "3                    NaN  \n",
       "4                    NaN  \n",
       "5                    NaN  \n",
       "6                    NaN  \n",
       "7                    NaN  \n",
       "\n",
       "[8 rows x 419 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "#criteria_2A3 = (df_read['experiment_type'] == '2A3_MaP') & (df_read['SN_filter'] == '1')\n",
    "#criteria_DMS = (df_read['experiment_type'] == 'DMS_MaP') & (df_read['SN_filter'] == '1')\n",
    "\n",
    "#criteria_2A3 = ((df_read['experiment_type'] == 'DMS_MaP')  & df_read['SN_filter'] == 1 )\n",
    "#df_2A3_Filter1 = df_read[criteria_2A3]\n",
    "#df_2A3_Filter1\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61508b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#where reactivity is NaN,\n",
    "# have Nan replaced with average of all numbers in the sequence.\n",
    "\n",
    "#Map sequence letters to numbers.\n",
    "\n",
    "#Looking at Reads and Signal To Noise ..they appear to be somewhat coorelated.\n",
    "\n",
    "#Create Dataset function\n",
    "\n",
    "\n",
    "#In contrastive loss model... you can train based on#\n",
    "#in a sequence which part is 2D fold and which part is 3D fold\n",
    "#See notebook https://www.kaggle.com/code/something4kag/ribonanza-3d-coords-prep\n",
    "#if it can be helpful\n",
    "# Also analyze and which position in the sequence the fold can occur and which fold ended up happening based on the data\n",
    "\n",
    "#another method to formulate contrastive learning model is by deferentiating sequences with low SNR and hence reactivity value will not be with high confidence.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db2f1a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#In RNA, the most common base pairings you'll find are between the following nucleotide bases:\n",
    "\n",
    "#Adenine (A) and Uracil (U): A forms base pairs with U. This is a fundamental pairing and is commonly seen in RNA molecules, particularly in single-stranded regions. It is important for the stability of stem-loop structures and is a key component of RNA secondary structure.\n",
    "\n",
    "#Guanine (G) and Cytosine (C): G forms base pairs with C, just as it does in DNA. This pairing is less common in RNA secondary structure but is still important for certain RNA molecules. It may be more prevalent in the context of ribozymes and catalytic RNA.\n",
    "\n",
    "#While A-U and G-C are the primary base pairings in RNA, it's essential to understand that RNA can also exhibit non-canonical or non-standard base pairings, especially in more complex RNA structures. These non-canonical pairings can involve different combinations of A, U, G, and C and are often seen in tertiary structures or specialized RNA molecules with specific functions.\n",
    "\n",
    "#The prevalence of A-U and G-C base pairings in an RNA molecule can vary depending on its sequence and function. For instance, regions that need to form stable secondary structures often rely on A-U pairings, while regions involved in catalytic activities may include G-C pairs. RNA structures are diverse and can exhibit a wide range of base pairing interactions to achieve their biological functions.\n",
    "\n",
    "\n",
    "\n",
    "#So a contrastive loss can be formed here where\n",
    "#AU pair GC pair are strong positive - stable\n",
    "#AG, UC are less stable\n",
    "#UG, UA, CG pair are unstable so negative .\n",
    "#\n",
    "#In RNA, the stable base pairs among the four nucleotide bases (A, G, U, and C) follow the standard Watson-Crick base-pairing rules. Here are the stable base pairs among these bases:\n",
    "\n",
    "#GC pairs are more stable than AU pair\n",
    "\n",
    "\n",
    "#So you can tokenzie these pairs in the transformer model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5b71bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Formulate Convolution NN or Dense Net which takes SNR, Reactivity error and feeds into the final layer of Transformer network\n",
    "# As an example\n",
    "#Lowest Reactivity Error and High SNR are  strong positives\n",
    "# Lowest SNR are strong negative.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#sequence length range from 115 to 206 in train dataset.\n",
    "#in final it will range from 207 to 457"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dbb5976",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In positional encoding\n",
    "#pos means the position of the word in the sequence.\n",
    "#i means the index for that particular word vector (index of the dimension)\n",
    "#dmodel is the dimension for e.g 512 from the example\n",
    "\n",
    "\n",
    "#For 2 experiment types i.e. DMS and 2A3 you can have start and end  token in a sequence for which data is available.\n",
    "#.e. start_DMS, end_DMS, start_2A3, end_2A3.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8607779c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cb051b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_258751/3653553058.py:7: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  react_columns = react_columns.applymap(lambda x: 0 if isinstance(x, (float, int)) and x < 0 else x)\n"
     ]
    }
   ],
   "source": [
    "if data_preprocessing_done == 0:\n",
    "    #Assigning reactivity Columns to react_columns dataframe and replacing NaN with 0.000 \n",
    "\n",
    "    react_columns = df.iloc[:,7:213].fillna(0.000000)\n",
    "\n",
    "    #Find mean of reactivity per row\n",
    "    react_columns = react_columns.applymap(lambda x: 0 if isinstance(x, (float, int)) and x < 0 else x)\n",
    "\n",
    "    react_columns_mean = react_columns.mean(axis=1)\n",
    "    #Free up memory\n",
    "    del(react_columns)\n",
    "\n",
    "    #Now replace NaN in react_columns with mean_reactivity\n",
    "    #react_columns_New = df.iloc[:,7:213].fillna(mean_reactivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac6bd190",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows: 100%|███████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 4928.68it/s]\n",
      "/tmp/ipykernel_258751/1102462686.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  react_columns = react_columns.applymap(lambda x: 0 if isinstance(x, (float, int)) and x < 0 else x)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if data_preprocessing_done == 0:\n",
    "    react_columns = df.iloc[:,7:213] #You may have to capture those indices as per sequence length i.e. when it extends to 457\n",
    "\n",
    "    # Replace NaN values in each row with values from replace_values array\n",
    "    for index, row in tqdm(react_columns.iterrows(), total=len(react_columns), desc=\"Processing rows\"):\n",
    "        react_columns.loc[index] = row.fillna(react_columns_mean[index])\n",
    "    \n",
    "    react_columns = react_columns.applymap(lambda x: 0 if isinstance(x, (float, int)) and x < 0 else x)\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a10cd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_map = {'A':1.0,\n",
    "           'C':2.0,\n",
    "           'G':3.0,\n",
    "           'U':4.0, \n",
    "           'M':5.0,  #Start token of DMS exp seq\n",
    "           'N':6.0,  #End token of DMS exp seq\n",
    "           'T':7.0,  #Start token of 2A3 exp seq\n",
    "           'X':8.0,  #End token of 2A3 exp seq\n",
    "           'Z':0.0   #Padding token\n",
    "          }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57653080",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows: 100%|███████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 7090.96it/s]\n"
     ]
    }
   ],
   "source": [
    "# Iterate over rows and replace a specific value in all columns\n",
    "\n",
    "\n",
    "#max_seq_len = 206 #This will change to 457 in private set  # Set the maximum sequence length to 100\n",
    "if data_preprocessing_done == 0:\n",
    "    df_sq = copy.deepcopy(df['sequence']) #saving a backup of sequences.\n",
    "    #react_columns['maped_sequence'] = [' ']*len(react_columns)\n",
    "    #for index, row in tqdm(df.iterrows(), total=len(df.rows), desc=\"Processing rows\"):\n",
    "    for index, row in tqdm(react_columns.iterrows(), total=len(react_columns), desc=\"Processing rows\"):\n",
    "        if df.at[index, 'experiment_type'] == \"2A3_MaP\":\n",
    "            concat_seq = 'T' + df.at[index, 'sequence'] + 'X'\n",
    "        if df.at[index, 'experiment_type'] == \"DMS_MaP\":\n",
    "            concat_seq = 'M' + df.at[index, 'sequence'] + 'N'\n",
    "        padding = \"Z\"*(max_seq_len - 2 - len(df.at[index, 'sequence']))\n",
    "        concatenated_seq = concat_seq + padding\n",
    "        df.at[index, 'sequence'] = [seq_map[s] for s in concatenated_seq]\n",
    "        #react_columns.at[index, 'maped_sequence'] = [seq_map[s] for s in concatenated_seq]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb2e3e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_258751/834134542.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns['mapped_sequence'] = copy.deepcopy(df['sequence'])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if data_preprocessing_done == 0:\n",
    "    #react_columns['reactivity_0207'] = copy.deepcopy(react_columns['reactivity_0206'])\n",
    "    #react_columns['reactivity_0208'] = copy.deepcopy(react_columns['reactivity_0206'])\n",
    "    for iii in range(207,511):\n",
    "        react_col_name = \"reactivity_0\" + str(iii)\n",
    "        react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
    "        \n",
    "    #replicated_columns = [react_columns['reactivity_0206'].repeat(2)]\n",
    "    #react_columns = pd.concat([react_columns, replicated_columns] , axis=1, ignore_index=True)\n",
    "    #print(react_columns)\n",
    "    react_columns['mapped_sequence'] = copy.deepcopy(df['sequence'])\n",
    "    #del react_columns['reactivity_0207']\n",
    "    #del react_columns['reactivity_0208']\n",
    "if save_pkl == 1:\n",
    "    react_columns.to_pickle(\"react_columns.pkl\")\n",
    "\n",
    "if load_pkl == 1:\n",
    "    react_columns = pd.read_pickle(\"react_columns.pkl\")\n",
    "    \n",
    "#react_columns.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02d4f1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom dataset class for your data\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, max_seq_len):\n",
    "        self.data = data\n",
    "        self.max_seq_len = max_seq_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        trg_sequence = torch.tensor(self.data.iloc[idx, :].tolist()[:-1])\n",
    "        src_sequence = torch.tensor(self.data.iloc[idx, :].tolist()[-1])\n",
    "        \n",
    "        #print(\"Size src seq \", src_sequence.size())\n",
    "        #print(\"Size trg seq \", trg_sequence, trg_sequence.size())\n",
    "        \n",
    "        return src_sequence, trg_sequence\n",
    "\n",
    "    \n",
    "# Create a DataLoader for batching and shuffling\n",
    "batch_size = 64\n",
    "#batch_size = 3\n",
    "\n",
    "\n",
    "# Define the size of the training set\n",
    "dataset_size = len(react_columns)\n",
    "train_size = int(0.5 * dataset_size)\n",
    "test_size = dataset_size - train_size\n",
    "\n",
    "custom_dataset = CustomDataset(react_columns, max_seq_len)\n",
    "train_indices, test_indices = random_split(custom_dataset, [train_size, test_size])\n",
    "train_dataloader = DataLoader(train_indices, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_indices, batch_size=batch_size)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "356a0751",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|███████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.64batch/s]\n",
      "Processing batches: 100%|███████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 24.99batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Training Loss: 0.1612\n",
      "Epoch [1/10], Validation Loss: 0.1881\n",
      "Model Saved because \n",
      "Current average validation loss 0.1881 is less than previous average validation loss 10000000000.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|███████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.71batch/s]\n",
      "Processing batches: 100%|███████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 31.94batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Training Loss: 0.1381\n",
      "Epoch [2/10], Validation Loss: 0.1535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved because \n",
      "Current average validation loss 0.1535 is less than previous average validation loss 0.1881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|███████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.75batch/s]\n",
      "Processing batches: 100%|███████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 31.30batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Training Loss: 0.1130\n",
      "Epoch [3/10], Validation Loss: 0.1390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved because \n",
      "Current average validation loss 0.1390 is less than previous average validation loss 0.1535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|███████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.57batch/s]\n",
      "Processing batches: 100%|███████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 33.98batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Training Loss: 0.0992\n",
      "Epoch [4/10], Validation Loss: 0.1341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved because \n",
      "Current average validation loss 0.1341 is less than previous average validation loss 0.1390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|███████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.62batch/s]\n",
      "Processing batches: 100%|███████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 33.33batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Training Loss: 0.0942\n",
      "Epoch [5/10], Validation Loss: 0.1316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved because \n",
      "Current average validation loss 0.1316 is less than previous average validation loss 0.1341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|███████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.71batch/s]\n",
      "Processing batches: 100%|███████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 32.20batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Training Loss: 0.0915\n",
      "Epoch [6/10], Validation Loss: 0.1305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved because \n",
      "Current average validation loss 0.1305 is less than previous average validation loss 0.1316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|███████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.18batch/s]\n",
      "Processing batches: 100%|███████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 32.93batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Training Loss: 0.0896\n",
      "Epoch [7/10], Validation Loss: 0.1307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|███████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.44batch/s]\n",
      "Processing batches: 100%|███████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 32.10batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Training Loss: 0.0884\n",
      "Epoch [8/10], Validation Loss: 0.1303\n",
      "Model Saved because \n",
      "Current average validation loss 0.1303 is less than previous average validation loss 0.1305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|███████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.71batch/s]\n",
      "Processing batches: 100%|███████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 32.44batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Training Loss: 0.0873\n",
      "Epoch [9/10], Validation Loss: 0.1296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved because \n",
      "Current average validation loss 0.1296 is less than previous average validation loss 0.1303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|███████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.59batch/s]\n",
      "Processing batches: 100%|███████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 33.15batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Training Loss: 0.0851\n",
      "Epoch [10/10], Validation Loss: 0.1299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(device)\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=512):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.encoding = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1).float()\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n",
    "        self.encoding[:, 0::2] = torch.sin(position * div_term)\n",
    "        self.encoding[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.encoding = self.encoding.unsqueeze(0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.encoding = self.encoding.to(x.device)\n",
    "        return x + self.encoding[:, :x.size(1)].detach()\n",
    "    \n",
    "\n",
    "\n",
    "class MyTransformerEncoderLayer(nn.TransformerEncoderLayer):\n",
    "    def __init__(self, d_model, nhead, batch_first=True, **kwargs):\n",
    "        super(MyTransformerEncoderLayer, self).__init__(d_model, nhead, **kwargs)\n",
    "        self.self_attn = nn.MultiheadAttention(d_model, nhead, batch_first=batch_first)\n",
    "\n",
    "\n",
    "class TransformerRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, nhead, num_layers, output_sequence_length, max_len=512):\n",
    "        super(TransformerRegressionModel, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, hidden_dim)\n",
    "        \n",
    "        self.positional_encoding = PositionalEncoding(hidden_dim, max_len=max_len)\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=input_dim, nhead=nhead),\n",
    "            num_layers=num_layers\n",
    "        )\n",
    "        '''\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            MyTransformerEncoderLayer(d_model=hidden_dim, nhead=nhead, batch_first=True),\n",
    "            num_layers=num_layers\n",
    "        )\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.transformer_decoder = nn.TransformerDecoder(\n",
    "            nn.TransformerDecoderLayer(d_model=input_dim, nhead=nhead),\n",
    "            num_layers=num_layers\n",
    "        )\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        self.fc = nn.Linear(input_dim, output_sequence_length * 1)\n",
    "        self.gelu = nn.GELU()\n",
    "        self.output_sequence_length = output_sequence_length\n",
    "\n",
    "\n",
    "    \n",
    "    def forward(self, x):              \n",
    "        \n",
    "        # Ensure that both the model and input are on the same device\n",
    "        device = next(self.parameters()).device\n",
    "        x = x.to(device)\n",
    "        \n",
    "        # Apply embedding to input\n",
    "        #print(\"X shape 1\", x.shape)\n",
    "        x = self.embedding(x)\n",
    "        #print(\"X shape 2\", x.shape)\n",
    "        \n",
    "        x = self.positional_encoding(x)\n",
    "        \n",
    "        # Permute to (sequence_length, batch_size, input_dim)\n",
    "        x = x.permute(1, 0, 2)\n",
    "        #print(\"X shape 3\", x.shape)\n",
    "        \n",
    "        # Encoder forward pass\n",
    "        encoder_output = self.transformer_encoder(x)\n",
    "\n",
    "        # Decoder forward pass with memory from the encoder\n",
    "        decoder_output = self.transformer_decoder(x, memory=encoder_output)\n",
    "\n",
    "        # Global average pooling over the sequence dimension\n",
    "        x = decoder_output.mean(dim=0)\n",
    "\n",
    "        # Final fully connected layer with GELU activation\n",
    "        x = self.gelu(self.fc(x))\n",
    "\n",
    "        return x\n",
    "    \n",
    "\n",
    "# Hyperparameters\n",
    "input_dim =  max_seq_len # Adjust based on your input size\n",
    "hidden_dim = 512\n",
    "nhead = 16\n",
    "num_layers = 6\n",
    "output_sequence_length = max_seq_len - 2  # Adjust based on your output sequence length\n",
    "#batch_size = 1\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001\n",
    "\n",
    "\n",
    "# Instantiate the model, loss function, and optimizer\n",
    "model = TransformerRegressionModel(input_dim, hidden_dim, nhead, num_layers, output_sequence_length).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "#optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9, weight_decay=0, amsgrad=False)\n",
    "\n",
    "\n",
    "\n",
    "training_losses = []  # to store training losses\n",
    "validation_losses = []\n",
    "prev_average_val_loss = 10000000000\n",
    "list_of_avg_loss = []\n",
    "epochss = []\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0.0  # accumulate loss for the entire epoch\n",
    "    val_loss = 0.0\n",
    "    #for inputs, targets in tqdm(train_dataloader.iterrows(), total=len(train_dataloader), desc=\"Processing rows\"):\n",
    "    #with tqdm(train_dataloader, desc=f'Epoch {epoch + 1}/{num_epochs}', unit='batch') as tqdm_loader:\n",
    "    #    for inputs, targets in tqdm_loader:\n",
    "         \n",
    "    model.train()        \n",
    "    #for batch, dat in enumerate(train_dataloader, 1): \n",
    "    for batch, dat in enumerate(tqdm(train_dataloader, desc=\"Processing batches\", unit=\"batch\"), 1):\n",
    "            inputs = dat[0].to(device, dtype=torch.long)\n",
    "            targets = dat[1].to(device).float()\n",
    "            #print(\"INPUT \", inputs)\n",
    "            #print(\"TARGET \", targets)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            #print(\"OUT\", outputs)\n",
    "            #print(f'TRAIN:  Batch {batch}, Input: {inputs.shape}, Outputs: {outputs.shape}, Targets: {targets.shape}')\n",
    "            #Pre-clipping may mean the model may not learn the targets.\n",
    "            outputs[outputs < 0] = 0.0\n",
    "            outputs[outputs > 1] = 1.0\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            #print(f\"Epoch: {epoch+1}, Training Loss: {loss.item()}\")\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        #for batch, dat in enumerate(test_dataloader, 1):\n",
    "        for batch, dat in enumerate(tqdm(test_dataloader, desc=\"Processing batches\", unit=\"batch\"), 1):\n",
    "            inputs = dat[0].to(device, dtype=torch.long)\n",
    "            targets = dat[1].to(device).float()\n",
    "            output = model(inputs)\n",
    "            #print(f'VAL:  Batch {batch}, Input: {inputs.shape}, Outputs: {output.shape}, Targets: {targets.shape}')\n",
    "            loss = criterion(output, targets)\n",
    "            #print(f\"Epoch: {epoch+1}, Validation Loss: {loss.item()}\")\n",
    "            val_loss += loss.item()\n",
    "    \n",
    "    #outputs.requires_grad_(True)\n",
    "    \n",
    "    \n",
    "    average_epoch_loss = epoch_loss / len(train_dataloader)\n",
    "    training_losses.append(average_epoch_loss)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Training Loss: {average_epoch_loss:.4f}')\n",
    "    \n",
    "    average_val_loss = val_loss / len(test_dataloader)\n",
    "    validation_losses.append(average_val_loss)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Validation Loss: {average_val_loss:.4f}')\n",
    "    epochss.append(epoch)\n",
    "    \n",
    "    list_of_avg_loss.append(average_val_loss)\n",
    "    #Save best model Every Epoch\n",
    "    if average_val_loss < prev_average_val_loss:\n",
    "        torch.save(model, MODEL_NAME)\n",
    "        print(\"Model Saved because \")\n",
    "        print(f'Current average validation loss {average_val_loss:.4f} is less than previous average validation loss {prev_average_val_loss:.4f}')\n",
    "    prev_average_val_loss = min(list_of_avg_loss)\n",
    "\n",
    "\n",
    "# Plotting the training loss\n",
    "plt.plot(epochss, training_losses, label='Training Loss')\n",
    "plt.plot(epochss, validation_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss over Epochs')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# After training, you can use the model for prediction\n",
    "# Example usage:\n",
    "# test_input = torch.randn(1, sequence_length, input_dim)  # Adjust based on your input size and sequence length\n",
    "# predicted_output = model(test_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53570b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29d418c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation predict\n",
    "#val_df = \n",
    "\n",
    "#Read TEST Sequence\n",
    "test_df = pd.read_csv(TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e1f6c88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GGGAACGACUCGAGUAGAGUCGAAAAUUUCCUUCCAAAUCCUGAGGGAGAGAUAGAGGCGGAGGGUCUGGGGGAGGAAUUAAAACACAAGGUCUCCUCCCCUCUCGCCUGUCCGAACUUGGGGGCACCCCGGCUCGUACUUCGGUACGAGCCGGGGAAAAGAAACAACAACAACAAC'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(4)\n",
    "test_df.at[0, 'sequence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5beb751a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df['sequence'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "482b60c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows: 100%|███████████████████████████████████████████████████████████████████████| 1343823/1343823 [03:18<00:00, 6772.17it/s]\n"
     ]
    }
   ],
   "source": [
    "test_df['DMS_sequence'] = copy.deepcopy(test_df['sequence'])\n",
    "test_df['2A3_sequence'] = copy.deepcopy(test_df['sequence'])\n",
    "\n",
    "\n",
    "test_df_sq = copy.deepcopy(test_df['sequence']) #saving a backup of sequences.\n",
    "#react_columns['maped_sequence'] = [' ']*len(react_columns)\n",
    "#for index, row in tqdm(df.iterrows(), total=len(df.rows), desc=\"Processing rows\"):\n",
    "for index, row in tqdm(test_df.iterrows(), total=len(test_df), desc=\"Processing rows\"):\n",
    "    \n",
    "    padding = \"Z\"*(max_seq_len - 2 - len(test_df.at[index, 'sequence']))\n",
    "    form_DMS_seq = 'M' + test_df.at[index, 'sequence'] + 'N' + padding\n",
    "    form_2A3_seq = 'T' + test_df.at[index, 'sequence'] + 'X' + padding\n",
    "    \n",
    "\n",
    "    test_df.at[index, 'DMS_sequence'] = [seq_map[s] for s in form_DMS_seq]\n",
    "    test_df.at[index, '2A3_sequence'] = [seq_map[s] for s in form_2A3_seq]\n",
    "    #if small_dataset == 1:\n",
    "    #    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7eb69870",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.no_grad():\n",
    "#src_data = src_data.to(device=device)\n",
    "#tgt_data = tgt_data.to(device=device, dtype=torch.long)\n",
    "#output = transformer_model(src_data, tgt_data[:, :-1])\n",
    "\n",
    "#out = transformer_model(test_df['2A3_sequence'][0], tgt_data[:, :-1])\n",
    "\n",
    "input_sequence = torch.tensor([test_df.at[357440, 'DMS_sequence']]).to(device=device, dtype=torch.long)\n",
    "#inputs = dat[0].to(device, dtype=torch.long)\n",
    "out = []\n",
    "#print(\"input seq\", input_sequence.size())\n",
    "out = model(input_sequence)\n",
    "#print(\"out\", out.size, out.shape)\n",
    "out[out < 0] = 0.0\n",
    "out[out > 1] = 1.0\n",
    "#out\n",
    "index = 357440\n",
    "seq_length = len(test_df.at[index, 'sequence'])\n",
    "padding = \"Z\"*(max_seq_len - 2 - len(test_df.at[357440, 'sequence']))\n",
    "id_minn = test_df.at[index, 'id_min']\n",
    "id_maxx = test_df.at[index, 'id_max']\n",
    "#print(f'index {index}, seq len {seq_length}, id_min {id_minn},  id_max {id_maxx} , difference {id_maxx - id_minn}')\n",
    "#print(test_df.at[index, 'DMS_sequence'])\n",
    "#print(f'pad -{padding}-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c21bf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "model  = torch.load(MODEL_NAME)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "28e8ca1e",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/media/spartans/COMMON:/RNA_Project/submission_0.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#sample_df = pd.read_csv(\"/media/spartans/COMMON:/RNA_Project/sample_submission.csv\")\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m sample_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSAMPLE_SUBMISSION_PATH\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/media/spartans/COMMON:/RNA_Project/submission_0.csv'"
     ]
    }
   ],
   "source": [
    "#sample_df = pd.read_csv(\"/media/spartans/COMMON:/RNA_Project/sample_submission.csv\")\n",
    "sample_df = pd.read_csv(SAMPLE_SUBMISSION_PATH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e8a637",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_df['id_max'][0]\n",
    "#print(test_df)\n",
    "\n",
    "\n",
    "for index, row in tqdm(test_df.iterrows(), total=len(test_df), desc=\"Processing rows\"):\n",
    "    input_sequence = torch.tensor([test_df.at[index, 'DMS_sequence']]).to(device=device, dtype=torch.long)\n",
    "    seq_length = len(test_df.at[index, 'sequence'])\n",
    "    #print(f'{seq_length}')\n",
    "    #if seq_length != 177:\n",
    "        #print(f' seq length {seq_len}')\n",
    "        #id_minn = test_df.at[index, 'id_min']\n",
    "        #id_maxx = test_df.at[index, 'id_max']\n",
    "        #print(f'index {index}, seq len {seq_length}, id_min {id_minn},  id_max {id_maxx} ')\n",
    "    #First check what is the sequence length. If it is less than or equal to 206 then process it straight.\n",
    "    \n",
    "    id_minn = test_df.at[index, 'id_min']\n",
    "    id_maxx = test_df.at[index, 'id_max']\n",
    "    #print(f'index {index}, seq len {seq_length}, id_min {id_minn},  id_max {id_maxx} ')\n",
    "    \n",
    "    #out_dms = []\n",
    "    out_dms = model(input_sequence)\n",
    "    out_dms[out_dms < 0] = 0.0\n",
    "    out_dms[out_dms > 1] = 1.0\n",
    "    \n",
    "    out_dms = out_dms.tolist()   \n",
    "    iiii = 0\n",
    "    for iii in range(id_minn, id_maxx): \n",
    "        sample_df.at[iii, 'reactivity_DMS_MaP'] = out_dms[0][iiii]\n",
    "        sample_df.at[iii, 'id'] = iii\n",
    "        iiii = iiii + 1\n",
    "\n",
    "\n",
    "    #out_2a3 = []\n",
    "    input_sequence = torch.tensor([test_df.at[index, '2A3_sequence']]).to(device=device, dtype=torch.long)\n",
    "    out_2a3 = model(input_sequence)\n",
    "    out_2a3[out_2a3 < 0] = 0.0\n",
    "    out_2a3[out_2a3 > 1] = 1.0\n",
    "    out_2a3 = out_2a3.tolist()\n",
    "    #out_2a3[:seq_length]\n",
    "    \n",
    "    #sample_df[id_minn:id_maxx]['reactivity_2A3_MaP'] = pd.DataFrame({'reactivity_2A3_MaP': out_2a3[0][:seq_length]}, index=range(id_minn, id_minn + seq_length))\n",
    "    iiii = 0 \n",
    "    for iii in range(id_minn, id_maxx):\n",
    "        sample_df.at[iii, 'reactivity_2A3_MaP'] = out_2a3[0][iiii]    \n",
    "        iiii = iiii + 1  \n",
    "\n",
    "sample_df['id'] = sample_df['id'].astype(int)\n",
    "columns_order = ['id','reactivity_DMS_MaP','reactivity_2A3_MaP']\n",
    "out_sample_df = sample_df[columns_order]\n",
    "out_sample_df.to_csv(SUBMISSION_PATH, index=False)\n",
    "    #if index==2:\n",
    "    #    break\n",
    "    \n",
    "    \n",
    "    \n",
    "#sample_df   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf76a66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
