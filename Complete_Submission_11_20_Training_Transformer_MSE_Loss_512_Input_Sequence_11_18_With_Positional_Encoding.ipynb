{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10dd24c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from transformer import Transformer \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import math\n",
    "import copy\n",
    "import os\n",
    "import gc\n",
    "import random\n",
    "import numpy as np\n",
    "#import polars as pl\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset, random_split\n",
    "import fastai\n",
    "from fastai.vision.all import *\n",
    "\n",
    "import math\n",
    "import copy\n",
    "\n",
    "# Check if a GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#device = \"cpu\"\n",
    "\n",
    "\n",
    "max_seq_len = 510 + 2  # +2 is added to cover start and end token of sequence This will change to 457 in private set  # Set the maximum sequence length to 100\n",
    "data_preprocessing_done = 0\n",
    "save_pkl = 0\n",
    "load_pkl = 0\n",
    "small_dataset = 1\n",
    "\n",
    "#Training Data\n",
    "if small_dataset == 1:\n",
    "    \n",
    "    #Uncomment this section when uploading the jupyter notebook\n",
    "    '''\n",
    "    df_read = pd.read_csv('/media/spartans/COMMON:/RNA_Project/train_data.csv')\n",
    "    \n",
    "    criteria_2A3 = (df_read['experiment_type'] == '2A3_MaP') & (df_read['SN_filter'] == 1)\n",
    "    criteria_DMS = (df_read['experiment_type'] == 'DMS_MaP') & (df_read['SN_filter'] == 1)\n",
    "\n",
    "    df_2A3_Filter1 = df_read[criteria_2A3]\n",
    "    df_2A3_Filter1 = df_2A3_Filter1.head(4)\n",
    "\n",
    "    df_DMS_Filter1 = df_read[criteria_DMS]\n",
    "    df_DMS_Filter1 = df_DMS_Filter1.head(4)\n",
    "\n",
    "   \n",
    "    df = pd.concat([df_2A3_Filter1, df_DMS_Filter1], ignore_index=True)\n",
    "    \n",
    "    df.to_csv('2A3_DMS_With_Filter1_Train_Data.csv', index=False)\n",
    "    #df_2A3_Filter1.to_csv('2A3_DMS_With_Filter1_Train_Data.csv', index=False)\n",
    "    '''\n",
    "    df = pd.read_csv('2A3_DMS_With_Filter1_Train_Data.csv')\n",
    "    #df = pd.read_csv('DMS_Data.csv')\n",
    "    #df = pd.read_csv('2A3_Data.csv')\n",
    "else:\n",
    "    df = pd.read_csv('/media/spartans/COMMON:/RNA_Project/train_data.csv')\n",
    "    \n",
    "\n",
    "#test_df = pd.read_csv('/media/spartans/COMMON:/RNA_Project/test_sequences.csv')\n",
    "TEST_PATH = \"/media/spartans/COMMON:/RNA_Project/test_sequences.csv\"\n",
    "SUBMISSION_PATH = \"/media/spartans/COMMON:/RNA_Project/submission_0.csv\"\n",
    "SAMPLE_SUBMISSION_PATH = \"/media/spartans/COMMON:/RNA_Project/sample_submission.csv\"\n",
    "MODEL_NAME = \"Trained_Model.model_512_11_18_2023\"\n",
    "\n",
    "seed=69\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = str(1)\n",
    "\n",
    "os.environ['TORCH_USE_CUDA_DSA'] = str(1)\n",
    "\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "seed_everything(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2deb452f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "#criteria_2A3 = (df_read['experiment_type'] == '2A3_MaP') & (df_read['SN_filter'] == '1')\n",
    "#criteria_DMS = (df_read['experiment_type'] == 'DMS_MaP') & (df_read['SN_filter'] == '1')\n",
    "\n",
    "#criteria_2A3 = ((df_read['experiment_type'] == 'DMS_MaP')  & df_read['SN_filter'] == 1 )\n",
    "#df_2A3_Filter1 = df_read[criteria_2A3]\n",
    "#df_2A3_Filter1\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61508b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#where reactivity is NaN,\n",
    "# have Nan replaced with average of all numbers in the sequence.\n",
    "\n",
    "#Map sequence letters to numbers.\n",
    "\n",
    "#Looking at Reads and Signal To Noise ..they appear to be somewhat coorelated.\n",
    "\n",
    "#Create Dataset function\n",
    "\n",
    "\n",
    "#In contrastive loss model... you can train based on#\n",
    "#in a sequence which part is 2D fold and which part is 3D fold\n",
    "#See notebook https://www.kaggle.com/code/something4kag/ribonanza-3d-coords-prep\n",
    "#if it can be helpful\n",
    "# Also analyze and which position in the sequence the fold can occur and which fold ended up happening based on the data\n",
    "\n",
    "#another method to formulate contrastive learning model is by deferentiating sequences with low SNR and hence reactivity value will not be with high confidence.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db2f1a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#In RNA, the most common base pairings you'll find are between the following nucleotide bases:\n",
    "\n",
    "#Adenine (A) and Uracil (U): A forms base pairs with U. This is a fundamental pairing and is commonly seen in RNA molecules, particularly in single-stranded regions. It is important for the stability of stem-loop structures and is a key component of RNA secondary structure.\n",
    "\n",
    "#Guanine (G) and Cytosine (C): G forms base pairs with C, just as it does in DNA. This pairing is less common in RNA secondary structure but is still important for certain RNA molecules. It may be more prevalent in the context of ribozymes and catalytic RNA.\n",
    "\n",
    "#While A-U and G-C are the primary base pairings in RNA, it's essential to understand that RNA can also exhibit non-canonical or non-standard base pairings, especially in more complex RNA structures. These non-canonical pairings can involve different combinations of A, U, G, and C and are often seen in tertiary structures or specialized RNA molecules with specific functions.\n",
    "\n",
    "#The prevalence of A-U and G-C base pairings in an RNA molecule can vary depending on its sequence and function. For instance, regions that need to form stable secondary structures often rely on A-U pairings, while regions involved in catalytic activities may include G-C pairs. RNA structures are diverse and can exhibit a wide range of base pairing interactions to achieve their biological functions.\n",
    "\n",
    "\n",
    "\n",
    "#So a contrastive loss can be formed here where\n",
    "#AU pair GC pair are strong positive - stable\n",
    "#AG, UC are less stable\n",
    "#UG, UA, CG pair are unstable so negative .\n",
    "#\n",
    "#In RNA, the stable base pairs among the four nucleotide bases (A, G, U, and C) follow the standard Watson-Crick base-pairing rules. Here are the stable base pairs among these bases:\n",
    "\n",
    "#GC pairs are more stable than AU pair\n",
    "\n",
    "\n",
    "#So you can tokenzie these pairs in the transformer model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5b71bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Formulate Convolution NN or Dense Net which takes SNR, Reactivity error and feeds into the final layer of Transformer network\n",
    "# As an example\n",
    "#Lowest Reactivity Error and High SNR are  strong positives\n",
    "# Lowest SNR are strong negative.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#sequence length range from 115 to 206 in train dataset.\n",
    "#in final it will range from 207 to 457"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dbb5976",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In positional encoding\n",
    "#pos means the position of the word in the sequence.\n",
    "#i means the index for that particular word vector (index of the dimension)\n",
    "#dmodel is the dimension for e.g 512 from the example\n",
    "\n",
    "\n",
    "#For 2 experiment types i.e. DMS and 2A3 you can have start and end  token in a sequence for which data is available.\n",
    "#.e. start_DMS, end_DMS, start_2A3, end_2A3.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8607779c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cb051b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13228/3653553058.py:7: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  react_columns = react_columns.applymap(lambda x: 0 if isinstance(x, (float, int)) and x < 0 else x)\n"
     ]
    }
   ],
   "source": [
    "if data_preprocessing_done == 0:\n",
    "    #Assigning reactivity Columns to react_columns dataframe and replacing NaN with 0.000 \n",
    "\n",
    "    react_columns = df.iloc[:,7:213].fillna(0.000000)\n",
    "\n",
    "    #Find mean of reactivity per row\n",
    "    react_columns = react_columns.applymap(lambda x: 0 if isinstance(x, (float, int)) and x < 0 else x)\n",
    "\n",
    "    react_columns_mean = react_columns.mean(axis=1)\n",
    "    #Free up memory\n",
    "    del(react_columns)\n",
    "\n",
    "    #Now replace NaN in react_columns with mean_reactivity\n",
    "    #react_columns_New = df.iloc[:,7:213].fillna(mean_reactivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac6bd190",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 5188.56it/s]\n",
      "/tmp/ipykernel_13228/1102462686.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  react_columns = react_columns.applymap(lambda x: 0 if isinstance(x, (float, int)) and x < 0 else x)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if data_preprocessing_done == 0:\n",
    "    react_columns = df.iloc[:,7:213] #You may have to capture those indices as per sequence length i.e. when it extends to 457\n",
    "\n",
    "    # Replace NaN values in each row with values from replace_values array\n",
    "    for index, row in tqdm(react_columns.iterrows(), total=len(react_columns), desc=\"Processing rows\"):\n",
    "        react_columns.loc[index] = row.fillna(react_columns_mean[index])\n",
    "    \n",
    "    react_columns = react_columns.applymap(lambda x: 0 if isinstance(x, (float, int)) and x < 0 else x)\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a10cd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_map = {'A':1.0,\n",
    "           'C':2.0,\n",
    "           'G':3.0,\n",
    "           'U':4.0, \n",
    "           'M':5.0,  #Start token of DMS exp seq\n",
    "           'N':6.0,  #End token of DMS exp seq\n",
    "           'T':7.0,  #Start token of 2A3 exp seq\n",
    "           'X':8.0,  #End token of 2A3 exp seq\n",
    "           'Z':0.0   #Padding token\n",
    "          }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57653080",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 7484.82it/s]\n"
     ]
    }
   ],
   "source": [
    "# Iterate over rows and replace a specific value in all columns\n",
    "\n",
    "\n",
    "#max_seq_len = 206 #This will change to 457 in private set  # Set the maximum sequence length to 100\n",
    "if data_preprocessing_done == 0:\n",
    "    df_sq = copy.deepcopy(df['sequence']) #saving a backup of sequences.\n",
    "    #react_columns['maped_sequence'] = [' ']*len(react_columns)\n",
    "    #for index, row in tqdm(df.iterrows(), total=len(df.rows), desc=\"Processing rows\"):\n",
    "    for index, row in tqdm(react_columns.iterrows(), total=len(react_columns), desc=\"Processing rows\"):\n",
    "        if df.at[index, 'experiment_type'] == \"2A3_MaP\":\n",
    "            concat_seq = 'T' + df.at[index, 'sequence'] + 'X'\n",
    "        if df.at[index, 'experiment_type'] == \"DMS_MaP\":\n",
    "            concat_seq = 'M' + df.at[index, 'sequence'] + 'N'\n",
    "        padding = \"Z\"*(max_seq_len - 2 - len(df.at[index, 'sequence']))\n",
    "        concatenated_seq = concat_seq + padding\n",
    "        df.at[index, 'sequence'] = [seq_map[s] for s in concatenated_seq]\n",
    "        #react_columns.at[index, 'maped_sequence'] = [seq_map[s] for s in concatenated_seq]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb2e3e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
      "/tmp/ipykernel_13228/834134542.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  react_columns['mapped_sequence'] = copy.deepcopy(df['sequence'])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if data_preprocessing_done == 0:\n",
    "    #react_columns['reactivity_0207'] = copy.deepcopy(react_columns['reactivity_0206'])\n",
    "    #react_columns['reactivity_0208'] = copy.deepcopy(react_columns['reactivity_0206'])\n",
    "    for iii in range(207,511):\n",
    "        react_col_name = \"reactivity_0\" + str(iii)\n",
    "        react_columns[react_col_name] = copy.deepcopy(react_columns['reactivity_0206'])\n",
    "        \n",
    "    #replicated_columns = [react_columns['reactivity_0206'].repeat(2)]\n",
    "    #react_columns = pd.concat([react_columns, replicated_columns] , axis=1, ignore_index=True)\n",
    "    #print(react_columns)\n",
    "    react_columns['mapped_sequence'] = copy.deepcopy(df['sequence'])\n",
    "    #del react_columns['reactivity_0207']\n",
    "    #del react_columns['reactivity_0208']\n",
    "if save_pkl == 1:\n",
    "    react_columns.to_pickle(\"react_columns.pkl\")\n",
    "\n",
    "if load_pkl == 1:\n",
    "    react_columns = pd.read_pickle(\"react_columns.pkl\")\n",
    "    \n",
    "#react_columns.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02d4f1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom dataset class for your data\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, max_seq_len):\n",
    "        self.data = data\n",
    "        self.max_seq_len = max_seq_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        trg_sequence = torch.tensor(self.data.iloc[idx, :].tolist()[:-1])\n",
    "        src_sequence = torch.tensor(self.data.iloc[idx, :].tolist()[-1])\n",
    "        \n",
    "        #print(\"Size src seq \", src_sequence.size())\n",
    "        #print(\"Size trg seq \", trg_sequence, trg_sequence.size())\n",
    "        \n",
    "        return src_sequence, trg_sequence\n",
    "\n",
    "    \n",
    "# Create a DataLoader for batching and shuffling\n",
    "batch_size = 64\n",
    "#batch_size = 3\n",
    "\n",
    "\n",
    "# Define the size of the training set\n",
    "dataset_size = len(react_columns)\n",
    "train_size = int(0.9 * dataset_size)\n",
    "test_size = dataset_size - train_size\n",
    "\n",
    "custom_dataset = CustomDataset(react_columns, max_seq_len)\n",
    "train_indices, test_indices = random_split(custom_dataset, [train_size, test_size])\n",
    "train_dataloader = DataLoader(train_indices, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_indices, batch_size=batch_size)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7083c75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=512):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.encoding = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1).float()\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n",
    "        self.encoding[:, 0::2] = torch.sin(position * div_term)\n",
    "        self.encoding[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.encoding = self.encoding.unsqueeze(0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.encoding = self.encoding.to(x.device)\n",
    "        return x + self.encoding[:, :x.size(1)].detach()\n",
    "    \n",
    "\n",
    "\n",
    "class MyTransformerEncoderLayer(nn.TransformerEncoderLayer):\n",
    "    def __init__(self, d_model, nhead, batch_first=True, **kwargs):\n",
    "        super(MyTransformerEncoderLayer, self).__init__(d_model, nhead, **kwargs)\n",
    "        self.self_attn = nn.MultiheadAttention(d_model, nhead, batch_first=batch_first)\n",
    "\n",
    "\n",
    "class TransformerRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, nhead, num_layers, output_sequence_length, max_len=512):\n",
    "        super(TransformerRegressionModel, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, hidden_dim)\n",
    "        \n",
    "        self.positional_encoding = PositionalEncoding(hidden_dim, max_len=max_len)\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=input_dim, nhead=nhead),\n",
    "            num_layers=num_layers\n",
    "        )\n",
    "        '''\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            MyTransformerEncoderLayer(d_model=hidden_dim, nhead=nhead, batch_first=True),\n",
    "            num_layers=num_layers\n",
    "        )\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.transformer_decoder = nn.TransformerDecoder(\n",
    "            nn.TransformerDecoderLayer(d_model=input_dim, nhead=nhead),\n",
    "            num_layers=num_layers\n",
    "        )\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        self.fc = nn.Linear(input_dim, output_sequence_length * 1)\n",
    "        self.gelu = nn.GELU()\n",
    "        self.output_sequence_length = output_sequence_length\n",
    "\n",
    "\n",
    "    \n",
    "    def forward(self, x):              \n",
    "        \n",
    "        # Ensure that both the model and input are on the same device\n",
    "        device = next(self.parameters()).device\n",
    "        x = x.to(device)\n",
    "        \n",
    "        # Apply embedding to input\n",
    "        #print(\"X shape 1\", x.shape)\n",
    "        x = self.embedding(x)\n",
    "        #print(\"X shape 2\", x.shape)\n",
    "        \n",
    "        x = self.positional_encoding(x)\n",
    "        \n",
    "        # Permute to (sequence_length, batch_size, input_dim)\n",
    "        x = x.permute(1, 0, 2)\n",
    "        #print(\"X shape 3\", x.shape)\n",
    "        \n",
    "        # Encoder forward pass\n",
    "        encoder_output = self.transformer_encoder(x)\n",
    "\n",
    "        # Decoder forward pass with memory from the encoder\n",
    "        decoder_output = self.transformer_decoder(x, memory=encoder_output)\n",
    "\n",
    "        # Global average pooling over the sequence dimension\n",
    "        x = decoder_output.mean(dim=0)\n",
    "\n",
    "        # Final fully connected layer with GELU activation\n",
    "        x = self.gelu(self.fc(x))\n",
    "\n",
    "        return x\n",
    "    \n",
    "\n",
    "# Hyperparameters\n",
    "input_dim =  max_seq_len # Adjust based on your input size\n",
    "hidden_dim = 512\n",
    "nhead = 16\n",
    "num_layers = 6\n",
    "output_sequence_length = max_seq_len - 2  # Adjust based on your output sequence length\n",
    "#batch_size = 1\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356a0751",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(device)\n",
    "\n",
    "# Instantiate the model, loss function, and optimizer\n",
    "model = TransformerRegressionModel(input_dim, hidden_dim, nhead, num_layers, output_sequence_length).to(device)\n",
    "#criterion = nn.MSELoss()\n",
    "criterion = nn.L1Loss(size_average=None, reduce=None, reduction='mean')\n",
    "#optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9, weight_decay=0, amsgrad=False)\n",
    "\n",
    "\n",
    "\n",
    "training_losses = []  # to store training losses\n",
    "validation_losses = []\n",
    "prev_average_val_loss = 10000000000\n",
    "list_of_avg_loss = []\n",
    "epochss = []\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0.0  # accumulate loss for the entire epoch\n",
    "    val_loss = 0.0\n",
    "    #for inputs, targets in tqdm(train_dataloader.iterrows(), total=len(train_dataloader), desc=\"Processing rows\"):\n",
    "    #with tqdm(train_dataloader, desc=f'Epoch {epoch + 1}/{num_epochs}', unit='batch') as tqdm_loader:\n",
    "    #    for inputs, targets in tqdm_loader:\n",
    "         \n",
    "    model.train()        \n",
    "    #for batch, dat in enumerate(train_dataloader, 1): \n",
    "    for batch, dat in enumerate(tqdm(train_dataloader, desc=\"Processing batches\", unit=\"batch\"), 1):\n",
    "            inputs = dat[0].to(device, dtype=torch.long)\n",
    "            targets = dat[1].to(device).float()\n",
    "            #print(\"INPUT \", inputs)\n",
    "            #print(\"TARGET \", targets)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            #print(\"OUT\", outputs)\n",
    "            #print(f'TRAIN:  Batch {batch}, Input: {inputs.shape}, Outputs: {outputs.shape}, Targets: {targets.shape}')\n",
    "            #Pre-clipping may mean the model may not learn the targets.\n",
    "            outputs[outputs < 0] = 0.0\n",
    "            outputs[outputs > 1] = 1.0\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            #print(f\"Epoch: {epoch+1}, Training Loss: {loss.item()}\")\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        #for batch, dat in enumerate(test_dataloader, 1):\n",
    "        for batch, dat in enumerate(tqdm(test_dataloader, desc=\"Processing batches\", unit=\"batch\"), 1):\n",
    "            inputs = dat[0].to(device, dtype=torch.long)\n",
    "            targets = dat[1].to(device).float()\n",
    "            output = model(inputs)\n",
    "            #print(f'VAL:  Batch {batch}, Input: {inputs.shape}, Outputs: {output.shape}, Targets: {targets.shape}')\n",
    "            loss = criterion(output, targets)\n",
    "            #print(f\"Epoch: {epoch+1}, Validation Loss: {loss.item()}\")\n",
    "            val_loss += loss.item()\n",
    "    \n",
    "    #outputs.requires_grad_(True)\n",
    "    \n",
    "    \n",
    "    average_epoch_loss = epoch_loss / len(train_dataloader)\n",
    "    training_losses.append(average_epoch_loss)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Training Loss: {average_epoch_loss:.4f}')\n",
    "    \n",
    "    average_val_loss = val_loss / len(test_dataloader)\n",
    "    validation_losses.append(average_val_loss)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Validation Loss: {average_val_loss:.4f}')\n",
    "    epochss.append(epoch)\n",
    "    \n",
    "    list_of_avg_loss.append(average_val_loss)\n",
    "    #Save best model Every Epoch\n",
    "    if average_val_loss < prev_average_val_loss:\n",
    "        torch.save(model.state_dict(), MODEL_NAME)\n",
    "        \n",
    "        \n",
    "        \n",
    "        print(\"Model Saved because \")\n",
    "        print(f'Current average validation loss {average_val_loss:.4f} is less than previous average validation loss {prev_average_val_loss:.4f}')\n",
    "    prev_average_val_loss = min(list_of_avg_loss)\n",
    "\n",
    "\n",
    "# Plotting the training loss\n",
    "plt.plot(epochss, training_losses, label='Training Loss')\n",
    "plt.plot(epochss, validation_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss over Epochs')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# After training, you can use the model for prediction\n",
    "# Example usage:\n",
    "# test_input = torch.randn(1, sequence_length, input_dim)  # Adjust based on your input size and sequence length\n",
    "# predicted_output = model(test_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53570b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29d418c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation predict\n",
    "#val_df = \n",
    "\n",
    "#Read TEST Sequence\n",
    "test_df = pd.read_csv(TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e1f6c88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GGGAACGACUCGAGUAGAGUCGAAAAUUUCCUUCCAAAUCCUGAGGGAGAGAUAGAGGCGGAGGGUCUGGGGGAGGAAUUAAAACACAAGGUCUCCUCCCCUCUCGCCUGUCCGAACUUGGGGGCACCCCGGCUCGUACUUCGGUACGAGCCGGGGAAAAGAAACAACAACAACAAC'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(4)\n",
    "test_df.at[0, 'sequence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5beb751a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df['sequence'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "482b60c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows: 100%|█████████████████████████████████████████████████████████████████████████████████| 1343823/1343823 [03:12<00:00, 6993.25it/s]\n"
     ]
    }
   ],
   "source": [
    "test_df['DMS_sequence'] = copy.deepcopy(test_df['sequence'])\n",
    "test_df['2A3_sequence'] = copy.deepcopy(test_df['sequence'])\n",
    "\n",
    "\n",
    "test_df_sq = copy.deepcopy(test_df['sequence']) #saving a backup of sequences.\n",
    "#react_columns['maped_sequence'] = [' ']*len(react_columns)\n",
    "#for index, row in tqdm(df.iterrows(), total=len(df.rows), desc=\"Processing rows\"):\n",
    "for index, row in tqdm(test_df.iterrows(), total=len(test_df), desc=\"Processing rows\"):\n",
    "    \n",
    "    padding = \"Z\"*(max_seq_len - 2 - len(test_df.at[index, 'sequence']))\n",
    "    form_DMS_seq = 'M' + test_df.at[index, 'sequence'] + 'N' + padding\n",
    "    form_2A3_seq = 'T' + test_df.at[index, 'sequence'] + 'X' + padding\n",
    "    \n",
    "\n",
    "    test_df.at[index, 'DMS_sequence'] = [seq_map[s] for s in form_DMS_seq]\n",
    "    test_df.at[index, '2A3_sequence'] = [seq_map[s] for s in form_2A3_seq]\n",
    "    #if small_dataset == 1:\n",
    "    #    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7eb69870",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.no_grad():\n",
    "#src_data = src_data.to(device=device)\n",
    "#tgt_data = tgt_data.to(device=device, dtype=torch.long)\n",
    "#output = transformer_model(src_data, tgt_data[:, :-1])\n",
    "\n",
    "#out = transformer_model(test_df['2A3_sequence'][0], tgt_data[:, :-1])\n",
    "\n",
    "input_sequence = torch.tensor([test_df.at[357440, 'DMS_sequence']]).to(device=device, dtype=torch.long)\n",
    "#inputs = dat[0].to(device, dtype=torch.long)\n",
    "out = []\n",
    "#print(\"input seq\", input_sequence.size())\n",
    "out = model(input_sequence)\n",
    "#print(\"out\", out.size, out.shape)\n",
    "out[out < 0] = 0.0\n",
    "out[out > 1] = 1.0\n",
    "#out\n",
    "index = 357440\n",
    "seq_length = len(test_df.at[index, 'sequence'])\n",
    "padding = \"Z\"*(max_seq_len - 2 - len(test_df.at[357440, 'sequence']))\n",
    "id_minn = test_df.at[index, 'id_min']\n",
    "id_maxx = test_df.at[index, 'id_max']\n",
    "#print(f'index {index}, seq len {seq_length}, id_min {id_minn},  id_max {id_maxx} , difference {id_maxx - id_minn}')\n",
    "#print(test_df.at[index, 'DMS_sequence'])\n",
    "#print(f'pad -{padding}-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c21bf64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerRegressionModel(\n",
       "  (embedding): Embedding(512, 512)\n",
       "  (positional_encoding): PositionalEncoding()\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x MyTransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (transformer_decoder): TransformerDecoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=512, out_features=510, bias=True)\n",
       "  (gelu): GELU(approximate='none')\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model  = torch.load(MODEL_NAME)\n",
    "model = TransformerRegressionModel(input_dim, hidden_dim, nhead, num_layers, output_sequence_length).to(device)\n",
    "model.load_state_dict(torch.load('With_State_DicT'))\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28e8ca1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample_df = pd.read_csv(\"/media/spartans/COMMON:/RNA_Project/sample_submission.csv\")\n",
    "sample_df = pd.read_csv(SAMPLE_SUBMISSION_PATH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "17e8a637",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows: 100%|████████████████████████████████████████████████████████████████████████████████| 1343823/1343823 [15:14:39<00:00, 24.49it/s]\n"
     ]
    }
   ],
   "source": [
    "test_df['id_max'][0]\n",
    "#print(test_df)\n",
    "sample_df['reactivity_DMS_MaP'] = sample_df['reactivity_DMS_MaP'].astype(float)\n",
    "sample_df['reactivity_2A3_MaP'] = sample_df['reactivity_DMS_MaP'].astype(float)\n",
    "\n",
    "for index, row in tqdm(test_df.iterrows(), total=len(test_df), desc=\"Processing rows\"):\n",
    "    input_sequence = torch.tensor([test_df.at[index, 'DMS_sequence']]).to(device=device, dtype=torch.long)\n",
    "    seq_length = len(test_df.at[index, 'sequence'])\n",
    "    #print(f'{seq_length}')\n",
    "    #if seq_length != 177:\n",
    "        #print(f' seq length {seq_len}')\n",
    "        #id_minn = test_df.at[index, 'id_min']\n",
    "        #id_maxx = test_df.at[index, 'id_max']\n",
    "        #print(f'index {index}, seq len {seq_length}, id_min {id_minn},  id_max {id_maxx} ')\n",
    "    #First check what is the sequence length. If it is less than or equal to 206 then process it straight.\n",
    "    \n",
    "    id_minn = test_df.at[index, 'id_min']\n",
    "    id_maxx = test_df.at[index, 'id_max']\n",
    "    #print(f'index {index}, seq len {seq_length}, id_min {id_minn},  id_max {id_maxx} ')\n",
    "    \n",
    "    #out_dms = []\n",
    "    out_dms = model(input_sequence)\n",
    "    out_dms[out_dms < 0] = 0.0\n",
    "    out_dms[out_dms > 1] = 1.0\n",
    "    \n",
    "    out_dms = out_dms.tolist()   \n",
    "    iiii = 0\n",
    "    for iii in range(id_minn, id_maxx): \n",
    "        sample_df.at[iii, 'reactivity_DMS_MaP'] = out_dms[0][iiii]\n",
    "        sample_df.at[iii, 'id'] = iii\n",
    "        iiii = iiii + 1\n",
    "\n",
    "\n",
    "    #out_2a3 = []\n",
    "    input_sequence = torch.tensor([test_df.at[index, '2A3_sequence']]).to(device=device, dtype=torch.long)\n",
    "    out_2a3 = model(input_sequence)\n",
    "    out_2a3[out_2a3 < 0] = 0.0\n",
    "    out_2a3[out_2a3 > 1] = 1.0\n",
    "    out_2a3 = out_2a3.tolist()\n",
    "    #out_2a3[:seq_length]\n",
    "    \n",
    "    #sample_df[id_minn:id_maxx]['reactivity_2A3_MaP'] = pd.DataFrame({'reactivity_2A3_MaP': out_2a3[0][:seq_length]}, index=range(id_minn, id_minn + seq_length))\n",
    "    iiii = 0 \n",
    "    for iii in range(id_minn, id_maxx):\n",
    "        sample_df.at[iii, 'reactivity_2A3_MaP'] = out_2a3[0][iiii]    \n",
    "        iiii = iiii + 1  \n",
    "\n",
    "sample_df['id'] = sample_df['id'].astype(int)\n",
    "columns_order = ['id','reactivity_DMS_MaP','reactivity_2A3_MaP']\n",
    "out_sample_df = sample_df[columns_order]\n",
    "out_sample_df.to_csv(SUBMISSION_PATH, index=False, float_format='%.6f')\n",
    "    #if index==2:\n",
    "    #    break\n",
    "    \n",
    "    \n",
    "    \n",
    "#sample_df   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf76a66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
